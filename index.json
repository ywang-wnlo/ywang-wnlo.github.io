[{"categories":["日常踩坑"],"content":"写代码难免遇到 bug，调试解决 bug 的快慢很影响开发的效率。本文主要是梳理并记录下个人经常用的调试方法（主要以 C/C++ 的 segment fault 为例） ","date":"2023-09-09","objectID":"/posts/89f2ed7d/:0:0","tags":["日常踩坑","Debug","addr2line","gdb","objdump","assert","反汇编"],"title":"Debug 从入门到入土","uri":"/posts/89f2ed7d/"},{"categories":["日常踩坑"],"content":"分类 根据调试时机与 bug 产生的时间的前后关系，主要分为“事后”、“事中”、“事先”三类： “事后” 主要是通过 addr2line 或者 objdump 等工具，定位报错时的程序运行位置 “事中” 主要是通过 GDB 来观察程序运行时的状态，实时的捕捉 bug “事先” 主要是通过在源代码中插入打印语句，来观察程序运行时各个变量的状态 ","date":"2023-09-09","objectID":"/posts/89f2ed7d/:1:0","tags":["日常踩坑","Debug","addr2line","gdb","objdump","assert","反汇编"],"title":"Debug 从入门到入土","uri":"/posts/89f2ed7d/"},{"categories":["日常踩坑"],"content":"事后 通常为了快速的定位 bug，会根据出错时的程序输出，来判断重新出错的位置 然而一般的程序输出可能不足以提供足够信息的情况，此时可以根据 segmentation fault (core dumped) 信息并且借助一些工具来定位出错的位置 ","date":"2023-09-09","objectID":"/posts/89f2ed7d/:2:0","tags":["日常踩坑","Debug","addr2line","gdb","objdump","assert","反汇编"],"title":"Debug 从入门到入土","uri":"/posts/89f2ed7d/"},{"categories":["日常踩坑"],"content":"addr2line addr2line 在程序含有 debug 信息时可以快速的将地址转换为文件名和行号 具体的使用方法可以通过 man addr2line 查看，这里简单介绍一下常用的用法 以下面的代码为例： #include \u003cstdio.h\u003e int main() { int *p = NULL; *p = 2; return 0; } # 编译时加上 -g 选项，生成 debug 信息 # -no-pie 选项是为了避免 ASLR 的影响（高版本的 gcc 默认开启 ASLR） $ gcc -g -no-pie test.c -o test # 运行程序，会出现 segmentation fault $ ./test [1] 7533 segmentation fault (core dumped) ./test # dmesg 查看内核日志，可以看到 segmentation fault 的详细信息 $ dmesg | tail -n 2 [46592.916853] test[7533]: segfault at 0 ip 000000000040111a sp 00007ffce6095a70 error 6 in test[401000+1000] [46592.916875] Code: c3 66 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 40 00 f3 0f 1e fa eb 8a f3 0f 1e fa 55 48 89 e5 48 c7 45 f8 00 00 00 00 48 8b 45 f8 \u003cc7\u003e 00 02 00 00 00 b8 00 00 00 00 5d c3 66 0f 1f 84 00 00 00 00 00 此时可以根据 ip 000000000040111a 来定位出错的位置，ip 后面跟着的数字就是 IP 寄存器的值，也就是出错时的程序运行位置，可以通过 addr2line 来将其转换为文件名和行号 # 将地址转换为文件名和行号 # -f 选项表示输出函数名 # -e 选项表示指定可执行文件 $ addr2line -f -e ./test 0x000000000040111a main /home/ywang/test.c:5 然而 addr2line 也有两个较为明显的局限： 需要提前在编译时加上 -g 选项，生成 debug 信息 对于高版本的 gcc，需要加上 -no-pie 选项，避免 ASLR 的影响 ","date":"2023-09-09","objectID":"/posts/89f2ed7d/:2:1","tags":["日常踩坑","Debug","addr2line","gdb","objdump","assert","反汇编"],"title":"Debug 从入门到入土","uri":"/posts/89f2ed7d/"},{"categories":["日常踩坑"],"content":"objdump 反汇编 通过 objdump 进行反汇编也是一种比较常用的定位 segmentation fault 的方法，这种方法能够精确的定位到执行的汇编指令，并且没有 addr2line 的上述限制，但是需要一定的汇编基础，否则看不懂汇编指令也是没用的 汇编指令的快速查询可以直接 Google 或者在一些工具站，例如 【felixcloutier】 或者 【University of Virginia Computer Science】x86 Assembly Guide 上进行速查 以下面的代码为例： #include \u003cstdio.h\u003e void func_bug() { int *p = NULL; *p = 2; } int main() { int a = 1; func_bug(); return 0; } # 无需任何选项，直接编译 $ gcc test.c -o test # 运行程序，会出现 segmentation fault $ ./test [1] 8173 segmentation fault (core dumped) ./test # dmesg 查看内核日志，可以看到 segmentation fault 的详细信息 $ dmesg | tail -n 2 [49630.541707] test[8173]: segfault at 0 ip 000055bce6f6c13d sp 00007fffad5149b0 error 6 in test[55bce6f6c000+1000] [49630.541732] Code: 5d c3 0f 1f 00 c3 0f 1f 80 00 00 00 00 f3 0f 1e fa e9 77 ff ff ff f3 0f 1e fa 55 48 89 e5 48 c7 45 f8 00 00 00 00 48 8b 45 f8 \u003cc7\u003e 00 02 00 00 00 90 5d c3 f3 0f 1e fa 55 48 89 e5 48 83 ec 10 c7 由于没有关闭 ASLR，所以每次运行程序时，ip 的值都会不一样，但是可以简单的换算获取到实际偏移量 首先需要通过 objdump 获取 .init 段的起始地址，如下所示： # 获取 init 段的起始地址 $ objdump -h ./test -j .init ./test: file format elf64-x86-64 Sections: Idx Name Size VMA LMA File off Algn 10 .init 0000001b 0000000000001000 0000000000001000 00001000 2**2 CONTENTS, ALLOC, LOAD, READONLY, CODE 我们查看 VMA 列，可以看到 .init 段的起始地址为 0x1000（个人经验，如果不对，欢迎 dalao 指正） 计算偏移量 然后根据 dmesg 中的 ip 以及程序被映射的 VMA 首地址计算代码偏移量，也就是 ip 000055bce6f6c13d …… in test[55bce6f6c000+xxx]，计算出 0x55bce6f6c13d - 0x55bce6f6c000 = 0x13d，然后在加上 .init 段的起始地址 0x1000，就可以得到实际的偏移量 0x113d # 反汇编原程序 $ objdump -d ./test ./test: file format elf64-x86-64 Disassembly of section .init: 0000000000001000 \u003c_init\u003e: 1000: f3 0f 1e fa endbr64 1004: 48 83 ec 08 sub $0x8,%rsp 1008: 48 8b 05 d9 2f 00 00 mov 0x2fd9(%rip),%rax # 3fe8 \u003c__gmon_start__\u003e 100f: 48 85 c0 test %rax,%rax 1012: 74 02 je 1016 \u003c_init+0x16\u003e 1014: ff d0 callq *%rax 1016: 48 83 c4 08 add $0x8,%rsp 101a: c3 retq Disassembly of section .plt: 0000000000001020 \u003c.plt\u003e: 1020: ff 35 a2 2f 00 00 pushq 0x2fa2(%rip) # 3fc8 \u003c_GLOBAL_OFFSET_TABLE_+0x8\u003e 1026: f2 ff 25 a3 2f 00 00 bnd jmpq *0x2fa3(%rip) # 3fd0 \u003c_GLOBAL_OFFSET_TABLE_+0x10\u003e 102d: 0f 1f 00 nopl (%rax) Disassembly of section .plt.got: 0000000000001030 \u003c__cxa_finalize@plt\u003e: 1030: f3 0f 1e fa endbr64 1034: f2 ff 25 bd 2f 00 00 bnd jmpq *0x2fbd(%rip) # 3ff8 \u003c__cxa_finalize@GLIBC_2.2.5\u003e 103b: 0f 1f 44 00 00 nopl 0x0(%rax,%rax,1) Disassembly of section .text: 0000000000001040 \u003c_start\u003e: 1040: f3 0f 1e fa endbr64 1044: 31 ed xor %ebp,%ebp 1046: 49 89 d1 mov %rdx,%r9 1049: 5e pop %rsi 104a: 48 89 e2 mov %rsp,%rdx 104d: 48 83 e4 f0 and $0xfffffffffffffff0,%rsp 1051: 50 push %rax 1052: 54 push %rsp 1053: 4c 8d 05 86 01 00 00 lea 0x186(%rip),%r8 # 11e0 \u003c__libc_csu_fini\u003e 105a: 48 8d 0d 0f 01 00 00 lea 0x10f(%rip),%rcx # 1170 \u003c__libc_csu_init\u003e 1061: 48 8d 3d de 00 00 00 lea 0xde(%rip),%rdi # 1146 \u003cmain\u003e 1068: ff 15 72 2f 00 00 callq *0x2f72(%rip) # 3fe0 \u003c__libc_start_main@GLIBC_2.2.5\u003e 106e: f4 hlt 106f: 90 nop 0000000000001070 \u003cderegister_tm_clones\u003e: 1070: 48 8d 3d 99 2f 00 00 lea 0x2f99(%rip),%rdi # 4010 \u003c__TMC_END__\u003e 1077: 48 8d 05 92 2f 00 00 lea 0x2f92(%rip),%rax # 4010 \u003c__TMC_END__\u003e 107e: 48 39 f8 cmp %rdi,%rax 1081: 74 15 je 1098 \u003cderegister_tm_clones+0x28\u003e 1083: 48 8b 05 4e 2f 00 00 mov 0x2f4e(%rip),%rax # 3fd8 \u003c_ITM_deregisterTMCloneTable\u003e 108a: 48 85 c0 test %rax,%rax 108d: 74 09 je 1098 \u003cderegister_tm_clones+0x28\u003e 108f: ff e0 jmpq *%rax 1091: 0f 1f 80 00 00 00 00 nopl 0x0(%rax) 1098: c3 retq 1099: 0f 1f 80 00 00 00 00 nopl 0x0(%rax) 00000000000010a0 \u003cregister_tm_clones\u003e: 10a0: 48 8d 3d 69 2f 00 00 lea 0x2f69(%rip),%rdi # 4010 \u003c__TMC_END__\u003e 10a7: 48 8d 35 62 2f 00 00 lea 0x2f62(%rip),%rsi # 4010 \u003c__TMC_END__\u003e 10ae: 48 29 fe sub %rdi,%rsi 10b1: 48 89 f0 mov %rsi,%rax 10b4: 48 c1 ee 3f shr $0x3f,%rsi 10b8: 48 c1 f8 03 sar $0x3,%rax 10bc: 48 01 c6 add %rax,%rsi 10bf: 48 d1 fe sar %rsi 10c2: 74 14 je 10d8 \u003cregister_tm_clones+0x38\u003e 10c4: 48 8b 05 25 2f 00 00 mov 0x2f25(%rip),%rax # 3ff0 \u003c_ITM_registerTMCloneTable\u003e 10cb: 48 85 c0 test %rax,%rax 10ce: 74 08 je 10d8 \u003cregister_tm_clones+0x38\u003e 10d0","date":"2023-09-09","objectID":"/posts/89f2ed7d/:2:2","tags":["日常踩坑","Debug","addr2line","gdb","objdump","assert","反汇编"],"title":"Debug 从入门到入土","uri":"/posts/89f2ed7d/"},{"categories":["日常踩坑"],"content":"事中 为了更好的查看出错时的程序的各个变量值，可以借助最强工具 gdb 来进行调试运行 ","date":"2023-09-09","objectID":"/posts/89f2ed7d/:3:0","tags":["日常踩坑","Debug","addr2line","gdb","objdump","assert","反汇编"],"title":"Debug 从入门到入土","uri":"/posts/89f2ed7d/"},{"categories":["日常踩坑"],"content":"最强工具 gdb gdb 是 GNU 出品的一个强大的调试工具，可以用来调试多种语言的程序，例如 C/C++、Go、Rust 等 gdb 的使用方法非常多，这里只介绍一些常用的用法，更多的用法可以通过 man gdb 查看 同样需要在编译时加上 -g 选项，生成 debug 信息 以下面的代码为例： #include \u003cstdio.h\u003e void func_bug() { int *p = NULL; *p = 2; } int main(int argc, char *argv[]) { if (argc == 1) { printf(\"usage: %s arg1\\n\", argv[0]); return 0; } func_bug(); return 0; } 启动 # 通过 gdb 启动程序，只需将程序名作为参数传入即可 $ gdb ./test GNU gdb (Ubuntu 9.2-0ubuntu1~20.04.1) 9.2 Copyright (C) 2020 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later \u003chttp://gnu.org/licenses/gpl.html\u003e This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-linux-gnu\". Type \"show configuration\" for configuration details. For bug reporting instructions, please see: \u003chttp://www.gnu.org/software/gdb/bugs/\u003e. Find the GDB manual and other documentation resources online at: \u003chttp://www.gnu.org/software/gdb/documentation/\u003e. For help, type \"help\". Type \"apropos word\" to search for commands related to \"word\"... Reading symbols from ./test... (gdb) 此时就成功通过 gdb 启动了程序，如果被调试的程序需要参数，可以通过 set args 命令来设置参数，用法如下： # 设置参数 (gdb) set args arg1 arg2 ... 运行 gdb 启动程序后，并不会直接运行程序，而是需要手动输入 run 命令来运行程序 # 配置参数后运行程序 (gdb) set args a1 b2 c3 (gdb) run Starting program: /home/wangyu/test a1 b2 c3 Program received signal SIGSEGV, Segmentation fault. 0x000055555555515d in func_bug () at test.c:5 5 *p = 2; (gdb) 这时能非常清晰的看出出错的位置 查看变量 print 命令来查看变量的值，用法如下： # 查看变量 (gdb) print p $1 = (int *) 0x0 查看堆栈 bt 命令来查看堆栈，用法如下： # 查看堆栈 (gdb) bt #0 0x000055555555515d in func_bug () at test.c:5 #1 0x00005555555551ab in main (argc=4, argv=0x7fffffffe388) at test.c:13 配置断点 break 或者 b 命令来配置断点，用法如下： # 配置断点 (gdb) break func_bug Breakpoint 1 at 0x555555555149: file test.c, line 3. (gdb) break test.c:5 Breakpoint 2 at 0x555555555159: file test.c, line 5. 查看断点 info breakpoints 或者 info b 命令来查看断点，用法如下： # 查看断点 (gdb) info b Num Type Disp Enb Address What 1 breakpoint keep y 0x0000555555555149 in func_bug at test.c:3 2 breakpoint keep y 0x0000555555555159 in func_bug at test.c:5 删除断点 delete 或者 d 命令来删除断点，用法如下： # 删除断点 (gdb) d 2 (gdb) info b Num Type Disp Enb Address What 1 breakpoint keep y 0x0000555555555149 in func_bug at test.c:3 单步执行 next 或者 n 命令来单步执行，如果遇到函数调用，则不会进入函数内部 step 或者 s 命令来单步执行，如果遇到函数调用，则会进入函数内部 继续执行 continue 或者 c 命令来继续执行，直到遇到断点或者程序结束 打印源代码 list 或者 l 命令来打印源代码，用法如下： # 打印源代码 (gdb) l 1 #include \u003cstdio.h\u003e 2 3 void func_bug() { 4 int *p = NULL; 5 *p = 2; 6 } 7 8 int main(int argc, char *argv[]) { 9 if (argc == 1) { 10 printf(\"usage: %s arg1\\n\", argv[0]); 直接输入 l 命令会打印出当前断点所在的代码，也可以通过 l xxx 来打印指定的代码，xxx 可以是行号，也可以是函数名 ","date":"2023-09-09","objectID":"/posts/89f2ed7d/:3:1","tags":["日常踩坑","Debug","addr2line","gdb","objdump","assert","反汇编"],"title":"Debug 从入门到入土","uri":"/posts/89f2ed7d/"},{"categories":["日常踩坑"],"content":"事先 ","date":"2023-09-09","objectID":"/posts/89f2ed7d/:4:0","tags":["日常踩坑","Debug","addr2line","gdb","objdump","assert","反汇编"],"title":"Debug 从入门到入土","uri":"/posts/89f2ed7d/"},{"categories":["日常踩坑"],"content":"printf 虽然 printf 是最简单的调试方法，但是也是最常用的调试方法，基本上没有 printf 调试不出来的 bug 一般流程如下： 通常对于一般的 bug，可以先根据出错时的程序输出，大致估计出错的位置 然后在源代码中插入打印语句，重新编译，再次运行程序 继续观察打印的输出，一步步的缩小出错的范围，最终定位到出错的位置 然后就可以打印出错位置的相应变量的值，进而分析出错原因 缺点： 但是然而 printf 本身会造成程序的运行效率降低，有时会出现加了 printf 之后 bug 复现不了，去掉 printf 之后 bug 又复现了的情况 这种情况下就需要优化 printf 的方式，例如改用 sprintf 将内容输出到内存中，然后通过单独的线程 fprintf 转储到文件中，这样就会减少对程序的运行效率的影响 当然也可以换用后续的其他的调试方法 ","date":"2023-09-09","objectID":"/posts/89f2ed7d/:4:1","tags":["日常踩坑","Debug","addr2line","gdb","objdump","assert","反汇编"],"title":"Debug 从入门到入土","uri":"/posts/89f2ed7d/"},{"categories":["日常踩坑"],"content":"assert assert 是 C/C++ 中的一个宏，用于判断一个表达式是否为真，如果为假，则输出错误信息，并终止程序的运行 #include \u003cassert.h\u003e int main() { int a = 1; assert(a == 2); return 0; } 例如上述代码会输出如下错误信息，并终止程序的运行： test: test.c:5: main: Assertion `a == 2' failed. [1] 3563773 abort (core dumped) ./test 因此我们可以提前在一些可能出错的地方插入 assert 语句，当程序运行到这里时，如果 assert 语句不成立，则会输出错误信息，并终止程序的运行，从而快速定位到出错的原因 缺点： 与 printf 一样，assert 也会造成程序的运行效率稍微降低，但是一般不会影响到 bug 的复现 但是为了程序的运行效率，程序 release 版本的时候应该将 assert 语句去掉，或者利用宏定义，在 release 的时候将 assert 语句替换成空语句 例如： // #define DEBUG #ifdef DEBUG #define ASSERT(x) assert(x) #else #define ASSERT(x) #endif ","date":"2023-09-09","objectID":"/posts/89f2ed7d/:4:2","tags":["日常踩坑","Debug","addr2line","gdb","objdump","assert","反汇编"],"title":"Debug 从入门到入土","uri":"/posts/89f2ed7d/"},{"categories":["日常踩坑"],"content":"小节 通常情况下，我个人会在出错后根据程序的编译耗时来进行选择 debug 的方式 当程序编译耗时较短时，我会优先选择 printf 的方式来进行调试 而当程序编译耗时较长时，我会优先选择 objdump 的方式来进行判断，如果 objdump 无法快速定位到出错的位置，我会再选择 gdb 的方式来进行调试 ","date":"2023-09-09","objectID":"/posts/89f2ed7d/:5:0","tags":["日常踩坑","Debug","addr2line","gdb","objdump","assert","反汇编"],"title":"Debug 从入门到入土","uri":"/posts/89f2ed7d/"},{"categories":["日常踩坑"],"content":"参考资料 【man】addr2line 【man】objdump 【felixcloutier】 【University of Virginia Computer Science】x86 Assembly Guide 【个人博客】GDB调试指南 ","date":"2023-09-09","objectID":"/posts/89f2ed7d/:6:0","tags":["日常踩坑","Debug","addr2line","gdb","objdump","assert","反汇编"],"title":"Debug 从入门到入土","uri":"/posts/89f2ed7d/"},{"categories":["路由器"],"content":"本文主要记录个人对小米 WR30U 路由器的解锁和刷机过程，整体步骤与 一般安装流程 类似，但是由于 WR30U 的解锁 ssh 和刷机的过程中有一些细节需要注意，因此记录一下 ","date":"2023-08-21","objectID":"/posts/e6410576/:0:0","tags":["OpenWrt","BootLoader","ImmortalWrt"],"title":"小米 WR30U 解锁并刷机","uri":"/posts/e6410576/"},{"categories":["路由器"],"content":"解锁 ssh ","date":"2023-08-21","objectID":"/posts/e6410576/:1:0","tags":["OpenWrt","BootLoader","ImmortalWrt"],"title":"小米 WR30U 解锁并刷机","uri":"/posts/e6410576/"},{"categories":["路由器"],"content":"环境准备 需要一台同时具有 WiFi 和有线网络的电脑，以及一根网线 然后需要配置 python 环境，并且安装 pycryptodome 依赖 conda create -n wr30u conda activate wr30u conda install pycryptodome 然后是解锁脚本，可以直接从 PatriciaLee3 的仓库中下载 ","date":"2023-08-21","objectID":"/posts/e6410576/:1:1","tags":["OpenWrt","BootLoader","ImmortalWrt"],"title":"小米 WR30U 解锁并刷机","uri":"/posts/e6410576/"},{"categories":["路由器"],"content":"解锁过程 PatriciaLee3 的仓库中已经给出了详细的解锁过程，这里只是简单记录一下 电脑连接原厂固件的路由器，进入 192.168.31.1 的管理后台，在常用设置-上网设置里分别设置： 上网设置 DHCP，自动配置 DNS 启动与智能网关无线配置同步（会重启） 固定 WAN 口为 1（会重启） 电脑连接有正常网络的 WiFi，然后将网线连接到路由器的 WAN 口 打开 控制面板 - 网络和 Internet - 网络和共享中心 - 更改适配器设置 - 选择 WLAN - 右键属性 - 共享，勾选第一个并确认，这个时候 WR30U 会通过有线连接共享电脑的网络，并且网络指示灯会变成蓝色 打开 控制面板 - 系统和安全 - Windows Defender 防火墙 - 启动或关闭 Windows Defender 防火墙，关闭 Windows Defender 防火墙 运行解锁脚本，并按照脚本提示操作 conda activate wr30u python server_emulator.py 解锁完成后，路由器的账号密码为 root 和 admin，之后记得重新开启防火墙，并且关闭共享网络 ","date":"2023-08-21","objectID":"/posts/e6410576/:1:2","tags":["OpenWrt","BootLoader","ImmortalWrt"],"title":"小米 WR30U 解锁并刷机","uri":"/posts/e6410576/"},{"categories":["路由器"],"content":"刷入 mt798x uboot ","date":"2023-08-21","objectID":"/posts/e6410576/:2:0","tags":["OpenWrt","BootLoader","ImmortalWrt"],"title":"小米 WR30U 解锁并刷机","uri":"/posts/e6410576/"},{"categories":["路由器"],"content":"简介 这里首先推荐刷入 hanwckf 的 mt798x uboot，这个 uboot 有很多功能，其中以下两点非常实用： 【使用方便】自带 MTK 原厂开发的简易 WebUI 恢复界面，可以通过 WebUI 直接刷入固件或者更新 uboot 【兼容性好】支持多种 Flash 分区布局切换功能（仅支持 spi-nand），可以在 WebUI 中切换不同的分区布局，完美兼容小米原厂固件 ","date":"2023-08-21","objectID":"/posts/e6410576/:2:1","tags":["OpenWrt","BootLoader","ImmortalWrt"],"title":"小米 WR30U 解锁并刷机","uri":"/posts/e6410576/"},{"categories":["路由器"],"content":"刷入流程 电脑接入正常网络，然后去 hanwckf 的仓库 release 页面下载对应的 uboot 文件：mt7981_wr30u-fip-fixed-parts-multi-layout.bin 电脑接入路由器网络，通过 scp 将 uboot 传到路由器上 scp mt7981_wr30u-fip-fixed-parts-multi-layout.bin root@192.168.31.1:/tmp 通过 ssh 登录路由器，查看布局 # on PC ssh root@192.168.31.1 # on Router # 查看当前分区布局 cat /proc/mtd 默认布局如下: dev: size erasesize name mtd0: 08000000 00020000 \"spi0.0\" mtd1: 00100000 00020000 \"BL2\" mtd2: 00040000 00020000 \"Nvram\" mtd3: 00040000 00020000 \"Bdata\" mtd4: 00200000 00020000 \"Factory\" mtd5: 00200000 00020000 \"FIP\" mtd6: 00040000 00020000 \"crash\" mtd7: 00040000 00020000 \"crash_log\" mtd8: 02200000 00020000 \"ubi\" mtd9: 02200000 00020000 \"ubi1\" mtd10: 02000000 00020000 \"overlay\" mtd11: 00c00000 00020000 \"data\" mtd12: 00040000 00020000 \"KF\" 如果需要备份，可以通过 nanddump 命令备份，之后通过 scp 将备份的文件传到电脑上 # on Router nanddump -f /tmp/BL2.bin /dev/mtd1 nanddump -f /tmp/Nvram.bin /dev/mtd2 nanddump -f /tmp/Bdata.bin /dev/mtd3 nanddump -f /tmp/Factory.bin /dev/mtd4 nanddump -f /tmp/FIP.bin /dev/mtd5 nanddump -f /tmp/ubi.bin /dev/mtd8 nanddump -f /tmp/KF.bin /dev/mtd12 # on PC scp root@192.168.31.1:/tmp/*.bin . 然后将 uboot 刷入 FIP 分区，之后关机 # on Router mtd write /tmp/mt7981_wr30u-fip-fixed-parts-multi-layout.bin FIP poweroff ","date":"2023-08-21","objectID":"/posts/e6410576/:2:2","tags":["OpenWrt","BootLoader","ImmortalWrt"],"title":"小米 WR30U 解锁并刷机","uri":"/posts/e6410576/"},{"categories":["路由器"],"content":"刷入 ImmortalWrt ","date":"2023-08-21","objectID":"/posts/e6410576/:3:0","tags":["OpenWrt","BootLoader","ImmortalWrt"],"title":"小米 WR30U 解锁并刷机","uri":"/posts/e6410576/"},{"categories":["路由器"],"content":"简介 ImmortalWrt 是 OpenWrt 的一个分支，相比于 OpenWrt 有更多的软件包以及设备支持，并且对中国大陆用户有特殊优化 ","date":"2023-08-21","objectID":"/posts/e6410576/:3:1","tags":["OpenWrt","BootLoader","ImmortalWrt"],"title":"小米 WR30U 解锁并刷机","uri":"/posts/e6410576/"},{"categories":["路由器"],"content":"刷入流程 电脑连接正常网络，去官网下载 Sysupgrade 固件 这里选择了 custom U-Boot layout 的固件，也就是 112M UBI layout 的固件，这样可以有更多的空间用于安装软件包，固件名格式为 immortalwrt-xxxxxx-mediatek-filogic-xiaomi_mi-router-wr30u-112m-nmbm-squashfs-sysupgrade.bin 针按住 reset 不放，再接上电源，等待 10s 左右松开，路由器的系统灯变蓝后就是成功进入 uboot 了 因 uboot 不支持 DHCP 功能，需要把电脑的 IP 地址设置成固定 IP： 电脑通过网线连接路由器，然后在网络设置里将以太网设置为静态，IP地址：192.168.31.100，子网掩码：255.255.255.0，网关：192.168.31.1，首选 DNS：192.168.31.1，最后保存 直接访问 WebUI 进行刷固件，将 layout 选为 immortalwrt-112m，然后上传前面下载的固件，点击刷机即可 ![layout 选择](layout 选择.png) ","date":"2023-08-21","objectID":"/posts/e6410576/:3:2","tags":["OpenWrt","BootLoader","ImmortalWrt"],"title":"小米 WR30U 解锁并刷机","uri":"/posts/e6410576/"},{"categories":["路由器"],"content":"刷为原厂固件 刷回原厂固件的过程与刷入 ImmortalWrt 类似，只是需要下载原厂固件，然后在 WebUI 中将 layout 配置为 default，之后上传原厂固件刷机即可 ","date":"2023-08-21","objectID":"/posts/e6410576/:4:0","tags":["OpenWrt","BootLoader","ImmortalWrt"],"title":"小米 WR30U 解锁并刷机","uri":"/posts/e6410576/"},{"categories":["路由器"],"content":"参考资料 【个人博客】酱紫表 - 小米 WR30U 解锁 SSH 刷 openwrt，最有性价比的百元路由器 【GitHub】wr30u_ssh 【个人博客】hanwckf - mt798x uboot 功能介绍 【ImmortalWrt】固件下载 ","date":"2023-08-21","objectID":"/posts/e6410576/:5:0","tags":["OpenWrt","BootLoader","ImmortalWrt"],"title":"小米 WR30U 解锁并刷机","uri":"/posts/e6410576/"},{"categories":["Linux"],"content":"本文主要记录个人使用 Ubuntu 中遇到的各种琐碎问题的解决方法，以及环境配置 ","date":"2022-11-24","objectID":"/posts/72a4cdfd/:0:0","tags":["nano","vim","perl","timedatectl","VNC"],"title":"Ubuntu 环境配置大合集","uri":"/posts/72a4cdfd/"},{"categories":["Linux"],"content":"修改默认编辑器为 vim 一般 Ubuntu 的默认编辑器是 nano，用起来非常不顺手，可以通过下面命令修改 sudo update-alternatives --config editor # 然后选择为 vim.basic 即可 ","date":"2022-11-24","objectID":"/posts/72a4cdfd/:1:0","tags":["nano","vim","perl","timedatectl","VNC"],"title":"Ubuntu 环境配置大合集","uri":"/posts/72a4cdfd/"},{"categories":["Linux"],"content":"解决报错 perl: warning: Setting locale failed vim .bashrc # vim .zshrc # 新增以下内容 export LC_ALL=\"en_US.UTF-8\" 然后重新登录 shell 或者手动执行一下 export LC_ALL=\"en_US.UTF-8\" 然后再执行 sudo locale-gen en_US.UTF-8 sudo dpkg-reconfigure locales # 配置过程中选择 en_US.UTF-8 一路确定即可 ","date":"2022-11-24","objectID":"/posts/72a4cdfd/:2:0","tags":["nano","vim","perl","timedatectl","VNC"],"title":"Ubuntu 环境配置大合集","uri":"/posts/72a4cdfd/"},{"categories":["Linux"],"content":"配置时区 Ubuntu 默认时间是 UTC 时间，可以通过修改时区来显示本地的时间 # 查看当前时区 timedatectl # 不知道时区名可以通过 tzselect 获取 tzselect # 配置当前时区为 Asia/Shanghai sudo timedatectl set-timezone Asia/Shanghai ","date":"2022-11-24","objectID":"/posts/72a4cdfd/:3:0","tags":["nano","vim","perl","timedatectl","VNC"],"title":"Ubuntu 环境配置大合集","uri":"/posts/72a4cdfd/"},{"categories":["Linux"],"content":"远程 VNC 服务器 # Ubuntu 22.04 sudo apt install tigervnc-standalone-server tigervnc-common # 初次启动并配置 vncserver # 关闭已开启的第一个实例 vncserver -kill :1 # 可能需要开启相应端口 sudo ufw allow 5901 # 取消只能本地连接的限制 vncserver -localhost no 客户端 在 Windows 直接下载 VNC Viewer 配置好相应的 IP 以及端口即可 ","date":"2022-11-24","objectID":"/posts/72a4cdfd/:4:0","tags":["nano","vim","perl","timedatectl","VNC"],"title":"Ubuntu 环境配置大合集","uri":"/posts/72a4cdfd/"},{"categories":["Linux"],"content":"参考资料 【man】update-alternatives 【stackoverflow】How to fix a locale setting warning from Perl 【linuxhint】timedatectl 【myfreax】如何在 Ubuntu 22.04 安装 VNC ","date":"2022-11-24","objectID":"/posts/72a4cdfd/:5:0","tags":["nano","vim","perl","timedatectl","VNC"],"title":"Ubuntu 环境配置大合集","uri":"/posts/72a4cdfd/"},{"categories":["测试"],"content":"本文主要记录自己在利用 RocksDB + ZenFS 测试 ZNS 过程中遇到的一些问题以及相应的解决办法 ","date":"2022-11-22","objectID":"/posts/b8506868/:0:0","tags":["日常踩坑","RocksDB","ZNS","QEMU","grub"],"title":"利用 RocksDB + ZenFS 测试 ZNS 的环境搭建和使用","uri":"/posts/b8506868/"},{"categories":["测试"],"content":"配置 ZNS 环境 ZNS 全称 Zoned Namespaces，中文一般译为分区命名空间，当今最常见的 ZNS 设备类型是基于闪存的 SSD。但是 ZNS SSD 目前还没有在消费级市场出货，只能通过软件模拟来搭建环境 ","date":"2022-11-22","objectID":"/posts/b8506868/:1:0","tags":["日常踩坑","RocksDB","ZNS","QEMU","grub"],"title":"利用 RocksDB + ZenFS 测试 ZNS 的环境搭建和使用","uri":"/posts/b8506868/"},{"categories":["测试"],"content":"配置 FEMU 官网给了 null_blk 以及 QEMU 的配置方法，但是个人对 FEMU 比较熟悉，可以理解成 QEMU 的 fork，支持模拟固态盘内部固件逻辑，于是采用 FEMU 模拟 ZNS 搭建环境 FEMU 的环境搭建比较简单，参考其 官方仓库 README 操作即可 **容易踩坑：**但是需要注意 ZNS 对 Linux 内核版本有要求，必须在 5.10 以上，因此推荐安装 Ubuntu 22.04 LTS。 不建议手动更新内核，过程复杂耗时，而且（sudo make headers_install 安装内核用户头文件过程中）存在一定的风险性 ","date":"2022-11-22","objectID":"/posts/b8506868/:1:1","tags":["日常踩坑","RocksDB","ZNS","QEMU","grub"],"title":"利用 RocksDB + ZenFS 测试 ZNS 的环境搭建和使用","uri":"/posts/b8506868/"},{"categories":["测试"],"content":"QEMU 制作和安装系统镜像 # 下载 Ubuntu 镜像 wget https://releases.ubuntu.com/22.04.1/ubuntu-22.04.1-live-server-amd64.iso # 制作磁盘镜像 qemu-img create -f qcow2 u22s.qcow2 80G # ubuntu 镜像挂在 cdrom 上启动 # 安装过程需要通过 vnc 连接操作，端口号 5901 qemu-system-x86_64 -m 2G -cdrom ubuntu-22.04.1-live-server-amd64.iso -hda u22s.qcow2 -boot d -vnc :1 # 安装完成后重启，再 vnc 连接一次，修改内核启动参数 qemu-system-x86_64 -m 2G -hda u22s.qcow2 -vnc :1 然后在虚拟内将内核启动时输出改为打印到串口 # 在虚拟机内 sudo vim /etc/default/grub 保证按照下面的配置 # 用于保证 grub 界面能输出到屏幕 #GRUB_TIMEOUT_STYLE=hidden GRUB_TIMEOUT=3 GRUB_TERMINAL=serial # 用于保证内核启动时能输出到屏幕 GRUB_CMDLINE_LINUX=\"ip=dhcp console=ttyS0,115200\" # (可选)屏蔽子菜单和 recovery 内核，方便快速切换内核 GRUB_DISABLE_SUBMENU=y GRUB_DISABLE_RECOVERY=\"true\" 然后更新重启即可 # 更新 grub sudo update-grub # sudo update-grub2 sudo poweroff 之后就可以不需要 vnc 连接了，可以加上 -nographic 使用了，例如 # 举例 qemu-system-x86_64 -enable-kvm -cpu host -smp=16 -m 4G -hda u22s.qcow2 -nographic ","date":"2022-11-22","objectID":"/posts/b8506868/:1:2","tags":["日常踩坑","RocksDB","ZNS","QEMU","grub"],"title":"利用 RocksDB + ZenFS 测试 ZNS 的环境搭建和使用","uri":"/posts/b8506868/"},{"categories":["测试"],"content":"配置 RocksDB 环境 RocksDB 官方仓库的 Wiki 有较为详细的安装指导 ","date":"2022-11-22","objectID":"/posts/b8506868/:2:0","tags":["日常踩坑","RocksDB","ZNS","QEMU","grub"],"title":"利用 RocksDB + ZenFS 测试 ZNS 的环境搭建和使用","uri":"/posts/b8506868/"},{"categories":["测试"],"content":"环境以及依赖安装 以 Ubuntu 为例： **容易踩坑：**一定要记得按照顺序来，先安装好所有依赖再编译 # 基本的编译工具等不过多介绍 # sudo apt install build-essential # sudo apt install pkg-config # gflags sudo apt install libgflags-dev # 压缩库，选一个就行 sudo apt install libsnappy-dev # sudo apt install zlib1g-dev # sudo apt install libbz2-dev # sudo apt install liblz4-dev # sudo apt install libzstd-dev ","date":"2022-11-22","objectID":"/posts/b8506868/:2:1","tags":["日常踩坑","RocksDB","ZNS","QEMU","grub"],"title":"利用 RocksDB + ZenFS 测试 ZNS 的环境搭建和使用","uri":"/posts/b8506868/"},{"categories":["测试"],"content":"编译 RocksDB 库以及测试工具 如果要在 ZNS 上测试，可以暂时跳过该小节，等配置好 ZenFS 后再进行 如果要用 YCSB 来测试，就需要编译 Java 版本的 jar 包，具体过程可以参考 这篇博文 用 db_bench 测试就直接 make db_bench 即可，可以加上 DEBUG_LEVEL=0 保证编译成 release 版本 # 编译测试工具 DEBUG_LEVEL=0 make -j db_bench # 安装编译好的 RocksDB 库 sudo make install **容易踩坑：**如果 -j 会全核一起编译，在核多内存少的情况下可能会报内存资源不足的错误，可以参考 这篇博客 利用 swap “增加”可用内存大小，或者限制下编译的并发度，例如 -j8 利用 db_bench 测试可以参考 官方测试 的方式，利用 benchmark.sh 来测试，当然也可以直接运行 db_bench ","date":"2022-11-22","objectID":"/posts/b8506868/:2:2","tags":["日常踩坑","RocksDB","ZNS","QEMU","grub"],"title":"利用 RocksDB + ZenFS 测试 ZNS 的环境搭建和使用","uri":"/posts/b8506868/"},{"categories":["测试"],"content":"配置 ZenFS 环境 ZenFS 官方仓库其实给了相应的指导，这里重新梳理下 ","date":"2022-11-22","objectID":"/posts/b8506868/:3:0","tags":["日常踩坑","RocksDB","ZNS","QEMU","grub"],"title":"利用 RocksDB + ZenFS 测试 ZNS 的环境搭建和使用","uri":"/posts/b8506868/"},{"categories":["测试"],"content":"安装 libzbd # 安装编译工具 sudo apt install m4 sudo apt install autoconf sudo apt install automake sudo apt install libtool # 拉取源码 # git clone https://github.com/westerndigitalcorporation/libzbd.git git clone git@github.com:westerndigitalcorporation/libzbd.git # 编译 cd libzbd sh ./autogen.sh ./configure make # 安装 sudo make install ","date":"2022-11-22","objectID":"/posts/b8506868/:3:1","tags":["日常踩坑","RocksDB","ZNS","QEMU","grub"],"title":"利用 RocksDB + ZenFS 测试 ZNS 的环境搭建和使用","uri":"/posts/b8506868/"},{"categories":["测试"],"content":"ZenFS 插件编译 然后需要切换回 RocksDB 的目录，将 ZenFS 加入其中进行编译 # 拉取源码 # git clone https://github.com/facebook/rocksdb.git # git clone git@github.com:facebook/rocksdb.git cd rocksdb # git clone https://github.com/westerndigitalcorporation/zenfs plugin/zenfs git clone git@github.com:westerndigitalcorporation/zenfs plugin/zenfs # 编译测试工具 DEBUG_LEVEL=0 ROCKSDB_PLUGINS=zenfs make -j db_bench # 安装编译好的 RocksDB 库 sudo DEBUG_LEVEL=0 ROCKSDB_PLUGINS=zenfs make install # 编译必要的 ZenFS 工具 cd plugin/zenfs/util make -j 至此所有测试需要的环境已经基本搭建好了 ","date":"2022-11-22","objectID":"/posts/b8506868/:3:2","tags":["日常踩坑","RocksDB","ZNS","QEMU","grub"],"title":"利用 RocksDB + ZenFS 测试 ZNS 的环境搭建和使用","uri":"/posts/b8506868/"},{"categories":["测试"],"content":"测试 接下来简单介绍下测试过程，假设 ZNS 固态盘的设备名为 nvme1n1 ","date":"2022-11-22","objectID":"/posts/b8506868/:4:0","tags":["日常踩坑","RocksDB","ZNS","QEMU","grub"],"title":"利用 RocksDB + ZenFS 测试 ZNS 的环境搭建和使用","uri":"/posts/b8506868/"},{"categories":["测试"],"content":"利用 zenfs 的测试脚本测试 zenfs 内置了一个测试脚本，只需指定设备名。脚本会设置 IO 调度器，制作文件系统以及自动配置 RocksDB 参数，但是参数配置的不够合理，需要自行修改 cd rocksdb sudo ./plugin/zenfs/tests/zenfs_base_performance.sh nvme1n1 该脚本会运行多个测试，而且每个测试会运行多个不同的 value 大小，运行时间较长，最后的测试结果汇总在 results/zenfs-nvme1n1-baseline_performance 目录下 ","date":"2022-11-22","objectID":"/posts/b8506868/:4:1","tags":["日常踩坑","RocksDB","ZNS","QEMU","grub"],"title":"利用 RocksDB + ZenFS 测试 ZNS 的环境搭建和使用","uri":"/posts/b8506868/"},{"categories":["测试"],"content":"直接 db_bench 测试 首先配置底层 IO 调度器为 mq-deadline 用户保持有序性（因为 ZNS 只支持追加写 echo mq-deadline | sudo tee /sys/block/nvme1n1/queue/scheduler 容易踩坑：利用 zenfs 创建 ZenFS 文件系统，其中 zbd 后直接给出设备名即可，不需要给出设备路径；而且需要指定 aux_path 用于存放 LOG 和 LOCK 文件，推荐放在非 ZNS 设备上，并且使用绝对路径 cd ~ mkdir zenfs-aux cd rocksdb sudo ./plugin/zenfs/util/zenfs mkfs --zbd=nvme1n1 --aux-path=/home/femu/zenfs-aux 制作好文件系统后，就可以用 db_bench 进行测试了 cd rocksdb sudo ./db_bench --fs_uri=zenfs://dev:nvme1n1 --benchmarks=fillrandom --use_direct_io_for_flush_and_compaction ","date":"2022-11-22","objectID":"/posts/b8506868/:4:2","tags":["日常踩坑","RocksDB","ZNS","QEMU","grub"],"title":"利用 RocksDB + ZenFS 测试 ZNS 的环境搭建和使用","uri":"/posts/b8506868/"},{"categories":["测试"],"content":"参考资料 【GitHub】RocksDB 【GitHub】ZenFS 【zonedstorage】ZNS 【GitHub】FEMU 【QEMU】QEMU User Documentation 【Wikibooks】QEMU/Images 【QEMU】Direct Linux Boot 【ask ubuntu】How to get to the GRUB menu at boot-time using serial console? 【CSDN】问题解决 C++: fatal error: Killed signal terminated program cc1plus 【GitHub】libzbd ","date":"2022-11-22","objectID":"/posts/b8506868/:5:0","tags":["日常踩坑","RocksDB","ZNS","QEMU","grub"],"title":"利用 RocksDB + ZenFS 测试 ZNS 的环境搭建和使用","uri":"/posts/b8506868/"},{"categories":["软件配置"],"content":"本文主要来源于 VCB-Studio 官网的 科普教程，个人重新梳理进行备份 ","date":"2022-11-16","objectID":"/posts/3b7ae835/:0:0","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"安装程序 1、安装 PotPlayer 和 LAV Filters 二者都是普通的 exe 安装包，双击启动安装即可，安装过程中可以全默认 2、安装 madVR 和 xy-SubFilter 二者都是插件，推荐将其解压到单独的文件夹中，然后移动至 Potplayer 目录下，最后以管理员权限运行其中的安装脚本 install.bat ","date":"2022-11-16","objectID":"/posts/3b7ae835/:1:0","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"显卡驱动配置 首先解锁显卡驱动上的色彩管理范围和显示器输出配置，打开【NVIDIA 控制面板】，参考下图进行配置 其他显卡配置类似，这里略去 ","date":"2022-11-16","objectID":"/posts/3b7ae835/:2:0","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"配置 Potplayer 首先我们来看一下最终目标，用 PotPlayer 随便打开一个视频，按一下 Tab 键，即可调出 Potplayer 自带的 OSD 菜单，红框中的内容是配置完成后的最佳配置 下面我们一步一步进行配置 ","date":"2022-11-16","objectID":"/posts/3b7ae835/:3:0","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"关闭 Potplayer 内置滤镜 在播放视频（暂停也可以）时 右键-选项，或者直接 F5 快捷键，进入 选项 菜单 切至 滤镜 选项卡，关闭 Pot 内置滤镜 ","date":"2022-11-16","objectID":"/posts/3b7ae835/:3:1","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"添加 LAV 滤镜/解码器 切至 滤镜-源滤镜/分离器 选项卡，点击 滤镜/解码器管理 ![添加 LAV 滤镜、解码器-1](添加 LAV 滤镜、解码器-1.png) 在新窗口中，点击 搜索后添加 后确认 LAV 的相关滤镜、解码器已被勾选，然后点击 确定 ![添加 LAV 滤镜、解码器-2](添加 LAV 滤镜、解码器-2.png) ","date":"2022-11-16","objectID":"/posts/3b7ae835/:3:2","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"分离器 切至 滤镜-源滤镜/分离器 选项卡 ，将右侧的所有选项都换成 LAV Splitter Source，无法切换的就保持原状，列表较长，记得滚轮翻页 ","date":"2022-11-16","objectID":"/posts/3b7ae835/:3:3","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"视频解码器 切至 滤镜-视频解码器 选项卡，将右侧的所有选项都换成 LAV Video Decoder，无法切换为 LAV 的就保持原状，列表较长，记得滚轮翻页 ","date":"2022-11-16","objectID":"/posts/3b7ae835/:3:4","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"视频渲染器 切至 视频 选项卡，设置视频渲染方式，选择 Madshi 视频渲染，也就是 madVR ","date":"2022-11-16","objectID":"/posts/3b7ae835/:3:5","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"音频解码器 切至 滤镜-音频解码器 选项卡 ，将右侧的所有选项都换成 LAV Audio Decoder，无法切换的就保持原状，列表较长，记得滚轮翻页 ","date":"2022-11-16","objectID":"/posts/3b7ae835/:3:6","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"音频渲染器 切至 声音 选项卡，设置音频渲染方式，选择 内置 WSAPI 音频渲染器 ","date":"2022-11-16","objectID":"/posts/3b7ae835/:3:7","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"其他 调教进度条 切至 播放 选项卡，开始调教进度条，将进度条的相关配置全开启 关闭音频规格化 切至 声音-规格化/混响 选项卡，关闭音频规格化，避免 potplayer 乱改音量 启用 xy-SubFilter 切至 滤镜-个人滤镜优先权 选项卡，点击 添加系统滤镜 在新窗口中，选中 xy-SubFilter 的相关滤镜，然后点击 确定 优先级设置上，将 XySubFilterAutoLoader 设为强制使用，负责外挂字幕； XySubFilter 设为按优先级使用，负责内挂字幕 所有配置完成后记得点击 应用 和 确定 按钮保存当前配置 ","date":"2022-11-16","objectID":"/posts/3b7ae835/:3:8","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"配置 LAV Filters 在播放视频（暂停也可以）时 右键-属性，或者直接 Ctrl+F1 快捷键，进入 属性 菜单 点击红色框就能进入视频/音频解码器设置界面 ","date":"2022-11-16","objectID":"/posts/3b7ae835/:4:0","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"LAV 视频解码器 视频解码器保持 LAV 默认设置即可，也就是勾选除了 AYUV 以外的所有选项；RGB Output Level 选 PC；Dither Mode 选 Random；Hardware Decoder to use 选 None ![LAV 视频解码器](LAV 视频解码器.png) ","date":"2022-11-16","objectID":"/posts/3b7ae835/:4:1","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"LAV 音频解码器 在音频解码器中，切换至 Mixing 标签，勾上 Enable Mixing 即可 ![LAV 音频解码器](LAV 音频解码器.png) ","date":"2022-11-16","objectID":"/posts/3b7ae835/:4:2","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"配置 madVR madVR 个人没有折腾，直接用默认配置 ","date":"2022-11-16","objectID":"/posts/3b7ae835/:5:0","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"使用 xy-SubFilter 由于 Potplayer 内置了字幕插件，加上我们选择 xy-SubFilter 来处理字幕，所以需要关闭 Potplayer 内置字幕插件，否则就会出现两行字幕 可以通过快捷键 ALt+H 快速开关内置字幕 而 xy-SubFilter 的字幕选择和开关则需要要在桌面右下角小图标右键进行切换 ","date":"2022-11-16","objectID":"/posts/3b7ae835/:6:0","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"其他问题 ","date":"2022-11-16","objectID":"/posts/3b7ae835/:7:0","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"倍数播放字幕异常 通过 x、c 快捷键调整倍数播放之后发现，字幕显示速度没变，经过一番搜索在 Anime 字幕论坛的 一篇帖子 里面找到了解决办法：直接 Shift+X 开关声音处理滤镜即可 ","date":"2022-11-16","objectID":"/posts/3b7ae835/:7:1","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["软件配置"],"content":"参考资料 【PotPlayer 官网】 【GitHub】LAV Filters 【madVR 官网】 【GitHub】xy-SubFilter 【VCB-Studio 官网】科普教程 2.2——基于 PotPlayer 和 madVR 的播放器教程（已更新 XySubFilter） 【Anime 字幕论坛】倍速播放 【个人博客】视频播放器使用教程 ","date":"2022-11-16","objectID":"/posts/3b7ae835/:8:0","tags":["Potplayer"],"title":"Windows 平台最强播放器组合 —— Potplayer + LAV Filters + madVR + xy-SubFilter","uri":"/posts/3b7ae835/"},{"categories":["Shell"],"content":"简介 PowerShell 是 Windows 最新的 Shell，而且在 GitHub 上开源并且提供了跨平台支持（虽然估计没哪个 Linux 用户会选择 PowerShell 为了美化 PowerShell，个人选择了 Oh My Posh。Oh My Posh 是一个开源的主体的框架，支持 PowerShell、CMD、Zsh、Bash、Fish 等多种 Shell 本文主要记录自己的 Oh My Posh 安装以及配置流程 ","date":"2022-11-16","objectID":"/posts/8ad4716e/:1:0","tags":["PowerShell","Windows"],"title":"美化 Shell 之 Windows/Linux PowerShell 篇","uri":"/posts/8ad4716e/"},{"categories":["Shell"],"content":"安装最新的 PowerShell Windows 默认安装的 PowerShell 版本太旧，所以先通过 winget 安装最新的版本 # winget search Microsoft.PowerShell winget install --id Microsoft.Powershell --source winget ","date":"2022-11-16","objectID":"/posts/8ad4716e/:2:0","tags":["PowerShell","Windows"],"title":"美化 Shell 之 Windows/Linux PowerShell 篇","uri":"/posts/8ad4716e/"},{"categories":["Shell"],"content":"安装 Oh My Posh 通过 winget 一键安装 Oh My Posh 即可 winget install JanDeDobbeleer.OhMyPosh -s winget ","date":"2022-11-16","objectID":"/posts/8ad4716e/:3:0","tags":["PowerShell","Windows"],"title":"美化 Shell 之 Windows/Linux PowerShell 篇","uri":"/posts/8ad4716e/"},{"categories":["Shell"],"content":"安装 Nerd 字体 Nerd 字体 其实只是在原本的开源字体上增加了一些图标（包括 PowerLine 所需的符号），而 Oh My Posh 中大多数主体都需要 Nerd 字体 直接在 官网 或者 GitHub 的 Release 中下载自己常用字体的压缩包，解压后直接打开 ttf 文件安装即可 个人习惯用 Cascadia Code、FiraCode 字体的启用与 Shell 的运行程序相关，需要在 VSCode 或者 Windows Terminal 应用中单独配置，这里不做介绍 ","date":"2022-11-16","objectID":"/posts/8ad4716e/:4:0","tags":["PowerShell","Windows"],"title":"美化 Shell 之 Windows/Linux PowerShell 篇","uri":"/posts/8ad4716e/"},{"categories":["Shell"],"content":"启用 Oh My Posh 启用 Oh My Posh 需要修改配置文件，通过 notepad 直接打开配置文件 notepad $PROFILE 如果打开报错，则需要首先创建配置文件 New-Item -Path $PROFILE -Type File -Force 在配置文件中添加以下内容，以后启动 PowerShell 就会自动启用 Oh My Posh 了 oh-my-posh init pwsh | Invoke-Expression ","date":"2022-11-16","objectID":"/posts/8ad4716e/:5:0","tags":["PowerShell","Windows"],"title":"美化 Shell 之 Windows/Linux PowerShell 篇","uri":"/posts/8ad4716e/"},{"categories":["Shell"],"content":"选择主题 Oh My Posh 支持非常丰富的主题，而且只需一行命令就可以直接在 Shell 预览 Get-PoshThemes 个人选择了 powerlevel10k_rainbow 主题，修改主题需要修改之前的配置文件，将之前内容进行修改即可，配置完成后需要重启终端~ notepad $PROFILE oh-my-posh init pwsh --config \"$env:POSH_THEMES_PATH/powerlevel10k_rainbow.omp.json\" | Invoke-Expression ","date":"2022-11-16","objectID":"/posts/8ad4716e/:6:0","tags":["PowerShell","Windows"],"title":"美化 Shell 之 Windows/Linux PowerShell 篇","uri":"/posts/8ad4716e/"},{"categories":["Shell"],"content":"参考资料 【ohmyposh】Oh My Posh 官网 【GitHub】Oh My Posh 仓库 【Microsoft】Installing PowerShell on Windows 【ohmyposh】Installation-Windows 【ohmyposh】Fonts 【ohmyposh】Prompt ","date":"2022-11-16","objectID":"/posts/8ad4716e/:7:0","tags":["PowerShell","Windows"],"title":"美化 Shell 之 Windows/Linux PowerShell 篇","uri":"/posts/8ad4716e/"},{"categories":["Linux","Shell"],"content":"简介 Z shell（Zsh）是一款可用作互动式登入的shell及指令码编写的命令直译器。 Zsh 对 Linux 默认的 Bourne shell（sh）做出了大量改进，同时加入了 Bash、ksh 及 tcsh 的某些功能。 并且自 2019 年起，macOS 的预设 Shell 已从 Bash 改为 Zsh 为了美化以及快速配置 Zsh，Oh My Zsh 应运而生。 Oh My Zsh 是一个开源的、社区驱动的框架，支持各种插件以及主题，在管理 Zsh 配置提供了很大的便利 本文主要记录自己的 Oh My Zsh 安装以及配置流程 ","date":"2022-11-16","objectID":"/posts/f2cdf8a6/:1:0","tags":["Linux","Shell","Zsh"],"title":"美化 Shell 之 Linux Zsh 篇","uri":"/posts/f2cdf8a6/"},{"categories":["Linux","Shell"],"content":"安装 Zsh 如果没有安装 Zsh 则需要手动安装一下，以 Ubuntu 为例： sudo apt install zsh 配置 Zsh 为默认 Shell chsh -s $(which zsh) ","date":"2022-11-16","objectID":"/posts/f2cdf8a6/:2:0","tags":["Linux","Shell","Zsh"],"title":"美化 Shell 之 Linux Zsh 篇","uri":"/posts/f2cdf8a6/"},{"categories":["Linux","Shell"],"content":"安装 Oh My Zsh 通过 curl 或者 wget 下载安装脚本一键安装 Oh My Zsh 即可 # curl sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" # wget sh -c \"$(wget -O- https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" 类似于 bash 的配置文件 ~/.bashrc 命名规则类似，Zsh 的配置文件是 ~/.zshrc，后续配置只需对该配置文件进行小小的修改即可 ","date":"2022-11-16","objectID":"/posts/f2cdf8a6/:3:0","tags":["Linux","Shell","Zsh"],"title":"美化 Shell 之 Linux Zsh 篇","uri":"/posts/f2cdf8a6/"},{"categories":["Linux","Shell"],"content":"主题配置 Oh My Zsh 支持非常丰富的主题，官方 给出了内置的所有主题的预览图 部分主题需要额外 PL 字体 以及 Nerd 字体 支持，参见 [安装 Nerd 字体](/posts/8ad4716e/#安装 Nerd 字体) 由于在 Oh My Posh 中用习惯了 powerlevel10k，并且 powerlevel10k 也支持 Oh My Zsh，于是后来又额外安装了 powerlevel10k 主题 安装流程也很方便，直接从 GitHub 拉取仓库，然后修改配置文件即可 git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k vim ~/.zshrc ZSH_THEME=\"powerlevel10k/powerlevel10k\" 之后重启终端后，powerlevel10k 会进入引导流程，可以自行微调风格 ","date":"2022-11-16","objectID":"/posts/f2cdf8a6/:4:0","tags":["Linux","Shell","Zsh"],"title":"美化 Shell 之 Linux Zsh 篇","uri":"/posts/f2cdf8a6/"},{"categories":["Linux","Shell"],"content":"插件安装 Oh My Zsh 默认会开启 git 插件，除此之外个人还额外安装了 zsh-autosuggestions 以及 zsh-syntax-highlighting 插件 ","date":"2022-11-16","objectID":"/posts/f2cdf8a6/:5:0","tags":["Linux","Shell","Zsh"],"title":"美化 Shell 之 Linux Zsh 篇","uri":"/posts/f2cdf8a6/"},{"categories":["Linux","Shell"],"content":"zsh-autosuggestions zsh-autosuggestions 开启后，Zsh 会根据历史记录和完成情况在您键入时建议命令，也就是根据历史记录快速补全命令，非常的好用！！！ 安装起来也非常简单，直接 git clone 即可 git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions # git clone git@github.com:zsh-users/zsh-autosuggestions.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions 之后修改配置文件，在 plugins 中加入 zsh-autosuggestions 即可 vim ~/.zshrc plugins=(git zsh-autosuggestions) ","date":"2022-11-16","objectID":"/posts/f2cdf8a6/:5:1","tags":["Linux","Shell","Zsh"],"title":"美化 Shell 之 Linux Zsh 篇","uri":"/posts/f2cdf8a6/"},{"categories":["Linux","Shell"],"content":"zsh-syntax-highlighting zsh-syntax-highlighting 开启后，在输入命令时就有了语法高亮，提升整体颜值的同时，还能辅助检查命令是否打错，安装过程类似 git clone https://github.com/zsh-users/zsh-syntax-highlighting ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting # git clone git@github.com:zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting 之后修改配置文件，在 plugins 中加入 zsh-syntax-highlighting 即可 vim ~/.zshrc plugins=(git zsh-autosuggestions zsh-syntax-highlighting) ","date":"2022-11-16","objectID":"/posts/f2cdf8a6/:5:2","tags":["Linux","Shell","Zsh"],"title":"美化 Shell 之 Linux Zsh 篇","uri":"/posts/f2cdf8a6/"},{"categories":["Linux","Shell"],"content":"参考资料 【维基百科】Z shell 【ohmyz】Oh My Zsh 官网 【GitHub】Oh My Zsh 仓库 【GitHub】Installing ZSH 【GitHub】Themes 【GitHub】zsh-autosuggestions 【GitHub】zsh-syntax-highlighting 【Zhihu】oh-my-zsh：让终端飞 【GitHub】Powerlevel10k ","date":"2022-11-16","objectID":"/posts/f2cdf8a6/:6:0","tags":["Linux","Shell","Zsh"],"title":"美化 Shell 之 Linux Zsh 篇","uri":"/posts/f2cdf8a6/"},{"categories":["日常踩坑"],"content":"本文主要参考 Python 遭遇 ProxyError 问题记录 重新梳理改写 ","date":"2022-03-29","objectID":"/posts/76f6af57/:0:0","tags":["日常踩坑","proxy","python","SSL"],"title":"从 SSLEOFError 到正确配置 Proxy","uri":"/posts/76f6af57/"},{"categories":["日常踩坑"],"content":"踩坑 在前几天搞定 pip 的 SSL 认证之后，结果在利用 requests 库请求 HTTPS 网站又出现了 SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')) 的 SSL 相关错误 经过一系列的查询资料和测试发现，原因竟然在于 python 自身的 urllib 库没有正确配置 HTTPS 代理 ","date":"2022-03-29","objectID":"/posts/76f6af57/:1:0","tags":["日常踩坑","proxy","python","SSL"],"title":"从 SSLEOFError 到正确配置 Proxy","uri":"/posts/76f6af57/"},{"categories":["日常踩坑"],"content":"代理服务器 ","date":"2022-03-29","objectID":"/posts/76f6af57/:2:0","tags":["日常踩坑","proxy","python","SSL"],"title":"从 SSLEOFError 到正确配置 Proxy","uri":"/posts/76f6af57/"},{"categories":["日常踩坑"],"content":"普通的代理服务器 上面提及的 HTTP(S) 代理，其实是通过代理服务器进行 HTTP(S) 流量的转发的意思，也是在上图中的 黄线 所代表的协议，文中后续用 出口协议 来指代 而和代理服务器之间其实也需要一种协议进行通信，就是在上图中的 绿线 部分，文中后续用 入口协议 来指代 而 入口协议 通常使用较多的都是 HTTP 和 Socks4/Socks5，很少有采用 HTTPS 作为与代理服务器间的连接协议，这点也是导致之前报错的主要原因 ","date":"2022-03-29","objectID":"/posts/76f6af57/:2:1","tags":["日常踩坑","proxy","python","SSL"],"title":"从 SSLEOFError 到正确配置 Proxy","uri":"/posts/76f6af57/"},{"categories":["日常踩坑"],"content":"科学上网工具 其实代理服务器和 SS、SSR、V2Ray、Clash 等科学上网代理工具都是同一种性质，主要的不同点在于与实际代理服务器之间的 入口协议 部分（例如 Shadowsocks、VMess、Trojan 等）。为了不被 GFW 发现，需要实现对流量的混淆加密等。而且通常为了兼容性等因素，大多数科学上网工具在与实际代理服务器之间还有一级本地的代理服务器 科学上网工具的特殊协议只是在上图中的只有红线部分使用，而整个蓝色框的部分就是科学上网工具，用户并不需要关心这些特殊协议，只需要通过与通常代理服务器一样的 绿线 的 入口协议 来进行连接即可 ","date":"2022-03-29","objectID":"/posts/76f6af57/:2:2","tags":["日常踩坑","proxy","python","SSL"],"title":"从 SSLEOFError 到正确配置 Proxy","uri":"/posts/76f6af57/"},{"categories":["日常踩坑"],"content":"代理配置 因此 入口协议 和 出口协议 之间其实没有任何因果联系，以 Clash for Windows, CFW 为例 它的 入口协议 支持 http 以及 socks，而且都在同一个端口，因此正确的代理配置应该是这样的： # 正确的配置方式 HTTP_PROXY=http://127.0.0.1:7890 HTTPS_PROXY=http://127.0.0.1:7890 或者 # 正确的配置方式 HTTP_PROXY=socks5://127.0.0.1:7890 HTTPS_PROXY=socks5://127.0.0.1:7890 重点： HTTPS_PROXY 也应该填写 http://127.0.0.1:7890，因为 HTTPS_PROXY 中 HTTPS 代表的是 出口协议，而 http://127.0.0.1:7890 代表和 127.0.0.1:7890 服务器之间的 入口协议 是 HTTP ","date":"2022-03-29","objectID":"/posts/76f6af57/:2:3","tags":["日常踩坑","proxy","python","SSL"],"title":"从 SSLEOFError 到正确配置 Proxy","uri":"/posts/76f6af57/"},{"categories":["日常踩坑"],"content":"追根溯源 # 错误的配置方式 HTTP_PROXY=http://127.0.0.1:7890 HTTPS_PROXY=https://127.0.0.1:7890 而之前一直采用的上述错误配置，则会因为旧版本的 python 的 pip 内含的 urllib3 不支持 HTTPS 的 入口协议 ，自动转换成了 HTTP 的 入口协议 进行连接了 ","date":"2022-03-29","objectID":"/posts/76f6af57/:3:0","tags":["日常踩坑","proxy","python","SSL"],"title":"从 SSLEOFError 到正确配置 Proxy","uri":"/posts/76f6af57/"},{"categories":["日常踩坑"],"content":"urllib3 但是在 urllib3 库升级到 v1.26.0 版本之后，增加了对 HTTPS 的 入口协议 的支持，参见 Add support for HTTPS connections to proxies. ","date":"2022-03-29","objectID":"/posts/76f6af57/:3:1","tags":["日常踩坑","proxy","python","SSL"],"title":"从 SSLEOFError 到正确配置 Proxy","uri":"/posts/76f6af57/"},{"categories":["日常踩坑"],"content":"pip pip 内置了的 requests 和 urllib3 包，而不依赖全局的 requests 和 urllib3 包 当 pip 版本高于 20.3 时，内置的 requests 包升级到了 v2.25.0，urllib3 包也升级到了 v1.26.2，也就是说开始支持 HTTPS 的 入口协议 了，参见 pypa/pip 20.3 (2020-11-30) NEWS.rst ","date":"2022-03-29","objectID":"/posts/76f6af57/:3:2","tags":["日常踩坑","proxy","python","SSL"],"title":"从 SSLEOFError 到正确配置 Proxy","uri":"/posts/76f6af57/"},{"categories":["日常踩坑"],"content":"万恶之源 urllib 但是其实他们都不是罪魁祸首，真正的原因其实在 python 的内置包 urllib 上 一般 CFW 等科学上网软件都会通过修改 Windows 注册表的 计算机\\HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings 目录下的 ProxyServer 来配置代理服务器地址端口以及 ProxyEnable 是否启用代理 CFW 在配置代理服务器时，仅仅给出了地址和端口，并没有给出 入口协议 # urllib 配置代理的源码摘录： if '=' in proxyServer: # Per-protocol settings for p in proxyServer.split(';'): protocol, address = p.split('=', 1) # See if address has a type:// prefix if not re.match('(?:[^/:]+)://', address): address = '%s://%s' % (protocol, address) proxies[protocol] = address else: # Use one setting for all protocols if proxyServer[:5] == 'http:': proxies['http'] = proxyServer else: proxies['http'] = 'http://%s' % proxyServer proxies['https'] = 'https://%s' % proxyServer proxies['ftp'] = 'ftp://%s' % proxyServer 按照上面给出的 urllib 库源码逻辑，会将代理配置为 proxies = { 'http': 'http://127.0.0.1:7890', 'https': 'https://127.0.0.1:7890', 'ftp': 'ftp://127.0.0.1:7890' } 因此导致了 pip、requests 等上层包，访问 HTTPS 网站时会错误的使用 https://127.0.0.1:7890 代理，而 CFW 根本不支持 HTTPS 的 入口协议，所以才会产生这么一系列的错误 个人推荐可以根据自己常用的科学上网工具所支持的 入口协议 来修改 urllib 库源码逻辑（文件位置一般在 ***/python3.*/urllib/request.py 或者 ***/anaconda3/Lib/urllib/request.py） if '=' in proxyServer: # Per-protocol settings for p in proxyServer.split(';'): protocol, address = p.split('=', 1) # See if address has a type:// prefix if not re.match('(?:[^/:]+)://', address): address = '%s://%s' % (protocol, address) proxies[protocol] = address else: # Use one setting for all protocols proxies['http'] = 'http://%s' % proxyServer proxies['https'] = 'http://%s' % proxyServer proxies['ftp'] = 'http://%s' % proxyServer 或者简单的按照下面的方式进行修改（并不一定适用所有情况） if '=' in proxyServer: # Per-protocol settings for p in proxyServer.split(';'): protocol, address = p.split('=', 1) # See if address has a type:// prefix if not re.match('(?:[^/:]+)://', address): address = '%s://%s' % (protocol, address) proxies[protocol] = address else: # Use one setting for all protocols proxies['http'] = proxyServer proxies['https'] = proxyServer proxies['ftp'] = proxyServer ","date":"2022-03-29","objectID":"/posts/76f6af57/:3:3","tags":["日常踩坑","proxy","python","SSL"],"title":"从 SSLEOFError 到正确配置 Proxy","uri":"/posts/76f6af57/"},{"categories":["日常踩坑"],"content":"参考资料 【博客园】Python 遭遇 ProxyError 问题记录 【维基百科】代理服务器 【GitHub】Fndroid/clash_for_windows_pkg 系统代理自动关闭或打开 【GitHub】pypa/pip Pip 20.3+ break proxy connection 【GitHub】urllib3/urllib3 Add support for HTTPS connections to proxies. 【GitHub】pypa/pip 20.3 (2020-11-30) NEWS.rst ","date":"2022-03-29","objectID":"/posts/76f6af57/:4:0","tags":["日常踩坑","proxy","python","SSL"],"title":"从 SSLEOFError 到正确配置 Proxy","uri":"/posts/76f6af57/"},{"categories":["日常踩坑"],"content":"最近电脑有个问题持续了好久：当默认浏览器设置为 chrome 时，并且 chrome 已经打开的情况下，在微信内通过默认浏览器打开总是没有反应 （如果 chrome 没有打开时，则会正常跳出 chrome 以及相应的网页，好气哦） ","date":"2022-03-14","objectID":"/posts/29e0b18c/:0:0","tags":["日常踩坑","chrome"],"title":"修复 chrome 打不开微信或者部分第三方应用内链接","uri":"/posts/29e0b18c/"},{"categories":["日常踩坑"],"content":"修复问题：卸载 KGChromePlugin 经过各种查询资料，最后发现原因是 chrome 的启动参数被 KGChromePlugin 金格插件篡改了，从而导致部分第三方应用（实测，微信、vscode、cmd 都不行，但是 QQ 可以）无法调用 chrome 打开超链接 可通过 chrome://version/ 查看命令行中是否含有 --register-pepper-plugins=XXX 根据 XXX 中的路径信息，找到 KGChromePlugin 所在的文件路径，通常是 C:\\Program Files (x86)\\KGChromePlugin，然后在文件夹中找到卸载程序 KGPMUninstall.exe，双击进行卸载即可 卸载之后，重启一下 chrome，命令行应该就恢复正常了，此时也能在已打开 chrome 的情况下在第三方应用中顺利打开超链接了 ","date":"2022-03-14","objectID":"/posts/29e0b18c/:1:0","tags":["日常踩坑","chrome"],"title":"修复 chrome 打不开微信或者部分第三方应用内链接","uri":"/posts/29e0b18c/"},{"categories":["日常踩坑"],"content":"参考资料 【知乎】chrome 浏览器 每次打开提示：“–no-sandbox.” 怎么去除？ ","date":"2022-03-14","objectID":"/posts/29e0b18c/:2:0","tags":["日常踩坑","chrome"],"title":"修复 chrome 打不开微信或者部分第三方应用内链接","uri":"/posts/29e0b18c/"},{"categories":["日常踩坑"],"content":"踩坑 好久没用 python，最近重新下载安装好 python 后发现用 pip 安装第三方包一直失败。经过一番折腾发现，如果报错信息符合下面两种，一般都是因为网络连接时 SSL 认证失败导致的 check_hostname requires server_hostname raise ValueError(\"check_hostname requires server_hostname\") ValueError: check_hostname requires server_hostname EOF occurred in violation of protocol Could not fetch URL https://pypi.org/simple/xxx/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/xxx/ (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)'))) - skipping ","date":"2022-03-08","objectID":"/posts/2e7aa01a/:1:0","tags":["日常踩坑","pip","python","SSL"],"title":"解决 pip 安装第三方包时因 SSL 报错","uri":"/posts/2e7aa01a/"},{"categories":["日常踩坑"],"content":"什么是 SSL ？ 传输层安全性协议（英语：Transport Layer Security，TLS）及其前身安全套接层（英语：Secure Sockets Layer，SSL）是现在的 HTTPS 协议中的一种安全协议，目的是为互联网通信提供安全及数据完整性保障 而较新版本的 python 内置的 pip 以及用于网络请求的 requests、urllib3 包也较新，并且会使用 HTTPS 协议来下载新的软件包 ","date":"2022-03-08","objectID":"/posts/2e7aa01a/:2:0","tags":["日常踩坑","pip","python","SSL"],"title":"解决 pip 安装第三方包时因 SSL 报错","uri":"/posts/2e7aa01a/"},{"categories":["日常踩坑"],"content":"为什么会报错 根据报错信息可以发现错误的根源就在于 SSL，也就是没有通过该安全协议的认证，通常是由于开启了网络代理、VPN 或者网络抓包等软件的导致的 ","date":"2022-03-08","objectID":"/posts/2e7aa01a/:3:0","tags":["日常踩坑","pip","python","SSL"],"title":"解决 pip 安装第三方包时因 SSL 报错","uri":"/posts/2e7aa01a/"},{"categories":["日常踩坑"],"content":"解决办法 ","date":"2022-03-08","objectID":"/posts/2e7aa01a/:4:0","tags":["日常踩坑","pip","python","SSL"],"title":"解决 pip 安装第三方包时因 SSL 报错","uri":"/posts/2e7aa01a/"},{"categories":["日常踩坑"],"content":"1. 临时关闭代理、VPN 或者网络抓包等软件 最推荐的办法是临时关闭代理、VPN 或者网络抓包等软件，但是如果关闭后下载速度过慢可以尝试后面两种解决办法 ","date":"2022-03-08","objectID":"/posts/2e7aa01a/:4:1","tags":["日常踩坑","pip","python","SSL"],"title":"解决 pip 安装第三方包时因 SSL 报错","uri":"/posts/2e7aa01a/"},{"categories":["日常踩坑"],"content":"2. 通过镜像的 HTTP 源来避免 SSL 认证问题 由于是 SSL 是 HTTPS 协议需要的，因此我们可以切换至 HTTP 的镜像站来进行安装下载 HTTPS 现在已经比较普及，有不少镜像源也早已经切换至 HTTPS 协议，但部分镜像源在支持 HTTPS 协议的而同时也还支持 HTTP 协议，下面简单罗列几个 pip 镜像源 # 清华，仅支持 HTTPS https://pypi.tuna.tsinghua.edu.cn/simple/ # 阿里，HTTP 和 HTTPS 均支持 http://mirrors.aliyun.com/pypi/simple/ https://mirrors.aliyun.com/pypi/simple/ # 豆瓣，HTTP 和 HTTPS 均支持 http://pypi.doubanio.com/simple/ https://pypi.doubanio.com/simple/ 安装时第三方包时可以参考如下命令： pip install xxx-package -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com pip install xxx-package -i http://pypi.doubanio.com/simple/ --trusted-host pypi.doubanio.com 如果想永久使用镜像站，则需要修改配置文件，以 Linux 为例： vim ~/.pip/pip.conf 修改文件内容如下 [global] index-url = http://mirrors.aliyun.com/pypi/simple/ [install] trusted-host = mirrors.aliyun.com ","date":"2022-03-08","objectID":"/posts/2e7aa01a/:4:2","tags":["日常踩坑","pip","python","SSL"],"title":"解决 pip 安装第三方包时因 SSL 报错","uri":"/posts/2e7aa01a/"},{"categories":["日常踩坑"],"content":"3. 切换至低版本 pip 经过测试，当 pip 版本高于 20.3 后才会出现此错误，因此我们可以手动将 pip 版本降级至 20.2.4 或者 20.3b1 等较低版本即可 python -m pip install pip==20.2.4 -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com python -m pip install pip==20.2.4 -i http://pypi.doubanio.com/simple/ --trusted-host pypi.doubanio.com ","date":"2022-03-08","objectID":"/posts/2e7aa01a/:4:3","tags":["日常踩坑","pip","python","SSL"],"title":"解决 pip 安装第三方包时因 SSL 报错","uri":"/posts/2e7aa01a/"},{"categories":["日常踩坑"],"content":"参考资料 【阿里云】PyPI 镜像 【CSDN】python pip 的安装、更新、卸载、降级、和使用 pip 管理包 【CSDN】修改 pip 配置文件路径、更改 pip 源、使用 pip 安装已经下载的 whl 文件 ","date":"2022-03-08","objectID":"/posts/2e7aa01a/:5:0","tags":["日常踩坑","pip","python","SSL"],"title":"解决 pip 安装第三方包时因 SSL 报错","uri":"/posts/2e7aa01a/"},{"categories":["测试"],"content":"本文主要记录在利用 YCSB 使用配置文件测试 RocksDB 的过程中遇到的一些问题以及相应的解决办法 ","date":"2021-12-26","objectID":"/posts/4bc1e607/:0:0","tags":["Maven","RocksDB","YCSB"],"title":"自定义配置 RocksDB 进行 YCSB 测试","uri":"/posts/4bc1e607/"},{"categories":["测试"],"content":"简介 YCSB 的全程是 Yahoo! Cloud Serving Benchmark，是雅虎开发的用来对云服务进行基础测试的工具，支持目前常见的 NoSQL 数据库产品，如 HBase、MongoDB、OrientDB、Redis 等等 RocksDB 是一个具有键/值接口的存储引擎，其中键和值是任意字节流。它是在 Facebook（Meta） 基于 LevelDB 开发的，并为 LevelDB API 提供向后兼容的支持 ","date":"2021-12-26","objectID":"/posts/4bc1e607/:1:0","tags":["Maven","RocksDB","YCSB"],"title":"自定义配置 RocksDB 进行 YCSB 测试","uri":"/posts/4bc1e607/"},{"categories":["测试"],"content":"编译 RocksDB 由于 YCSB 是用 Java 实现的，一般测试的数据库都需要提供 Java 版本的 .jar 包 虽然 RocksDB 最初是 C++ 的一个库（因为是嵌入式数据库），但是后续也提供了 Java 的 API 以及可以通过源码编译出 .jar 包，也可以直接通过 Maven 获取 官方在 GitHub 上给出了 Java 版本的介绍，编译过程也很简单 首先需要保证机器上安装好了 Java 的环境，必须在 1.7+ 版本以上，例如，安装 openjdk-8-jdk 包即可 sudo apt install openjdk-8-jdk 同时 RocksDB 本身还有一些环境需要安装，官方 也给出来了 sudo apt-get install libgflags-dev libsnappy-dev zlib1g-dev libbz2-dev liblz4-dev libzstd-dev 实际编译 jar 包时，需要提前配置好环境变量 export JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\" 实际编译时，有两个中版本可以选择，其中 rocksdbjava 是 debug 版本，而 rocksdbjavastatic 这是 release 版本，不过官方在 Java 版说明中没有提及，我是在 Makefile 文件 中找到的 make -j$(nproc) rocksdbjava make -j$(nproc) rocksdbjavastatic ","date":"2021-12-26","objectID":"/posts/4bc1e607/:2:0","tags":["Maven","RocksDB","YCSB"],"title":"自定义配置 RocksDB 进行 YCSB 测试","uri":"/posts/4bc1e607/"},{"categories":["测试"],"content":"编译 YCSB YCSB 在 2019/10/17 的 4a99009 增加了对 RocksDB 配置文件的支持，然而目前官方给出的 release 版本还是 0.17.0，并且发布时间是 2019/10/6，因此我们只能选择从源码开始编译了 根据 官方给出的流程 git clone https://github.com/brianfrankcooper/YCSB.git cd YCSB mvn -pl site.ycsb:rocksdb-binding -am clean package 此时编译好的文件在 ./rocksdb/target/ 目录下 ~/YCSB$ ls rocksdb/target/*.jar rocksdb/target/rocksdb-binding-0.18.0-SNAPSHOT.jar 该 .jar 包其实只是 YCSB 和 RocksDB 之间的中间件，实际使用的 RocksDB 的 .jar 包以及其他的依赖包则是在 ./rocksdb/target/dependency/ 目录下 ~/YCSB$ tree rocksdb/target/dependency/ rocksdb/target/dependency/ ├── jcip-annotations-1.0.jar ├── rocksdbjni-6.2.2.jar ├── slf4j-api-1.7.25.jar └── slf4j-simple-1.7.25.jar RocksDB 的包其实是由 YCSB 通过 Maven 下载的，具体的版本在 pom.xml 中定义了 如果使用原本 RocksDB 则可以简单的通过修改这个版本信息，重新编译利用 Maven 重新下载 如果使用的是自己修改过源码的 RocksDB 则需要将自行编译的 RocksDB 的 .jar 包移到该目录下，并且删除旧的 .jar 包 ","date":"2021-12-26","objectID":"/posts/4bc1e607/:3:0","tags":["Maven","RocksDB","YCSB"],"title":"自定义配置 RocksDB 进行 YCSB 测试","uri":"/posts/4bc1e607/"},{"categories":["测试"],"content":"修复报错 但此时如果使用 ./bin/ycsb.sh 来进行测试，会报错 ~/YCSB$ ./bin/ycsb.sh load rocksdb -s -P workloads/workloada -p rocksdb.dir=tmp/ /usr/lib/jvm/java-8-openjdk-amd64/bin/java -classpath /home/ywang/YCSB/conf:/home/ywang/YCSB/core/target/core-0.18.0-SNAPSHOT.jar:/home/ywang/YCSB/rocksdb/target/rocksdb-binding-0.18.0-SNAPSHOT.jar:/home/ywang/YCSB/rocksdb/target/dependency/jcip-annotations-1.0.jar:/home/ywang/YCSB/rocksdb/target/dependency/rocksdbjni-6.2.2.jar:/home/ywang/YCSB/rocksdb/target/dependency/slf4j-api-1.7.25.jar:/home/ywang/YCSB/rocksdb/target/dependency/slf4j-simple-1.7.25.jar site.ycsb.Client -load -db site.ycsb.db.rocksdb.RocksDBClient -s -P workloads/workloada -p rocksdb.dir=tmp/ Command line: -load -db site.ycsb.db.rocksdb.RocksDBClient -s -P workloads/workloada -p rocksdb.dir=tmp/ YCSB Client 0.18.0-SNAPSHOT Loading workload... Exception in thread \"main\" java.lang.NoClassDefFoundError: org/apache/htrace/core/Tracer$Builder at site.ycsb.Client.getTracer(Client.java:458) at site.ycsb.Client.main(Client.java:304) Caused by: java.lang.ClassNotFoundException: org.apache.htrace.core.Tracer$Builder at java.net.URLClassLoader.findClass(URLClassLoader.java:387) at java.lang.ClassLoader.loadClass(ClassLoader.java:418) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352) at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ... 2 more (might take a few minutes for large data sets) 主要是使用的 ./bin/ycsb.sh 脚本有 bug，官方已经知道，并尝试修复，不过好像仍然没有解决 目前可以手动将 htrace 的包的依赖加入 RocksDB 中，并重新编译，利用 Maven 下载到 ./rocksdb/target/dependency/ 目录下 可以手动将 ./core/pom.xml 中 htrace 的依赖信息复制添加到 ./rocksdb/pom.xml 中 \u003c!-- ./rocksdb/pom.xml --\u003e …… \u003cdependency\u003e \u003cgroupId\u003eorg.rocksdb\u003c/groupId\u003e \u003cartifactId\u003erocksdbjni\u003c/artifactId\u003e \u003cversion\u003e${rocksdb.version}\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.htrace\u003c/groupId\u003e \u003cartifactId\u003ehtrace-core4\u003c/artifactId\u003e \u003cversion\u003e4.1.0-incubating\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003esite.ycsb\u003c/groupId\u003e \u003cartifactId\u003ecore\u003c/artifactId\u003e \u003cversion\u003e${project.version}\u003c/version\u003e \u003cscope\u003eprovided\u003c/scope\u003e \u003c/dependency\u003e …… 然后利用 mvn -pl site.ycsb:rocksdb-binding -am clean package 重新编译 这时再次利用 ./bin/ycsb.sh 来进行测试，还会报错 ~/YCSB$ ./bin/ycsb.sh load rocksdb -s -P workloads/workloada -p rocksdb.dir=tmp/ /usr/lib/jvm/java-8-openjdk-amd64/bin/java -classpath /home/ywang/YCSB/conf:/home/ywang/YCSB/core/target/core-0.18.0-SNAPSHOT.jar:/home/ywang/YCSB/rocksdb/target/rocksdb-binding-0.18.0-SNAPSHOT.jar:/home/ywang/YCSB/rocksdb/target/dependency/htrace-core4-4.1.0-incubating.jar:/home/ywang/YCSB/rocksdb/target/dependency/jcip-annotations-1.0.jar:/home/ywang/YCSB/rocksdb/target/dependency/rocksdbjni-6.2.2.jar:/home/ywang/YCSB/rocksdb/target/dependency/slf4j-api-1.7.25.jar:/home/ywang/YCSB/rocksdb/target/dependency/slf4j-simple-1.7.25.jar site.ycsb.Client -load -db site.ycsb.db.rocksdb.RocksDBClient -s -P workloads/workloada -p rocksdb.dir=tmp/ Command line: -load -db site.ycsb.db.rocksdb.RocksDBClient -s -P workloads/workloada -p rocksdb.dir=tmp/ YCSB Client 0.18.0-SNAPSHOT Loading workload... Starting test. [Thread-3] INFO site.ycsb.db.rocksdb.RocksDBClient - RocksDB data dir: tmp 2021-12-25 16:10:30:807 0 sec: 0 operations; est completion in 0 second DBWrapper: report latency for each error is false and specific error codes to track for latency are: [] Exception in thread \"Thread-3\" java.lang.NoClassDefFoundError: org/HdrHistogram/EncodableHistogram at site.ycsb.measurements.Measurements.constructOneMeasurement(Measurements.java:129) at site.ycsb.measurements.Measurements.getOpMeasurement(Measurements.java:220) at site.ycsb.measurements.Measurements.measure(Measurements.java:188) at site.ycsb.DBWrapper.measure(DBWrapper.java:184) at site.ycsb.DBWrapper.insert(DBWrapper.java:229) at site.ycsb.workloads.CoreWorkload.doInsert(CoreWorkload.java:621) at site.ycsb.ClientThread.run(ClientThread.java:135) at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.ClassNotFoundException: org.HdrHistogram.EncodableHistogram at java.net.URLClassLoad","date":"2021-12-26","objectID":"/posts/4bc1e607/:4:0","tags":["Maven","RocksDB","YCSB"],"title":"自定义配置 RocksDB 进行 YCSB 测试","uri":"/posts/4bc1e607/"},{"categories":["测试"],"content":"自定义配置 RocksDB 进行 YCSB 测试 自定义配置 RocksDB 的方式就很简单了，在 YCSB 测试时增加 rocksdb.optionsfile 参数并给出配置文件的路径即可 ./bin/ycsb.sh load rocksdb -s -P workloads/workloada -p rocksdb.dir=/tmp/ycsb-rocksdb-data -p workloads/ycsb-rocksdb-options.ini ./bin/ycsb.sh run rocksdb -s -P workloads/workloada -p rocksdb.dir=/tmp/ycsb-rocksdb-data -p workloads/ycsb-rocksdb-options.ini 配置文件可以参考 RocksDB 官方的例子 修改 也可以先不加测试文件，执行一次 ./bin/ycsb.sh load rocksdb -s -P workloads/workloada -p rocksdb.dir=/tmp/ycsb-rocksdb-data，让 YCSB 自己生成，然后根据 RocksDB 测试目录（/tmp/ycsb-rocksdb-data）下的 OPTIONS-000009 的配置文件来修改 ","date":"2021-12-26","objectID":"/posts/4bc1e607/:5:0","tags":["Maven","RocksDB","YCSB"],"title":"自定义配置 RocksDB 进行 YCSB 测试","uri":"/posts/4bc1e607/"},{"categories":["测试"],"content":"参考资料 【GitHub】RocksJava Basics 【man】nproc(1) — Linux manual page 【GitHub】Cannot execute YCSB #1105 【GitHub】[core] Fix ycsb.sh and ycsb.bat missing core dependencies #908 【CSDN】rocksdb 在 YCSB 中的运行教程 ","date":"2021-12-26","objectID":"/posts/4bc1e607/:6:0","tags":["Maven","RocksDB","YCSB"],"title":"自定义配置 RocksDB 进行 YCSB 测试","uri":"/posts/4bc1e607/"},{"categories":["Hexo"],"content":"想让网站能够被更多的人阅读，搜索引擎带来的流量必不可少。本文主要介绍如何配置 Hexo 并被主流的搜索引擎（Google、Bing）收录 搜索引擎能搜索到网站的前提是它抓取了网站的内容，并对其建立了索引，其实也就是爬虫爬取 + 插入数据库。虽然大部分搜索引擎都是自动抓取网络上的所有链接，并尝试爬取以及入库，但通常会比较缓慢（毕竟它并不一定知道我们网站的地址hhh）。所以更加推荐由我们站长主动出击，直接告诉它我们的网站地址 延伸阅读：Google 搜索运作方式的基础知识 ","date":"2021-12-08","objectID":"/posts/abac0c46/:0:0","tags":["Hexo","NexT"],"title":"Hexo 配置主流搜索引擎收录流程记录","uri":"/posts/abac0c46/"},{"categories":["Hexo"],"content":"是否已经被收录 为了查看网站是否已经被收录，可以在 Google 或者 Bing 以下查询格式搜索，根据自己网站的地址对后面的 http(s) 链接进行替换即可 site:https://ywang-wnlo.github.io/ 如果能搜索到内容，那么恭喜网站已经被搜索引擎收录。不过为了更好的被收录网站中的内容，还是推荐生成站点地图并提交，来告诉搜索引擎网站中有哪些链接需要被爬取 ","date":"2021-12-08","objectID":"/posts/abac0c46/:1:0","tags":["Hexo","NexT"],"title":"Hexo 配置主流搜索引擎收录流程记录","uri":"/posts/abac0c46/"},{"categories":["Hexo"],"content":"生成站点地图 站点地图是一种文件，您以在其中提供与网站中的网页、视频或其他文件有关的信息，还可以说明这些内容之间的关系。搜索引擎会读取此文件，以便更高效地抓取您的网站。站点地图会告诉搜索引擎您认为网站中的哪些网页和文件比较重要，还会提供与这些文件有关的重要信息。例如，网页上次更新的时间和网页是否有任何备用的语言版本 Hexo 配置站点地图 sitemap 可以利用 hexo-generator-sitemap 插件，具体的配置过程参见 这里 仅仅生成站点地图还不够，为了更早被收录站点地图中的链接，还需要主动将站点地图提交给搜索引擎 ","date":"2021-12-08","objectID":"/posts/abac0c46/:2:0","tags":["Hexo","NexT"],"title":"Hexo 配置主流搜索引擎收录流程记录","uri":"/posts/abac0c46/"},{"categories":["Hexo"],"content":"提交站点地图 下面手把手教你如何给 Google 和 Bing 提交站点地图 （由于 GitHub 屏蔽了百度的爬虫，所以在这里不做百度搜索引擎的流程介绍，不过以下内容可以参考） ","date":"2021-12-08","objectID":"/posts/abac0c46/:3:0","tags":["Hexo","NexT"],"title":"Hexo 配置主流搜索引擎收录流程记录","uri":"/posts/abac0c46/"},{"categories":["Hexo"],"content":"Google Google 官网给了详细的文档，可以看这篇 新手入门指南 而对我们来说，主要分三个步骤：注册 Search Console，验证网站所有权，提交站点地图 注册 Search Console 注册的过程非常简单，进入 GSC 官网，用谷歌账号登录即可 验证网站所有权 登录之后，就需要添加我们的网站了 由于该博客是利用 GitHub Pages 搭建，并没有 DNS 配置的相关权限，因此我们使用第二种方式进行配置，点击 继续 后会有五种方式供我们选择 个人推荐使用第二种，也就是 HTML 标记的方式，因为 NexT 主题的配置中对其进行支持，配置起来比较简单 点击复制，记录下其中的标记信息，例如我们这里复制的原始内容是 \u003cmeta name=\"google-site-verification\" content=\"F3QOKaQRQaSAxN-JLDLGD21CCU5CkZRssZYwX-Mn-Zc\" /\u003e 所以在 Next 的配置文件中 _config.next.yml 配置如下内容 # Google Webmaster tools verification. # See: https://developers.google.com/search google_site_verification: F3QOKaQRQaSAxN-JLDLGD21CCU5CkZRssZYwX-Mn-Zc 之后重新生成网站，并推送到 GitHub，等待 GitHub Pages 生成完毕后，点击 验证 即可 提交站点地图 之前 hexo-generator-sitemap 插件生成的站点地图，会默认放在在根目录下，只需在 GSC 的站点地图页面 填好站点地图的位置，然后点击提交即可 不过和 Bing 不同，Google 的站点地图爬取需要一定的时间，并且由于 GSC 的 bug，会将 等待中 错误的显示为 无法获取，一般需要几天的时间，此时只能耐心等待 ","date":"2021-12-08","objectID":"/posts/abac0c46/:3:1","tags":["Hexo","NexT"],"title":"Hexo 配置主流搜索引擎收录流程记录","uri":"/posts/abac0c46/"},{"categories":["Hexo"],"content":"Bing 从 GSC 导入 Bing 的流程和前面类似，不过由于已经配置好了 GSC，我们可以选择直接从 GSC 进行导入即可 手动添加网站 如果需要手动添加的话，其实步骤和 Google 也很类似 这里一样推荐使用第二种，也就是 HTML Meta 标记的方式，因为 NexT 主题的配置中对其进行支持，配置起来比较简单 点击复制，记录下其中的标记信息，例如我们这里复制的原始内容是 \u003cmeta name=\"msvalidate.01\" content=\"65AB321A829DD5542989CC078C3ABD9E\" /\u003e 所以在 Next 的配置文件中 _config.next.yml 配置如下内容 # Bing Webmaster tools verification. # See: https://www.bing.com/webmasters bing_site_verification: 65AB321A829DD5542989CC078C3ABD9E 之后重新生成网站，并推送到 GitHub，等待 GitHub Pages 生成完毕后，点击 验证 即可 提交站点地图也，只需在 Bing Webmasters tools 的站点地图页面 填好站点地图的位置，然后点击 提交 即可 Bing 的站点地图爬取一般几分钟就会完成，之后只需静静等待 Bing 给我们网站建立索引即可，一般来说一两天就可以完成整个网站的爬取，这点要比 Google 快不少 ","date":"2021-12-08","objectID":"/posts/abac0c46/:3:2","tags":["Hexo","NexT"],"title":"Hexo 配置主流搜索引擎收录流程记录","uri":"/posts/abac0c46/"},{"categories":["Hexo"],"content":"手动请求编入索引 根据个人观察，Google 及时获取到站点地图后似乎不会立刻根据站点地图爬取网站，因此推荐再自行进行一次手动请求编入索引 具体流程为： 点击 GSC 的【网址检查】或者直接在顶部输入栏输入网站的根地址（也可以是其他子页面地址） 等待结果返回后，点击【请求编入索引】即可 个人实测，大概需要一个月左右，Google 上就能搜索到网站上的大多数页面了 ","date":"2021-12-08","objectID":"/posts/abac0c46/:4:0","tags":["Hexo","NexT"],"title":"Hexo 配置主流搜索引擎收录流程记录","uri":"/posts/abac0c46/"},{"categories":["Hexo"],"content":"参考资料 【Google】Google 搜索运作方式的基础知识 【Google】浏览 Google 搜索文档，改善网站的 SEO 过程 【Google】了解站点地图 【Google】新手入门指南 【个人博客】Hexo 博客站点地图配置（Google） 【个人博客】Hexo 博客主流搜索引擎收录详细指南 ","date":"2021-12-08","objectID":"/posts/abac0c46/:5:0","tags":["Hexo","NexT"],"title":"Hexo 配置主流搜索引擎收录流程记录","uri":"/posts/abac0c46/"},{"categories":["IO Stack"],"content":"当前内容基于 Linux Kernel v5.4.121 ","date":"2021-12-05","objectID":"/posts/9ba60726/:0:0","tags":["buffer IO","kernel","page cache","writeback","todo"],"title":"page cache 简介","uri":"/posts/9ba60726/"},{"categories":["IO Stack"],"content":"page cache 由于磁盘 HDD 甚至于现在广泛使用的固态硬盘 SSD 的读写速度都远小于内存 DRAM 的读写速度，为了避免每次读取数据都要直接访问这些低速的底层存储设备，Linux 在利用 DRAM 实现了一个缓存层，缓存的粒度是 page，因此也叫 page cache，中文一般称为页（面）缓存 经过这层 page cache 的作用，IO 的性能得到了显著的提升。不过由于 DRAM 具有易失性，在掉电后数据会丢失，因此内核中的 回写机制 定时将 page cache 中的数据下刷到设备上，保证数据的持久化。此外内核还在 page cache 中实现了巧妙的预读机制提升了顺序读性能 ","date":"2021-12-05","objectID":"/posts/9ba60726/:1:0","tags":["buffer IO","kernel","page cache","writeback","todo"],"title":"page cache 简介","uri":"/posts/9ba60726/"},{"categories":["IO Stack"],"content":"直接 IO 与 缓存 IO 在拥有 page cache 这一层缓存后，写数据就有了三种不同的策略： 不经过缓存，直接写底层存储设备，但同时要使缓存中数据失效，也叫不缓存（nowrite） 只写缓存，缓存中数据定期刷到底层存储设备上，也叫写回（write back） 同时写缓存和底层存储设备，也叫写穿（write through） 前两种就是 Linux 在 IO 栈中支持的直接 IO（direct IO）和缓存 IO（buffer IO） 第三种策略虽然能非常简单保证缓存和底层设备的一致性，不过基于时间局部性原理，page cache 中的数据可能只是中间态，会被频繁修改，每次写穿会产生大量的开销 ","date":"2021-12-05","objectID":"/posts/9ba60726/:2:0","tags":["buffer IO","kernel","page cache","writeback","todo"],"title":"page cache 简介","uri":"/posts/9ba60726/"},{"categories":["IO Stack"],"content":"Linux IO 栈 详细的 Linux IO 栈图如下（来源于 Thomas-Krenn-Wiki）： 其实简化一下，可以分为文件系统、块层和设备驱动层这三层 ","date":"2021-12-05","objectID":"/posts/9ba60726/:3:0","tags":["buffer IO","kernel","page cache","writeback","todo"],"title":"page cache 简介","uri":"/posts/9ba60726/"},{"categories":["IO Stack"],"content":"Linux 中的具体实现 这里介绍和 page cache 相关的主要结构体和一些常用的函数 ","date":"2021-12-05","objectID":"/posts/9ba60726/:4:0","tags":["buffer IO","kernel","page cache","writeback","todo"],"title":"page cache 简介","uri":"/posts/9ba60726/"},{"categories":["IO Stack"],"content":"相关结构体 超级块 super_block 每个文件系统都有 super_block 结构体，用于存储该文件系统的特定信息 其定义在 include/linux/fs.h 中 struct super_block { struct list_head s_list; /* Keep this first */ dev_t s_dev; /* search index; _not_ kdev_t */ unsigned char s_blocksize_bits; unsigned long s_blocksize; loff_t s_maxbytes; /* Max file size */ struct file_system_type *s_type; const struct super_operations *s_op; const struct dquot_operations *dq_op; const struct quotactl_ops *s_qcop; const struct export_operations *s_export_op; unsigned long s_flags; unsigned long s_iflags; /* internal SB_I_* flags */ unsigned long s_magic; struct dentry *s_root; struct rw_semaphore s_umount; int s_count; atomic_t s_active; #ifdef CONFIG_SECURITY void *s_security; #endif const struct xattr_handler **s_xattr; #ifdef CONFIG_FS_ENCRYPTION const struct fscrypt_operations *s_cop; struct key *s_master_keys; /* master crypto keys in use */ #endif #ifdef CONFIG_FS_VERITY const struct fsverity_operations *s_vop; #endif struct hlist_bl_head s_roots; /* alternate root dentries for NFS */ struct list_head s_mounts; /* list of mounts; _not_ for fs use */ struct block_device *s_bdev; struct backing_dev_info *s_bdi; struct mtd_info *s_mtd; struct hlist_node s_instances; unsigned int s_quota_types; /* Bitmask of supported quota types */ struct quota_info s_dquot; /* Diskquota specific options */ struct sb_writers s_writers; /* * Keep s_fs_info, s_time_gran, s_fsnotify_mask, and * s_fsnotify_marks together for cache efficiency. They are frequently * accessed and rarely modified. */ void *s_fs_info; /* Filesystem private info */ /* Granularity of c/m/atime in ns (cannot be worse than a second) */ u32 s_time_gran; /* Time limits for c/m/atime in seconds */ time64_t s_time_min; time64_t s_time_max; #ifdef CONFIG_FSNOTIFY __u32 s_fsnotify_mask; struct fsnotify_mark_connector __rcu *s_fsnotify_marks; #endif char s_id[32]; /* Informational name */ uuid_t s_uuid; /* UUID */ unsigned int s_max_links; fmode_t s_mode; /* * The next field is for VFS *only*. No filesystems have any business * even looking at it. You had been warned. */ struct mutex s_vfs_rename_mutex; /* Kludge */ /* * Filesystem subtype. If non-empty the filesystem type field * in /proc/mounts will be \"type.subtype\" */ const char *s_subtype; const struct dentry_operations *s_d_op; /* default d_op for dentries */ /* * Saved pool identifier for cleancache (-1 means none) */ int cleancache_poolid; struct shrinker s_shrink; /* per-sb shrinker handle */ /* Number of inodes with nlink == 0 but still referenced */ atomic_long_t s_remove_count; /* Pending fsnotify inode refs */ atomic_long_t s_fsnotify_inode_refs; /* Being remounted read-only */ int s_readonly_remount; /* AIO completions deferred from interrupt context */ struct workqueue_struct *s_dio_done_wq; struct hlist_head s_pins; /* * Owning user namespace and default context in which to * interpret filesystem uids, gids, quotas, device nodes, * xattrs and security labels. */ struct user_namespace *s_user_ns; /* * The list_lru structure is essentially just a pointer to a table * of per-node lru lists, each of which has its own spinlock. * There is no need to put them into separate cachelines. */ struct list_lru s_dentry_lru; struct list_lru s_inode_lru; struct rcu_head rcu; struct work_struct destroy_work; struct mutex s_sync_lock; /* sync serialisation lock */ /* * Indicates how deep in a filesystem stack this SB is */ int s_stack_depth; /* s_inode_list_lock protects s_inodes */ spinlock_t s_inode_list_lock ____cacheline_aligned_in_smp; struct list_head s_inodes; /* all inodes */ spinlock_t s_inode_wblist_lock; struct list_head s_inodes_wb; /* writeback inodes */ } __randomize_layout; super_block 通常在挂载文件系统时会从底层存储设备上读取并构建，并且需要同步回底层存储设备 索引节点 inode 而 inode 则是文件系统中最重要的一个结构体，用于保存一个文件的元数据以及其在底层设备上的位置信息等（在 Linux 下一切皆是文件，目录也是一种文件） 其定义也在 include/linux/fs.h 中 /* * Keep mostly read-only and often accessed (especially for * the RCU path lookup and 'stat' data) fields at the beginning * of the 'struct inode' */ ","date":"2021-12-05","objectID":"/posts/9ba60726/:4:1","tags":["buffer IO","kernel","page cache","writeback","todo"],"title":"page cache 简介","uri":"/posts/9ba60726/"},{"categories":["IO Stack"],"content":"常用函数 通常 address_space 上会挂载一个 address_space_operations 结构，用于自定义对 page cache 中的页面操作的函数 address_space_operations 结构定义也在 include/linux/fs.h 中 struct address_space_operations { int (*writepage)(struct page *page, struct writeback_control *wbc); int (*readpage)(struct file *, struct page *); /* Write back some dirty pages from this mapping. */ int (*writepages)(struct address_space *, struct writeback_control *); /* Set a page dirty. Return true if this dirtied it */ int (*set_page_dirty)(struct page *page); /* * Reads in the requested pages. Unlike -\u003ereadpage(), this is * PURELY used for read-ahead!. */ int (*readpages)(struct file *filp, struct address_space *mapping, struct list_head *pages, unsigned nr_pages); int (*write_begin)(struct file *, struct address_space *mapping, loff_t pos, unsigned len, unsigned flags, struct page **pagep, void **fsdata); int (*write_end)(struct file *, struct address_space *mapping, loff_t pos, unsigned len, unsigned copied, struct page *page, void *fsdata); /* Unfortunately this kludge is needed for FIBMAP. Don't use it */ sector_t (*bmap)(struct address_space *, sector_t); void (*invalidatepage) (struct page *, unsigned int, unsigned int); int (*releasepage) (struct page *, gfp_t); void (*freepage)(struct page *); ssize_t (*direct_IO)(struct kiocb *, struct iov_iter *iter); /* * migrate the contents of a page to the specified target. If * migrate_mode is MIGRATE_ASYNC, it must not block. */ int (*migratepage) (struct address_space *, struct page *, struct page *, enum migrate_mode); bool (*isolate_page)(struct page *, isolate_mode_t); void (*putback_page)(struct page *); int (*launder_page) (struct page *); int (*is_partially_uptodate) (struct page *, unsigned long, unsigned long); void (*is_dirty_writeback) (struct page *, bool *, bool *); int (*error_remove_page)(struct address_space *, struct page *); /* swapfile support */ int (*swap_activate)(struct swap_info_struct *sis, struct file *file, sector_t *span); void (*swap_deactivate)(struct file *file); }; 这里简要介绍一下其中通用的部分常用函数 从底层填充 当打开一个文件后，page cache 不会立即缓存这个文件的所有数据页，而是随着对文件的读写来逐渐填充的 readpage 和 readpages 就是将底层存储设备上的一个或者多个页的数据读到 page cache 中 写入修改 page cache 的写入较为复杂，主要分为三个阶段： write_begin 主要负责查找、或者分配新的物理页，并将其锁定，有时还需要先从底层读取最新的数据页 writepage 或者 writepages 就是负责对这些物理页的实际写入过程 write_end 主要负责解锁这些物理页，并且更新 inode 中的元数据信息，例如 i_size 其他 direct_IO 则是负责不经过 page cache 的直接 IO 的实现 需要注意的是，当需要读的数据在 page cache 中缓存的和底层存储数据不一致时，也就是 page 为 dirty 状态时，通常需要调用 filemap_write_and_wait 或者 filemap_write_and_wait_range 先将这部分脏数据写到底层设备之后，才能执行 direct read ","date":"2021-12-05","objectID":"/posts/9ba60726/:4:2","tags":["buffer IO","kernel","page cache","writeback","todo"],"title":"page cache 简介","uri":"/posts/9ba60726/"},{"categories":["IO Stack"],"content":"参考资料 【Thomas-Krenn-Wiki】Linux Storage Stack Diagram 【CSDN】浅墨: 聊聊 Linux IO (中) —— Linux 内核中的 IO 栈 【LKD】Linux Kernel Development (3rd Edition) 【阿里云技术博客】The Xarray Data Structure 【LWN】Some VFS address space operations changes 【博客园】Page Cache 与 Page 回写 ","date":"2021-12-05","objectID":"/posts/9ba60726/:5:0","tags":["buffer IO","kernel","page cache","writeback","todo"],"title":"page cache 简介","uri":"/posts/9ba60726/"},{"categories":["Hexo"],"content":"简介 NexT 主题是 Hexo 上使用最广，同时在 GitHub 上也是 Star 最多的主题，bug 修复和功能更新也比较快。当前博客就是使用 Hexo 配合 NexT 主题搭建的 ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:1:0","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"版本 在 【必读】更新说明及常见问题 中有相关说明，NexT 一共有三个不同的仓库： 版本 年份 仓库 v5.1.4 或更低 2014 ~ 2017 iissnan/hexo-theme-next v6.0.0 ~ v7.8.0 2018 ~ 2019 theme-next/hexo-theme-next v8.0.0 或更高 2020 next-theme/hexo-theme-next 旧的仓库基本上已经不再更新，因此推荐选择最新的 next-theme/hexo-theme-next 仓库的 NexT 主题 ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:1:1","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"安装 推荐使用 GitHub 进行安装，可以随时更新 因为笔者个人在 Windows 环境下写博客，后续命令均以 PowerShell 为例 cd \u003chexo-dir\u003e # git clone https://github.com/next-theme/hexo-theme-next.git .\\themes\\next\\ git clone git@github.com:next-theme/hexo-theme-next.git cp .\\themes\\next\\_config.yml .\\_config.next.yml ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:2:0","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"配置记录 对 NexT 主题的配置可以直接在 hexo 仓库下的配置文件 _config.next.yml 中进行修改即可，该文件的修改会在生成页面时覆盖主题目录下的配置文件 .\\themes\\next\\_config.yml 衍生拓展：【Hexo】配置文件优先级 ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:0","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"风格/主题 NexT 主题包含了 4 个风格，个人喜欢 Gemini，类似卡片的风格，边界比较明显 修改 _config.next.yml 之后，用 hexo clean; hexo g; hexo s 重新生成一下，就可以在 本地 预览了（后续流程如果没有特殊说明则基本一致） # Schemes # scheme: Muse # scheme: Mist # scheme: Pisces scheme: Gemini ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:1","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"网页图标 在各类网站上下载合适图标，按照配置文件中的文件名命名，并放在 images 下即可 衍生阅读：【Apple】Configuring Web Applications favicon: small: /images/favicon-16x16-next.png medium: /images/favicon-32x32-next.png apple_touch_icon: /images/apple-touch-icon-next.png safari_pinned_tab: /images/logo.svg #android_manifest: /manifest.json ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:2","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"菜单栏 菜单栏配置默认没有开启，个人开启了 首页、标签、分类、归档 四个子项目，并开启了图标和数量的气泡显示 # Usage: `Key: /link/ || icon` # Key is the name of menu item. If the translation for this item is available, the translated text will be loaded, otherwise the Key name will be used. Key is case-sensitive. # Value before `||` delimiter is the target link, value after `||` delimiter is the name of Font Awesome icon. # External url should start with http:// or https:// menu: home: / || fa fa-home #about: /about/ || fa fa-user tags: /tags/ || fa fa-tags categories: /categories/ || fa fa-th archives: /archives/ || fa fa-archive #schedule: /schedule/ || fa fa-calendar #sitemap: /sitemap.xml || fa fa-sitemap #commonweal: /404/ || fa fa-heartbeat # Enable / Disable menu icons / item badges. menu_settings: icons: true badges: true ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:3","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"侧边栏 默认头像会开启旋转功能，花里胡哨的而且旋转有点快，个人选择了关闭 # Sidebar Avatar avatar: # Replace the default image and set the url here. url: /images/avatar.gif # If true, the avatar will be displayed in circle. rounded: true # If true, the avatar will be rotated with the cursor. rotated: false 在单独的文章页面时侧边栏会默认显示为目录，并且 标签、分类、归档 已经在菜单栏开启了，所以个人选择了关闭 # Posts / Categories / Tags in sidebar. site_state: false 其他社交网站的主页的配置起来也很简单，简单替换一下链接，并且取消注释即可 # Social Links # Usage: `Key: permalink || icon` # Key is the link label showing to end users. # Value before `||` delimiter is the target permalink, value after `||` delimiter is the name of Font Awesome icon. social: GitHub: https://github.com/ywang-wnlo || fab fa-github E-Mail: mailto:ywang_wnlo@qq.com || fa fa-envelope #Weibo: https://weibo.com/yourname || fab fa-weibo #Google: https://plus.google.com/yourname || fab fa-google #Twitter: https://twitter.com/yourname || fab fa-twitter #FB Page: https://www.facebook.com/yourname || fab fa-facebook #StackOverflow: https://stackoverflow.com/yourname || fab fa-stack-overflow #YouTube: https://youtube.com/yourname || fab fa-youtube #Instagram: https://instagram.com/yourname || fab fa-instagram #Skype: skype:yourname?call|chat || fab fa-skype ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:4","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"本地搜索 本地搜索可以快速的检索所有的文章，有时候还是很有用的 配置本地搜索之前，首先要在 hexo 下安装插件 npm install hexo-generator-searchdb --save 然后在配置中开启即可 # Local Search # Dependencies: https://github.com/next-theme/hexo-generator-searchdb local_search: enable: true # If auto, trigger search by changing input. # If manual, trigger search by pressing enter key or search button. trigger: auto # Show top n results per article, show all results by setting to -1 top_n_per_article: -1 # Unescape html strings to the readable one. unescape: true # Preload the search data when the page loads. preload: false ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:5","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"代码块 代码块的高亮有很多种配色可以选，并且可以开启一键复制功能 codeblock: # Code Highlight theme # All available themes: https://theme-next.js.org/highlight/ theme: light: vs dark: vs2015 prism: light: prism dark: prism-dark # Add copy button on codeblock copy_button: enable: true # Available values: default | flat | mac style: default ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:6","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"动画效果 NexT 默认开启了动画效果，但是感觉比较慢，感觉有些影响阅读，推荐开启 async，并且适当的修改动画效果 P.S. 菜单栏的动画不可以关闭和调整，应该是个 bug # Use Animate.css to animate everything. # For more information: https://animate.style motion: enable: true async: true transition: # All available transition variants: https://theme-next.js.org/animate/ post_block: fadeIn post_header: post_body: coll_header: # Only for Pisces | Gemini. sidebar: fadeInDown ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:7","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"阅读进度 阅读进度有两种展示方式，一个在回到首页的按钮上直接显示百分比，另一个可以配置在首位部增加进度条，个人两个都开启了 back2top: enable: true # Back to top in sidebar. sidebar: false # Scroll percent label in b2t button. scrollpercent: true # Reading progress bar reading_progress: enable: true # Available values: left | right start_at: left # Available values: top | bottom position: bottom reversed: false color: \"#37c6c0\" height: 5px ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:8","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"书签 NexT 的书签功能可以保存当前的阅读进度，下次打开是会在续接该进度 # Bookmark Support bookmark: enable: true # Customize the color of the bookmark. color: \"#222\" # If auto, save the reading progress when closing the page or clicking the bookmark-icon. # If manual, only save it by clicking the bookmark-icon. save: auto ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:9","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"Mermaid Mermaid 可以快速的用代码生成简单的流程图、时序图、甘特图等 NexT 中开启 Mermaid 支持很方便，同时还有不同的风格可以选 # Mermaid tag mermaid: enable: true # Available themes: default | dark | forest | neutral theme: light: neutral dark: dark ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:10","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"lazyload lazyload 是网站常用的技术，通过按需加载，避免一次性加载过多内容导致的打开缓慢 # Vanilla JavaScript plugin for lazyloading images. # For more information: https://apoorv.pro/lozad.js/demo/ lazyload: true ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:11","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"fancybox fancybox 可以在点击图片时放大该图片，并且可以快速浏览当前文章的所有图片 # FancyBox is a tool that offers a nice and elegant way to add zooming functionality for images. # For more information: https://fancyapps.com/fancybox/ fancybox: true ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:12","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"pangu 对于强迫症来说，中英文混排时加上空格能很大程度改善阅读体验，但是有时候会不小心打漏部分空格，而 pangu 这个项目就可以帮你在展示时自动加上空格 # Pangu Support # For more information: https://github.com/vinta/pangu.js # Server-side plugin: https://github.com/next-theme/hexo-pangu pangu: true ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:13","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"捐赠 文章末尾还可以求打赏，需要配置好相应的二维码图片，并且可以修改提示语句 # Donate (Sponsor) settings # Front-matter variable (nonsupport animation). reward_settings: # If true, a donate button will be displayed in every article by default. enable: true animation: false comment: 赏个鸡腿🍗 reward: wechatpay: /images/wechatpay.png alipay: /images/alipay.jpg #paypal: /images/paypal.png #bitcoin: /images/bitcoin.png ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:14","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"版权声明 NexT 内置了文章末尾增加版权声明，只需手动开启即可 # Creative Commons 4.0 International License. # See: https://creativecommons.org/about/cclicenses/ creative_commons: # Available values: by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | cc-zero license: by-nc-sa # Available values: big | small size: small sidebar: false post: true # You can set a language value if you prefer a translated version of CC license, e.g. deed.zh # CC licenses are available in 39 languages, you can find the specific and correct abbreviation you need on https://creativecommons.org language: ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:15","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"不蒜子 不蒜子 是一个极简的网页计数器，NexT 已经内置，只需打开即可 # Show Views / Visitors of the website / page with busuanzi. # For more information: http://ibruce.info/2015/04/04/busuanzi/ busuanzi_count: enable: true total_visitors: true total_visitors_icon: fa fa-user total_views: true total_views_icon: fa fa-eye post_views: true post_views_icon: far fa-eye ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:16","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"gitalk 评论系统也是一个博客必不可少的，由于本博客搭在 GitHub Pages 上，所以评论系统就采用利用 GitHub Issues 实现的 gitalk NexT 已经内置的 gitalk 的 js 和 css，在配置文件中开启并进行配置即可 在修改配置文件之前需要先在 GitHub 上申请一个 OAuth Application，入口在 【Settings】 -\u003e 【Developer settings】 -\u003e 【OAuth Apps】 -\u003e 【New OAuth App】，或者直接使用这个 链接 填写好之后，记录下应用 id 以及密钥，如果没有显示密钥需要手动生成一下 然后首先选用 gitalk 作为评论系统 # Multiple Comment System Support comments: # Available values: tabs | buttons style: tabs # Choose a comment system to be displayed by default. # Available values: disqus | disqusjs | changyan | livere | gitalk | utterances active: gitalk # Setting `true` means remembering the comment system selected by the visitor. storage: true # Lazyload all comment systems. lazyload: true # Modify texts or order for any naves, here are some examples. nav: #disqus: # text: Load Disqus # order: -1 #gitalk: # order: -2 在 gitalk 配置中填上相应的内容 # Gitalk # For more information: https://gitalk.github.io gitalk: enable: true github_id: \u003cGitHub id\u003e # GitHub repo owner repo: \u003cGitHub id\u003e.github.io # Repository name to store issues client_id: \u003c应用 id\u003e # GitHub Application Client ID client_secret: \u003c应用密钥\u003e # GitHub Application Client Secret admin_user: \u003cGitHub id\u003e # GitHub repo owner and collaborators, only these guys can initialize gitHub issues distraction_free_mode: true # Facebook-like distraction free mode # When the official proxy is not available, you can change it to your own proxy address proxy: https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token # This is official proxy address # Gitalk's display language depends on user's browser or system environment # If you want everyone visiting your site to see a uniform language, you can set a force language value # Available values: en | es-ES | fr | ru | zh-CN | zh-TW language: ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:3:17","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Hexo"],"content":"参考资料 【NexT】v8.0.0+ 官网 【必读】更新说明及常见问题 【Hexo】配置文件优先级 【Apple】Configuring Web Applications 【Mermaid】官网 【GitHub】pangu 【不蒜子】官网 【GitHub】Gitalk ","date":"2021-12-04","objectID":"/posts/9a0b7c3b/:4:0","tags":["Hexo","NexT"],"title":"NexT 主题的配置使用记录","uri":"/posts/9a0b7c3b/"},{"categories":["Linux","Shell"],"content":"背景 今天学弟在使用 NVMe-over-TCP 时发现无法卸载 nvmet 驱动，显示使用中 在一起探讨和测试中发现最终的原因竟然在于 rm -r 和 rmdir 这两个命令上 ","date":"2021-11-24","objectID":"/posts/935ae1f0/:1:0","tags":["Linux","Shell","strace"],"title":"rm -r 与 rmdir 区别","uri":"/posts/935ae1f0/"},{"categories":["Linux","Shell"],"content":"二者区别 命令 主要系统调用 操作对象 rmdir rmdir 仅目录 rm -r openat, getdents64, close, unlinkat 目录，以及目录所有文件 ","date":"2021-11-24","objectID":"/posts/935ae1f0/:2:0","tags":["Linux","Shell","strace"],"title":"rm -r 与 rmdir 区别","uri":"/posts/935ae1f0/"},{"categories":["Linux","Shell"],"content":"rmdir rmdir 直接调用 rmdir 来删除目录，如果目录非空，则会删除失败 ","date":"2021-11-24","objectID":"/posts/935ae1f0/:2:1","tags":["Linux","Shell","strace"],"title":"rm -r 与 rmdir 区别","uri":"/posts/935ae1f0/"},{"categories":["Linux","Shell"],"content":"rm -r 会先用 openat 打开目录，通过 getdents64 获取目录中的内容，然后 close 目录 再第二次加上 O_CLOEXEC 标记openat 打开目录，表明当前目录即将删除，再次通过 getdents64 获取目录中的内容，然后 close 目录 然后依次通过 unlinkat 删除目录中的内容 最后通过 unlinkat 删除目录 ","date":"2021-11-24","objectID":"/posts/935ae1f0/:2:2","tags":["Linux","Shell","strace"],"title":"rm -r 与 rmdir 区别","uri":"/posts/935ae1f0/"},{"categories":["Linux","Shell"],"content":"rm -rf 但是如果使用的是 rm -rf，并且在第 3 步删除目录内文件失败时，则会跳过第 4 步，也就是说不会再对目录做任何操作 ","date":"2021-11-24","objectID":"/posts/935ae1f0/:2:3","tags":["Linux","Shell","strace"],"title":"rm -r 与 rmdir 区别","uri":"/posts/935ae1f0/"},{"categories":["Linux","Shell"],"content":"测试过程 ","date":"2021-11-24","objectID":"/posts/935ae1f0/:3:0","tags":["Linux","Shell","strace"],"title":"rm -r 与 rmdir 区别","uri":"/posts/935ae1f0/"},{"categories":["Linux","Shell"],"content":"配置环境 首先建立一个非空目录，并且给目录中的文件配置权限，禁止删除文件 mkdir dir touch dir/file sudo chattr +i dir/file 此时目录树如下 $ tree dir dir └── file 0 directories, 1 file ","date":"2021-11-24","objectID":"/posts/935ae1f0/:3:1","tags":["Linux","Shell","strace"],"title":"rm -r 与 rmdir 区别","uri":"/posts/935ae1f0/"},{"categories":["Linux","Shell"],"content":"rmdir $ strace -o rmdir rmdir dir/ rmdir: failed to remove 'dir/': Directory not empty strace 抓到的内容如下，主要内容在第 37 行 execve(\"/usr/bin/rmdir\", [\"rmdir\", \"dir/\"], 0x7ffe38ddae38 /* 26 vars */) = 0 brk(NULL) = 0x561e92b83000 arch_prctl(0x3001 /* ARCH_??? */, 0x7fff06684960) = -1 EINVAL (Invalid argument) access(\"/etc/ld.so.preload\", R_OK) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3 fstat(3, {st_mode=S_IFREG|0644, st_size=46019, ...}) = 0 mmap(NULL, 46019, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f51af80c000 close(3) = 0 openat(AT_FDCWD, \"/lib/x86_64-linux-gnu/libc.so.6\", O_RDONLY|O_CLOEXEC) = 3 read(3, \"\\177ELF\\2\\1\\1\\3\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\u003e\\0\\1\\0\\0\\0\\360q\\2\\0\\0\\0\\0\\0\"..., 832) = 832 pread64(3, \"\\6\\0\\0\\0\\4\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0\"..., 784, 64) = 784 pread64(3, \"\\4\\0\\0\\0\\20\\0\\0\\0\\5\\0\\0\\0GNU\\0\\2\\0\\0\\300\\4\\0\\0\\0\\3\\0\\0\\0\\0\\0\\0\\0\", 32, 848) = 32 pread64(3, \"\\4\\0\\0\\0\\24\\0\\0\\0\\3\\0\\0\\0GNU\\0\\t\\233\\222%\\274\\260\\320\\31\\331\\326\\10\\204\\276X\u003e\\263\"..., 68, 880) = 68 fstat(3, {st_mode=S_IFREG|0755, st_size=2029224, ...}) = 0 mmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f51af80a000 pread64(3, \"\\6\\0\\0\\0\\4\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0\"..., 784, 64) = 784 pread64(3, \"\\4\\0\\0\\0\\20\\0\\0\\0\\5\\0\\0\\0GNU\\0\\2\\0\\0\\300\\4\\0\\0\\0\\3\\0\\0\\0\\0\\0\\0\\0\", 32, 848) = 32 pread64(3, \"\\4\\0\\0\\0\\24\\0\\0\\0\\3\\0\\0\\0GNU\\0\\t\\233\\222%\\274\\260\\320\\31\\331\\326\\10\\204\\276X\u003e\\263\"..., 68, 880) = 68 mmap(NULL, 2036952, PROT_READ, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7f51af618000 mprotect(0x7f51af63d000, 1847296, PROT_NONE) = 0 mmap(0x7f51af63d000, 1540096, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x25000) = 0x7f51af63d000 mmap(0x7f51af7b5000, 303104, PROT_READ, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x19d000) = 0x7f51af7b5000 mmap(0x7f51af800000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1e7000) = 0x7f51af800000 mmap(0x7f51af806000, 13528, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7f51af806000 close(3) = 0 arch_prctl(ARCH_SET_FS, 0x7f51af80b580) = 0 mprotect(0x7f51af800000, 12288, PROT_READ) = 0 mprotect(0x561e91688000, 4096, PROT_READ) = 0 mprotect(0x7f51af845000, 4096, PROT_READ) = 0 munmap(0x7f51af80c000, 46019) = 0 brk(NULL) = 0x561e92b83000 brk(0x561e92ba4000) = 0x561e92ba4000 openat(AT_FDCWD, \"/usr/lib/locale/locale-archive\", O_RDONLY|O_CLOEXEC) = 3 fstat(3, {st_mode=S_IFREG|0644, st_size=3035952, ...}) = 0 mmap(NULL, 3035952, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f51af332000 close(3) = 0 rmdir(\"dir/\") = -1 ENOTEMPTY (Directory not empty) openat(AT_FDCWD, \"/usr/share/locale/locale.alias\", O_RDONLY|O_CLOEXEC) = 3 fstat(3, {st_mode=S_IFREG|0644, st_size=2996, ...}) = 0 read(3, \"# Locale name alias data base.\\n#\"..., 4096) = 2996 read(3, \"\", 4096) = 0 close(3) = 0 openat(AT_FDCWD, \"/usr/share/locale/en_US.UTF-8/LC_MESSAGES/coreutils.mo\", O_RDONLY) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \"/usr/share/locale/en_US.utf8/LC_MESSAGES/coreutils.mo\", O_RDONLY) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \"/usr/share/locale/en_US/LC_MESSAGES/coreutils.mo\", O_RDONLY) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \"/usr/share/locale/en.UTF-8/LC_MESSAGES/coreutils.mo\", O_RDONLY) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \"/usr/share/locale/en.utf8/LC_MESSAGES/coreutils.mo\", O_RDONLY) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \"/usr/share/locale/en/LC_MESSAGES/coreutils.mo\", O_RDONLY) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \"/usr/share/locale-langpack/en_US.UTF-8/LC_MESSAGES/coreutils.mo\", O_RDONLY) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \"/usr/share/locale-langpack/en_US.utf8/LC_MESSAGES/coreutils.mo\", O_RDONLY) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \"/usr/share/locale-langpack/en_US/LC_MESSAGES/coreutils.mo\", O_RDONLY) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \"/usr/sh","date":"2021-11-24","objectID":"/posts/935ae1f0/:3:2","tags":["Linux","Shell","strace"],"title":"rm -r 与 rmdir 区别","uri":"/posts/935ae1f0/"},{"categories":["Linux","Shell"],"content":"rm -r $ strace -o rm_r_fail.strace rm -r dir/ rm: cannot remove 'dir/file': Operation not permitted rm: cannot remove 'dir/': Directory not empty strace 抓到的内容如下，主要内容在第 39-59 以及 94-96 行 execve(\"/usr/bin/rm\", [\"rm\", \"-r\", \"dir/\"], 0x7ffc2c0fb640 /* 26 vars */) = 0 brk(NULL) = 0x56082871e000 arch_prctl(0x3001 /* ARCH_??? */, 0x7ffd0d910cf0) = -1 EINVAL (Invalid argument) access(\"/etc/ld.so.preload\", R_OK) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3 fstat(3, {st_mode=S_IFREG|0644, st_size=46019, ...}) = 0 mmap(NULL, 46019, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f65c441d000 close(3) = 0 openat(AT_FDCWD, \"/lib/x86_64-linux-gnu/libc.so.6\", O_RDONLY|O_CLOEXEC) = 3 read(3, \"\\177ELF\\2\\1\\1\\3\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\u003e\\0\\1\\0\\0\\0\\360q\\2\\0\\0\\0\\0\\0\"..., 832) = 832 pread64(3, \"\\6\\0\\0\\0\\4\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0\"..., 784, 64) = 784 pread64(3, \"\\4\\0\\0\\0\\20\\0\\0\\0\\5\\0\\0\\0GNU\\0\\2\\0\\0\\300\\4\\0\\0\\0\\3\\0\\0\\0\\0\\0\\0\\0\", 32, 848) = 32 pread64(3, \"\\4\\0\\0\\0\\24\\0\\0\\0\\3\\0\\0\\0GNU\\0\\t\\233\\222%\\274\\260\\320\\31\\331\\326\\10\\204\\276X\u003e\\263\"..., 68, 880) = 68 fstat(3, {st_mode=S_IFREG|0755, st_size=2029224, ...}) = 0 mmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f65c441b000 pread64(3, \"\\6\\0\\0\\0\\4\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0\"..., 784, 64) = 784 pread64(3, \"\\4\\0\\0\\0\\20\\0\\0\\0\\5\\0\\0\\0GNU\\0\\2\\0\\0\\300\\4\\0\\0\\0\\3\\0\\0\\0\\0\\0\\0\\0\", 32, 848) = 32 pread64(3, \"\\4\\0\\0\\0\\24\\0\\0\\0\\3\\0\\0\\0GNU\\0\\t\\233\\222%\\274\\260\\320\\31\\331\\326\\10\\204\\276X\u003e\\263\"..., 68, 880) = 68 mmap(NULL, 2036952, PROT_READ, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7f65c4229000 mprotect(0x7f65c424e000, 1847296, PROT_NONE) = 0 mmap(0x7f65c424e000, 1540096, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x25000) = 0x7f65c424e000 mmap(0x7f65c43c6000, 303104, PROT_READ, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x19d000) = 0x7f65c43c6000 mmap(0x7f65c4411000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1e7000) = 0x7f65c4411000 mmap(0x7f65c4417000, 13528, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7f65c4417000 close(3) = 0 arch_prctl(ARCH_SET_FS, 0x7f65c441c580) = 0 mprotect(0x7f65c4411000, 12288, PROT_READ) = 0 mprotect(0x560827bb0000, 4096, PROT_READ) = 0 mprotect(0x7f65c4456000, 4096, PROT_READ) = 0 munmap(0x7f65c441d000, 46019) = 0 brk(NULL) = 0x56082871e000 brk(0x56082873f000) = 0x56082873f000 openat(AT_FDCWD, \"/usr/lib/locale/locale-archive\", O_RDONLY|O_CLOEXEC) = 3 fstat(3, {st_mode=S_IFREG|0644, st_size=3035952, ...}) = 0 mmap(NULL, 3035952, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f65c3f43000 close(3) = 0 ioctl(0, TCGETS, {B38400 opost isig icanon echo ...}) = 0 lstat(\"/\", {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0 newfstatat(AT_FDCWD, \"dir/\", {st_mode=S_IFDIR|0775, st_size=4096, ...}, AT_SYMLINK_NOFOLLOW) = 0 openat(AT_FDCWD, \"dir/\", O_RDONLY|O_NOCTTY|O_NONBLOCK|O_NOFOLLOW|O_DIRECTORY) = 3 fstat(3, {st_mode=S_IFDIR|0775, st_size=4096, ...}) = 0 fcntl(3, F_GETFL) = 0x38800 (flags O_RDONLY|O_NONBLOCK|O_LARGEFILE|O_NOFOLLOW|O_DIRECTORY) fcntl(3, F_SETFD, FD_CLOEXEC) = 0 getdents64(3, /* 3 entries */, 32768) = 72 close(3) = 0 geteuid() = 1000 newfstatat(AT_FDCWD, \"dir/\", {st_mode=S_IFDIR|0775, st_size=4096, ...}, AT_SYMLINK_NOFOLLOW) = 0 faccessat(AT_FDCWD, \"dir/\", W_OK) = 0 openat(AT_FDCWD, \"dir/\", O_RDONLY|O_NOCTTY|O_NONBLOCK|O_NOFOLLOW|O_CLOEXEC|O_DIRECTORY) = 3 fstat(3, {st_mode=S_IFDIR|0775, st_size=4096, ...}) = 0 fcntl(3, F_GETFL) = 0x38800 (flags O_RDONLY|O_NONBLOCK|O_LARGEFILE|O_NOFOLLOW|O_DIRECTORY) fcntl(3, F_SETFD, FD_CLOEXEC) = 0 fstatfs(3, {f_type=EXT2_SUPER_MAGIC, f_bsize=4096, f_blocks=20510566, f_bfree=15993067, f_bavail=14940434, f_files=5242880, f_ffree=5074130, f_fsid={val=[3258576323, 2412010735]}, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_RELATIME}) = 0 fcntl(3, F_DUPFD_CLOEXEC, 3) = 4 getdents64(3, /* 3 entries */, 32768) = 72 getdents64(3, /* 0 entries */, 32768) = 0 close(3) = 0 newfstatat(4, \"file\",","date":"2021-11-24","objectID":"/posts/935ae1f0/:3:3","tags":["Linux","Shell","strace"],"title":"rm -r 与 rmdir 区别","uri":"/posts/935ae1f0/"},{"categories":["Linux","Shell"],"content":"rm -rf $ strace -o rm_fail.strace rm -rf dir/ rm: cannot remove 'dir/file': Operation not permitted strace 抓到的内容如下，主要内容在第 39-55 行 execve(\"/usr/bin/rm\", [\"rm\", \"-rf\", \"dir/\"], 0x7fff7bc99c20 /* 26 vars */) = 0 brk(NULL) = 0x5566570fe000 arch_prctl(0x3001 /* ARCH_??? */, 0x7ffde2720670) = -1 EINVAL (Invalid argument) access(\"/etc/ld.so.preload\", R_OK) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3 fstat(3, {st_mode=S_IFREG|0644, st_size=46019, ...}) = 0 mmap(NULL, 46019, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7fcb89d87000 close(3) = 0 openat(AT_FDCWD, \"/lib/x86_64-linux-gnu/libc.so.6\", O_RDONLY|O_CLOEXEC) = 3 read(3, \"\\177ELF\\2\\1\\1\\3\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\u003e\\0\\1\\0\\0\\0\\360q\\2\\0\\0\\0\\0\\0\"..., 832) = 832 pread64(3, \"\\6\\0\\0\\0\\4\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0\"..., 784, 64) = 784 pread64(3, \"\\4\\0\\0\\0\\20\\0\\0\\0\\5\\0\\0\\0GNU\\0\\2\\0\\0\\300\\4\\0\\0\\0\\3\\0\\0\\0\\0\\0\\0\\0\", 32, 848) = 32 pread64(3, \"\\4\\0\\0\\0\\24\\0\\0\\0\\3\\0\\0\\0GNU\\0\\t\\233\\222%\\274\\260\\320\\31\\331\\326\\10\\204\\276X\u003e\\263\"..., 68, 880) = 68 fstat(3, {st_mode=S_IFREG|0755, st_size=2029224, ...}) = 0 mmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fcb89d85000 pread64(3, \"\\6\\0\\0\\0\\4\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0\"..., 784, 64) = 784 pread64(3, \"\\4\\0\\0\\0\\20\\0\\0\\0\\5\\0\\0\\0GNU\\0\\2\\0\\0\\300\\4\\0\\0\\0\\3\\0\\0\\0\\0\\0\\0\\0\", 32, 848) = 32 pread64(3, \"\\4\\0\\0\\0\\24\\0\\0\\0\\3\\0\\0\\0GNU\\0\\t\\233\\222%\\274\\260\\320\\31\\331\\326\\10\\204\\276X\u003e\\263\"..., 68, 880) = 68 mmap(NULL, 2036952, PROT_READ, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fcb89b93000 mprotect(0x7fcb89bb8000, 1847296, PROT_NONE) = 0 mmap(0x7fcb89bb8000, 1540096, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x25000) = 0x7fcb89bb8000 mmap(0x7fcb89d30000, 303104, PROT_READ, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x19d000) = 0x7fcb89d30000 mmap(0x7fcb89d7b000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1e7000) = 0x7fcb89d7b000 mmap(0x7fcb89d81000, 13528, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7fcb89d81000 close(3) = 0 arch_prctl(ARCH_SET_FS, 0x7fcb89d86580) = 0 mprotect(0x7fcb89d7b000, 12288, PROT_READ) = 0 mprotect(0x5566566dd000, 4096, PROT_READ) = 0 mprotect(0x7fcb89dc0000, 4096, PROT_READ) = 0 munmap(0x7fcb89d87000, 46019) = 0 brk(NULL) = 0x5566570fe000 brk(0x55665711f000) = 0x55665711f000 openat(AT_FDCWD, \"/usr/lib/locale/locale-archive\", O_RDONLY|O_CLOEXEC) = 3 fstat(3, {st_mode=S_IFREG|0644, st_size=3035952, ...}) = 0 mmap(NULL, 3035952, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7fcb898ad000 close(3) = 0 ioctl(0, TCGETS, {B38400 opost isig icanon echo ...}) = 0 lstat(\"/\", {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0 newfstatat(AT_FDCWD, \"dir/\", {st_mode=S_IFDIR|0775, st_size=4096, ...}, AT_SYMLINK_NOFOLLOW) = 0 openat(AT_FDCWD, \"dir/\", O_RDONLY|O_NOCTTY|O_NONBLOCK|O_NOFOLLOW|O_DIRECTORY) = 3 fstat(3, {st_mode=S_IFDIR|0775, st_size=4096, ...}) = 0 fcntl(3, F_GETFL) = 0x38800 (flags O_RDONLY|O_NONBLOCK|O_LARGEFILE|O_NOFOLLOW|O_DIRECTORY) fcntl(3, F_SETFD, FD_CLOEXEC) = 0 getdents64(3, /* 3 entries */, 32768) = 72 close(3) = 0 openat(AT_FDCWD, \"dir/\", O_RDONLY|O_NOCTTY|O_NONBLOCK|O_NOFOLLOW|O_CLOEXEC|O_DIRECTORY) = 3 fstat(3, {st_mode=S_IFDIR|0775, st_size=4096, ...}) = 0 fcntl(3, F_GETFL) = 0x38800 (flags O_RDONLY|O_NONBLOCK|O_LARGEFILE|O_NOFOLLOW|O_DIRECTORY) fcntl(3, F_SETFD, FD_CLOEXEC) = 0 fstatfs(3, {f_type=EXT2_SUPER_MAGIC, f_bsize=4096, f_blocks=20510566, f_bfree=15993067, f_bavail=14940434, f_files=5242880, f_ffree=5074130, f_fsid={val=[3258576323, 2412010735]}, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_RELATIME}) = 0 fcntl(3, F_DUPFD_CLOEXEC, 3) = 4 getdents64(3, /* 3 entries */, 32768) = 72 getdents64(3, /* 0 entries */, 32768) = 0 close(3) = 0 unlinkat(4, \"file\", 0) = -1 EPERM (Operation not permitted) openat(AT_FDCWD, \"/usr/share/locale/locale.alias\", O_RDONLY|O_CLOEXEC) = 3 fstat(3, {st_mode=S_IFREG|0644, st_size=2996, ...}) = 0 read(3, \"# Locale name alias data ba","date":"2021-11-24","objectID":"/posts/935ae1f0/:3:4","tags":["Linux","Shell","strace"],"title":"rm -r 与 rmdir 区别","uri":"/posts/935ae1f0/"},{"categories":["Linux","Shell"],"content":"参考资料 【mellanox 社区】HowTo Configure NVMe over Fabrics 【硬见】NVMe-oF 不只是 RDMA，还有 TCP 【CSDN】Linux 防止文件和目录被意外删除或修改 【man】open 【stackexchange】Why are rmdir and unlink two separate system calls? ","date":"2021-11-24","objectID":"/posts/935ae1f0/:4:0","tags":["Linux","Shell","strace"],"title":"rm -r 与 rmdir 区别","uri":"/posts/935ae1f0/"},{"categories":["Hexo"],"content":"Hexo 是一个快速、简洁且高效的博客框架，个人只需用 Markdown 来写文档，并且拥有丰富的插件和主题。当前博客就是使用 Hexo 配合 NexT 主题搭建的 因为笔者个人在 Windows 环境下写博客，后续命令均以 PowerShell 为例 ","date":"2021-11-22","objectID":"/posts/4143201a/:0:0","tags":["Hexo","NexT"],"title":"Hexo 插件推荐以及使用小技巧","uri":"/posts/4143201a/"},{"categories":["Hexo"],"content":"插件推荐 ","date":"2021-11-22","objectID":"/posts/4143201a/:1:0","tags":["Hexo","NexT"],"title":"Hexo 插件推荐以及使用小技巧","uri":"/posts/4143201a/"},{"categories":["Hexo"],"content":"hexo-deployer-git Hexo 支持一键部署网站到 git 仓库上，其他的一键部署方式参考 官网介绍 安装 npm install hexo-deployer-git --save 配置 deploy: type: git repo: \u003c仓库链接\u003e # 可以是 https 链接也可以是 git 链接 branch: [分支] # GitHub 的网站分支为 gh-pages，其他网站可能有所不同 message: [message] # 默认是 Site updated: {{ now('YYYY-MM-DD HH:mm:ss') }} 默认的提交信息只有时间信息，没有过多的参考价值推荐使用自定义提交信息，具体参考 后续小节 ","date":"2021-11-22","objectID":"/posts/4143201a/:1:1","tags":["Hexo","NexT"],"title":"Hexo 插件推荐以及使用小技巧","uri":"/posts/4143201a/"},{"categories":["Hexo"],"content":"hexo-word-counter 显示每篇文章的字数统计以及大致阅读时长，需要主题支持 安装 npm install hexo-word-counter --save 配置 # hexo-word-counter ## https://github.com/next-theme/hexo-word-counter symbols_count_time: symbols: true time: true total_symbols: false total_time: false exclude_codeblock: false awl: 4 wpm: 275 suffix: \"mins.\" 具体配置可以参考官方给出的说明： Note for Chinese users: because in Chinese language average word length about ~1.5 and if you at most cases write posts in Chinese (without mixed English), recommended to set awl to 2 and wpm to 300. But if you usualy mix your posts with English, awl to 4 and wpm to 275 will be nice. 也就是说纯中文时推荐 awl 设为 2，wpm 设为 300；而中英文混合时推荐 awl 设为 4，wpm 设为 275 ","date":"2021-11-22","objectID":"/posts/4143201a/:1:2","tags":["Hexo","NexT"],"title":"Hexo 插件推荐以及使用小技巧","uri":"/posts/4143201a/"},{"categories":["Hexo"],"content":"hexo-abbrlink Hexo 默认的文章链接是以时间以及文件名命名的，如果文件名为中文时转译之后会很长，并且不美观。而该插件可以利用 hash 值替换原有的文章链接 安装 npm install hexo-abbrlink --save 配置 首先修改 _config.yml 文件中的 permalink 的配置 permalink: posts/:abbrlink.html 再增加以下配置 # abbrlink config ## https://github.com/rozbo/hexo-abbrlink abbrlink: alg: crc32 # support crc16(default) and crc32 rep: hex # support dec(default) and hex drafts: true # (true)Process draft,(false)Do not process draft. false(default) # Generate categories from directory-tree # depth: the max_depth of directory-tree you want to generate, should \u003e 0 auto_category: enable: true # true(default) depth: 3 # 3(default) over_write: false auto_title: false # enable auto title, it can auto fill the title by path auto_date: false # enable auto date, it can auto fill the date by time today force: false # enable force mode, in this mode, the plugin will ignore the cache, and calc the abbrlink for every post even it already had abbrlink. ","date":"2021-11-22","objectID":"/posts/4143201a/:1:3","tags":["Hexo","NexT"],"title":"Hexo 插件推荐以及使用小技巧","uri":"/posts/4143201a/"},{"categories":["Hexo"],"content":"hexo-generator-sitemap 为了使博客能被谷歌、bing、百度收录，最好生成 sitemap 方便爬取，整体流程可以参考 这篇博文 安装 npm install hexo-generator-sitemap --save 配置 # hexo-generator-sitemap ## https://github.com/hexojs/hexo-generator-sitemap sitemap: path: sitemap.xml # template: ./sitemap_template.xml rel: true tags: false categories: false ","date":"2021-11-22","objectID":"/posts/4143201a/:1:4","tags":["Hexo","NexT"],"title":"Hexo 插件推荐以及使用小技巧","uri":"/posts/4143201a/"},{"categories":["Hexo"],"content":"小技巧 ","date":"2021-11-22","objectID":"/posts/4143201a/:2:0","tags":["Hexo","NexT"],"title":"Hexo 插件推荐以及使用小技巧","uri":"/posts/4143201a/"},{"categories":["Hexo"],"content":"自定义提交信息 hexo deploy -m \"自定义提交信息\" 例如使用 hexo 仓库的提交信息来提交到 deploy 仓库 hexo deploy -m (git log -1 --pretty=format:%s) 如果中文乱码，可以参考 这篇博客 修改 UTF-8 编码 ","date":"2021-11-22","objectID":"/posts/4143201a/:2:1","tags":["Hexo","NexT"],"title":"Hexo 插件推荐以及使用小技巧","uri":"/posts/4143201a/"},{"categories":["Hexo"],"content":"参考资料 【Hexo】一键部署 【GitHub】hexo-deployer-git 【GitHub】hexo-word-counter 【GitHub】hexo-abbrlink 【GitHub】hexo-generator-sitemap 【Git】git log 自定义输出格式 【CSDN】解决 Windows PowerShell 乱码 ","date":"2021-11-22","objectID":"/posts/4143201a/:3:0","tags":["Hexo","NexT"],"title":"Hexo 插件推荐以及使用小技巧","uri":"/posts/4143201a/"},{"categories":["IO Stack"],"content":"当前内容基于 Linux Kernel v5.4.121 ","date":"2021-11-19","objectID":"/posts/646202b9/:0:0","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"writeback 回写 在 page cache 简介 有过介绍 buffer IO 通过 page cache 进行缓存，减少对底层存储设备的直接读写，同时能够提高整体性能 写入到 page cache 的数据不会立刻写入后端设备，而是标记为“脏”，并被加入到脏页链表，后续由内核中的回写进程周期性的将脏页写回到底层存储设备 下面主要分析 page cache 回写机制的策略和实现 ","date":"2021-11-19","objectID":"/posts/646202b9/:1:0","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"相关结构体 ","date":"2021-11-19","objectID":"/posts/646202b9/:2:0","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"底层设备信息 在 include/linux/backing-dev-defs.h 中定义了 backing_dev_info 结构体，主要用与记录底层的设备信息 struct backing_dev_info { u64 id; struct rb_node rb_node; /* keyed by -\u003eid */ struct list_head bdi_list; unsigned long ra_pages; /* max readahead in PAGE_SIZE units */ unsigned long io_pages; /* max allowed IO size */ congested_fn *congested_fn; /* Function pointer if device is md/dm */ void *congested_data; /* Pointer to aux data for congested func */ // 通常为 \"block\" const char *name; struct kref refcnt; /* Reference counter for the structure */ unsigned int capabilities; /* Device capabilities */ unsigned int min_ratio; unsigned int max_ratio, max_prop_frac; /* * Sum of avg_write_bw of wbs with dirty inodes. \u003e 0 if there are * any dirty wbs, which is depended upon by bdi_has_dirty(). */ atomic_long_t tot_write_bandwidth; struct bdi_writeback wb; /* the root writeback info for this bdi */ struct list_head wb_list; /* list of all wbs */ #ifdef CONFIG_CGROUP_WRITEBACK struct radix_tree_root cgwb_tree; /* radix tree of active cgroup wbs */ struct rb_root cgwb_congested_tree; /* their congested states */ struct mutex cgwb_release_mutex; /* protect shutdown of wb structs */ struct rw_semaphore wb_switch_rwsem; /* no cgwb switch while syncing */ #else struct bdi_writeback_congested *wb_congested; #endif wait_queue_head_t wb_waitq; // bdi_class 设备 struct device *dev; // 主设备号:次设备号 char dev_name[64]; // 实际的底层设备 struct device *owner; struct timer_list laptop_mode_wb_timer; #ifdef CONFIG_DEBUG_FS struct dentry *debug_dir; #endif }; 初始化 该结构体只会由 mm/backing-dev.c 中的 bdi_alloc_node 函数来申请内存空间并调用 bdi_init 初始化 部分字段说明 name 字段 在 block/blk-core.c 中 blk_alloc_queue_node 会调用 bdi_alloc_node 来初始化该结构体，其中 name 字段赋值为 \"block\" dev 字段 在 mm/backing-dev.c 的 bdi_register_va 会调用 device_create 创建一个 bdi_class 类型的设备，并赋值给 dev 字段 dev_name 字段 在 mm/backing-dev.c 的 bdi_register_va 还会对 dev_name 进行赋值 根据调用栈溯源可以发现，mm/backing-dev.c 的 bdi_register_owner 将 fmt 和 args 传递到 bdi_register_va，最终会将主设备号和次设备号拼接组合后进行赋值 owner 字段 在 mm/backing-dev.c 的 bdi_register_owner 还会对 owner 进行赋值 实际赋值的为 disk 对应的 dev，通过 disk_to_dev 宏转换得到 ","date":"2021-11-19","objectID":"/posts/646202b9/:2:1","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"设备回写管理 在 include/linux/backing-dev-defs.h 中定义了 bdi_writeback 结构体，用于管理一个块设备的回写，同时支持 cgroup 进行限制 /* * Each wb (bdi_writeback) can perform writeback operations, is measured * and throttled, independently. Without cgroup writeback, each bdi * (bdi_writeback) is served by its embedded bdi-\u003ewb. * * On the default hierarchy, blkcg implicitly enables memcg. This allows * using memcg's page ownership for attributing writeback IOs, and every * memcg - blkcg combination can be served by its own wb by assigning a * dedicated wb to each memcg, which enables isolation across different * cgroups and propagation of IO back pressure down from the IO layer upto * the tasks which are generating the dirty pages to be written back. * * A cgroup wb is indexed on its bdi by the ID of the associated memcg, * refcounted with the number of inodes attached to it, and pins the memcg * and the corresponding blkcg. As the corresponding blkcg for a memcg may * change as blkcg is disabled and enabled higher up in the hierarchy, a wb * is tested for blkcg after lookup and removed from index on mismatch so * that a new wb for the combination can be created. */ struct bdi_writeback { struct backing_dev_info *bdi; /* our parent bdi */ unsigned long state; /* Always use atomic bitops on this */ unsigned long last_old_flush; /* last old data flush */ struct list_head b_dirty; /* dirty inodes */ struct list_head b_io; /* parked for writeback */ struct list_head b_more_io; /* parked for more writeback */ struct list_head b_dirty_time; /* time stamps are dirty */ spinlock_t list_lock; /* protects the b_* lists */ struct percpu_counter stat[NR_WB_STAT_ITEMS]; struct bdi_writeback_congested *congested; unsigned long bw_time_stamp; /* last time write bw is updated */ unsigned long dirtied_stamp; unsigned long written_stamp; /* pages written at bw_time_stamp */ unsigned long write_bandwidth; /* the estimated write bandwidth */ unsigned long avg_write_bandwidth; /* further smoothed write bw, \u003e 0 */ /* * The base dirty throttle rate, re-calculated on every 200ms. * All the bdi tasks' dirty rate will be curbed under it. * @dirty_ratelimit tracks the estimated @balanced_dirty_ratelimit * in small steps and is much more smooth/stable than the latter. */ unsigned long dirty_ratelimit; unsigned long balanced_dirty_ratelimit; struct fprop_local_percpu completions; int dirty_exceeded; enum wb_reason start_all_reason; spinlock_t work_lock; /* protects work_list \u0026 dwork scheduling */ struct list_head work_list; struct delayed_work dwork; /* work item used for writeback */ unsigned long dirty_sleep; /* last wait */ struct list_head bdi_node; /* anchored at bdi-\u003ewb_list */ #ifdef CONFIG_CGROUP_WRITEBACK struct percpu_ref refcnt; /* used only for !root wb's */ struct fprop_local_percpu memcg_completions; struct cgroup_subsys_state *memcg_css; /* the associated memcg */ struct cgroup_subsys_state *blkcg_css; /* and blkcg */ struct list_head memcg_node; /* anchored at memcg-\u003ecgwb_list */ struct list_head blkcg_node; /* anchored at blkcg-\u003ecgwb_list */ union { struct work_struct release_work; struct rcu_head rcu; }; #endif }; 初始化 该结构体由 mm/backing-dev.c 中的 wb_init 函数初始化 graph TD bdi_init --\u003e cgwb_bdi_init --\u003e wb_init 部分字段说明 b_dirty 字段 暂存所有的脏 inode 的链表 b_io 字段 暂存即将回写的 inode 的链表 b_more_io 字段 暂存由于一次回写数量限制原因导致的等待下次回写的 inode 链表 b_dirty_time 字段 暂存仅仅是时间戳更新而被至脏的 inode 的链表 list_lock 字段 为了保护上述 4 个 b_* 列表的自旋锁 dwork 字段 用于 page cache 回写机制的 work 关键结构体 work_list 字段 暂存所有需要回写的任务的链表 work_lock 字段 为了保护 work_list 以及 dwork 调度的自旋锁 ","date":"2021-11-19","objectID":"/posts/646202b9/:2:2","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"回写任务 在 fs/fs-writeback.c 中定义了 wb_writeback_work 结构体，用于描述一次回写任务的相关参数 /* * Passed into wb_writeback(), essentially a subset of writeback_control */ struct wb_writeback_work { // 本次回写的页数限制 long nr_pages; // 回写的文件系统的超级块 struct super_block *sb; // 回写的模式 enum writeback_sync_modes sync_mode; // tag-and-write 机制标记 unsigned int tagged_writepages:1; // 定期回写标记 unsigned int for_kupdate:1; // 继续上次循环回写标记 unsigned int range_cyclic:1; // 阈值回写标记 unsigned int for_background:1; // sync 系统调用标记 unsigned int for_sync:1; /* sync(2) WB_SYNC_ALL writeback */ unsigned int auto_free:1; /* free on completion */ enum wb_reason reason; /* why was writeback initiated? */ struct list_head list; /* pending work list */ struct wb_completion *done; /* set if the caller waits */ }; 后续通过 include/linux/writeback.h 中的 writeback_control 结构体封装，传递给底层的 writepages 函数 /* * A control structure which tells the writeback code what to do. These are * always on the stack, and hence need no locking. They are always initialised * in a manner such that unspecified fields are set to zero. */ struct writeback_control { long nr_to_write; /* Write this many pages, and decrement this for each page written */ long pages_skipped; /* Pages which were not written */ /* * For a_ops-\u003ewritepages(): if start or end are non-zero then this is * a hint that the filesystem need only write out the pages inside that * byterange. The byte at `end' is included in the writeout request. */ loff_t range_start; loff_t range_end; enum writeback_sync_modes sync_mode; unsigned for_kupdate:1; /* A kupdate writeback */ unsigned for_background:1; /* A background writeback */ unsigned tagged_writepages:1; /* tag-and-write to avoid livelock */ unsigned for_reclaim:1; /* Invoked from the page allocator */ unsigned range_cyclic:1; /* range_start is cyclic */ unsigned for_sync:1; /* sync(2) WB_SYNC_ALL writeback */ /* * When writeback IOs are bounced through async layers, only the * initial synchronous phase should be accounted towards inode * cgroup ownership arbitration to avoid confusion. Later stages * can set the following flag to disable the accounting. */ unsigned no_cgroup_owner:1; unsigned punt_to_cgroup:1; /* cgrp punting, see __REQ_CGROUP_PUNT */ #ifdef CONFIG_CGROUP_WRITEBACK struct bdi_writeback *wb; /* wb this writeback is issued under */ struct inode *inode; /* inode being written out */ /* foreign inode detection, see wbc_detach_inode() */ int wb_id; /* current wb id */ int wb_lcand_id; /* last foreign candidate wb id */ int wb_tcand_id; /* this foreign candidate wb id */ size_t wb_bytes; /* bytes written by current wb */ size_t wb_lcand_bytes; /* bytes written by last candidate */ size_t wb_tcand_bytes; /* bytes written by this candidate */ #endif }; 部分字段说明 sync_mode 字段 WB_SYNC_NONE：绝大部分回写任务的配置，不会等待回写真正落盘，下发写命令后就返回 WB_SYNC_ALL：sync 系统调用时配置，必须等待回调函数执行完成，写的数据真正落盘之后才会返回 tagged_writepages 字段 值为 1 表示开启 tag-and-write 机制用于避免活锁。该机制详情参考 后续小节 for_kupdate 字段 值为 1 表示当前任务是定期回写任务，用于回写已经至脏超过指定时间（内核中当前配置为 30s）的脏页。定期回写详情参考 后续小节 range_cyclic 字段 值为 1 表示当前任务的回写范围为整个 inode，并且从上次完成的位置作为起始位置进行循环回写。值为 0 则根据 struct writeback_control wbc 的 range_start 以及 range_end 作为回写的范围。range_cyclic 的详情参考 后续小节 for_background 字段 值为 1 表示当前任务是阈值回写任务，当脏页比例超过阈值后才会触发。阈值回写详情参考 后续小节 for_sync 字段 值为 1 表示当前任务是阈值回写任务 sync 系统调用手动触发的回写任务。sync 系统调用详情参考 后续小节 ","date":"2021-11-19","objectID":"/posts/646202b9/:2:3","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"回写线程 前面说过 bdi_writeback 结构体中 struct delayed_work dwork 就是关键的负责 page cache 回写工作的结构体 ","date":"2021-11-19","objectID":"/posts/646202b9/:3:0","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"初始化 wb_init 函数会对 wb-\u003edwork 赋值，注册实际的工作函数 wb_workfn 由于这是个 delayed_work，注册的工作函数不会立即执行，需要后续利用 mod_delayed_work 来修改 delayed_work 内置的定时器时间来唤醒 (P.S. 图片中函数开头为 cg 代表和 cgroup 相关，同一层级多个同名函数和宏定义的编译控制有关) 根据函数调用图，大致分析可知，当设备申请 queue 时会初始化 backing_dev_info 结构体和 bdi_writeback 结构体，以及初始化回写线程 ","date":"2021-11-19","objectID":"/posts/646202b9/:3:1","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"立即唤醒 虽然 dwork 是个 delayed_work，但是我们可以在调用 mod_delayed_work 将延时设置为 0，来立即唤醒回写线程 wb_wakeup wb_wakeup 就是修改延时为 0，直接唤醒回写线程 // fs/fs-writeback.c static void wb_wakeup(struct bdi_writeback *wb) { spin_lock_bh(\u0026wb-\u003ework_lock); if (test_bit(WB_registered, \u0026wb-\u003estate)) mod_delayed_work(bdi_wq, \u0026wb-\u003edwork, 0); spin_unlock_bh(\u0026wb-\u003ework_lock); } wb_queue_work wb_queue_work 将一个回写任务插入到队列尾部，然后修改延时为 0，立即唤醒回写线程 // fs/fs-writeback.c static void wb_queue_work(struct bdi_writeback *wb, struct wb_writeback_work *work) { trace_writeback_queue(wb, work); if (work-\u003edone) atomic_inc(\u0026work-\u003edone-\u003ecnt); spin_lock_bh(\u0026wb-\u003ework_lock); if (test_bit(WB_registered, \u0026wb-\u003estate)) { list_add_tail(\u0026work-\u003elist, \u0026wb-\u003ework_list); mod_delayed_work(bdi_wq, \u0026wb-\u003edwork, 0); } else finish_writeback_work(wb, work); spin_unlock_bh(\u0026wb-\u003ework_lock); } ","date":"2021-11-19","objectID":"/posts/646202b9/:3:2","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"定时唤醒 定时唤醒主要是由 wb_wakeup_delayed 来实现的，而时间间隔在 mm/page-writeback.c 进行了定义 // mm/page-writeback.c /* * The interval between `kupdate'-style writebacks */ unsigned int dirty_writeback_interval = 5 * 100; /* centiseconds */ EXPORT_SYMBOL_GPL(dirty_writeback_interval); // mm/backing-dev.c /* * This function is used when the first inode for this wb is marked dirty. It * wakes-up the corresponding bdi thread which should then take care of the * periodic background write-out of dirty inodes. Since the write-out would * starts only 'dirty_writeback_interval' centisecs from now anyway, we just * set up a timer which wakes the bdi thread up later. * * Note, we wouldn't bother setting up the timer, but this function is on the * fast-path (used by '__mark_inode_dirty()'), so we save few context switches * by delaying the wake-up. * * We have to be careful not to postpone flush work if it is scheduled for * earlier. Thus we use queue_delayed_work(). */ void wb_wakeup_delayed(struct bdi_writeback *wb) { unsigned long timeout; timeout = msecs_to_jiffies(dirty_writeback_interval * 10); spin_lock_bh(\u0026wb-\u003ework_lock); if (test_bit(WB_registered, \u0026wb-\u003estate)) queue_delayed_work(bdi_wq, \u0026wb-\u003edwork, timeout); spin_unlock_bh(\u0026wb-\u003ework_lock); } wb_wakeup_delayed 使用 5s 作为时间间隔，当调用 wb_wakeup_delayed 后，回写线程会在 5s 后被唤醒 定时唤醒只会在两种情形下被调用： __mark_inode_dirty：当给一个 inode 标记为脏时，如果脏的不仅仅是时间戳，而且当前的 b_dirty 链表是空的，也就是说第一次将脏页挂在 b_dirty 链表时，开启定时唤醒 wb_workfn：当回写线程处理完 work_list 上的所有任务后，如果仍有脏 inode 在 b_{dirty|io|more_io} 上时，开启定时唤醒 简单的讲，就是只要存在脏 inode 在 b_{dirty|io|more_io} 上时，内核的回写线程每 5s 内肯定会被唤醒一次 ","date":"2021-11-19","objectID":"/posts/646202b9/:3:3","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"释放销毁 当需要对整个 backing_dev_info 结构释放时，也会立即唤醒内核回写线程，并且会下刷现有的所有工作 graph TD release_bdi --\u003e bdi_unregister --\u003e wb_shutdown release_bdi ---\u003e wb_exit ","date":"2021-11-19","objectID":"/posts/646202b9/:3:4","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"细节分析 ","date":"2021-11-19","objectID":"/posts/646202b9/:4:0","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"tag-and-write 该机制会在 write_pages 时先快速对下刷范围内的脏页进行标记，后续只对标记过的脏页进行下刷 首先回写任务的参数会通过 fs/fs-writeback.c 的 writeback_sb_inodes 函数传递给 struct writeback_control wbc 后续在 mm/page-writeback.c 中 write_cache_pages 就会根据 wbc 的 tagged_writepages 字段进行判断，配置不同的 tag，以及是否需要快速遍历脏页并标记 /** * write_cache_pages - walk the list of dirty pages of the given address space and write all of them. * @mapping: address space structure to write * @wbc: subtract the number of written pages from *@wbc-\u003enr_to_write * @writepage: function called for each page * @data: data passed to writepage function * * If a page is already under I/O, write_cache_pages() skips it, even * if it's dirty. This is desirable behaviour for memory-cleaning writeback, * but it is INCORRECT for data-integrity system calls such as fsync(). fsync() * and msync() need to guarantee that all the data which was dirty at the time * the call was made get new I/O started against them. If wbc-\u003esync_mode is * WB_SYNC_ALL then we were called for data integrity and we must wait for * existing IO to complete. * * To avoid livelocks (when other process dirties new pages), we first tag * pages which should be written back with TOWRITE tag and only then start * writing them. For data-integrity sync we have to be careful so that we do * not miss some pages (e.g., because some other process has cleared TOWRITE * tag we set). The rule we follow is that TOWRITE tag can be cleared only * by the process clearing the DIRTY tag (and submitting the page for IO). * * To avoid deadlocks between range_cyclic writeback and callers that hold * pages in PageWriteback to aggregate IO until write_cache_pages() returns, * we do not loop back to the start of the file. Doing so causes a page * lock/page writeback access order inversion - we should only ever lock * multiple pages in ascending page-\u003eindex order, and looping back to the start * of the file violates that rule and causes deadlocks. * * Return: %0 on success, negative error code otherwise */ int write_cache_pages(struct address_space *mapping, struct writeback_control *wbc, writepage_t writepage, void *data) { int ret = 0; int done = 0; int error; struct pagevec pvec; int nr_pages; pgoff_t uninitialized_var(writeback_index); pgoff_t index; pgoff_t end; /* Inclusive */ pgoff_t done_index; int range_whole = 0; xa_mark_t tag; pagevec_init(\u0026pvec); if (wbc-\u003erange_cyclic) { writeback_index = mapping-\u003ewriteback_index; /* prev offset */ index = writeback_index; end = -1; } else { index = wbc-\u003erange_start \u003e\u003e PAGE_SHIFT; end = wbc-\u003erange_end \u003e\u003e PAGE_SHIFT; if (wbc-\u003erange_start == 0 \u0026\u0026 wbc-\u003erange_end == LLONG_MAX) range_whole = 1; } if (wbc-\u003esync_mode == WB_SYNC_ALL || wbc-\u003etagged_writepages) tag = PAGECACHE_TAG_TOWRITE; else tag = PAGECACHE_TAG_DIRTY; if (wbc-\u003esync_mode == WB_SYNC_ALL || wbc-\u003etagged_writepages) tag_pages_for_writeback(mapping, index, end); done_index = index; while (!done \u0026\u0026 (index \u003c= end)) { int i; nr_pages = pagevec_lookup_range_tag(\u0026pvec, mapping, \u0026index, end, tag); if (nr_pages == 0) break; for (i = 0; i \u003c nr_pages; i++) { struct page *page = pvec.pages[i]; done_index = page-\u003eindex; lock_page(page); /* * Page truncated or invalidated. We can freely skip it * then, even for data integrity operations: the page * has disappeared concurrently, so there could be no * real expectation of this data interity operation * even if there is now a new, dirty page at the same * pagecache address. */ if (unlikely(page-\u003emapping != mapping)) { continue_unlock: unlock_page(page); continue; } if (!PageDirty(page)) { /* someone wrote it for us */ goto continue_unlock; } if (PageWriteback(page)) { if (wbc-\u003esync_mode != WB_SYNC_NONE) wait_on_page_writeback(page); else goto continue_unlock; } BUG_ON(PageWriteback(page)); if (!clear_page_dirty_for_io(page)) goto continue_unlock; trace_wbc_writepage(wbc, inode_to_bdi(mapping-\u003ehost)); error = (*writepage)(page, wbc, data); if (unlikely(error)) { /* * Handle errors according to the type of * writeback. There's no need to continue for ","date":"2021-11-19","objectID":"/posts/646202b9/:4:1","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"range_cyclic range_cyclic 早在内核的 v2.6.18-rc1 版本就已经实现，可以参考 111ebb6 的提交信息辅助理解 [PATCH] writeback: fix range handling When a writeback_control's `start' and `end' fields are used to indicate a one-byte-range starting at file offset zero, the required values of .start=0,.end=0 mean that the -\u003ewritepages() implementation has no way of telling that it is being asked to perform a range request. Because we're currently overloading (start == 0 \u0026\u0026 end == 0) to mean \"this is not a write-a-range request\". To make all this sane, the patch changes range of writeback_control. So caller does: If it is calling -\u003ewritepages() to write pages, it sets range (range_start/end or range_cyclic) always. And if range_cyclic is true, -\u003ewritepages() thinks the range is cyclic, otherwise it just uses range_start and range_end. This patch does, - Add LLONG_MAX, LLONG_MIN, ULLONG_MAX to include/linux/kernel.h -1 is usually ok for range_end (type is long long). But, if someone did, range_end += val; range_end is \"val - 1\" u64val = range_end \u003e\u003e bits; u64val is \"~(0ULL)\" or something, they are wrong. So, this adds LLONG_MAX to avoid nasty things, and uses LLONG_MAX for range_end. - All callers of -\u003ewritepages() sets range_start/end or range_cyclic. - Fix updates of -\u003ewriteback_index. It seems already bit strange. If it starts at 0 and ended by check of nr_to_write, this last index may reduce chance to scan end of file. So, this updates -\u003ewriteback_index only if range_cyclic is true or whole-file is scanned. Signed-off-by: OGAWA Hirofumi \u003chirofumi@mail.parknet.co.jp\u003e Cc: Nathan Scott \u003cnathans@sgi.com\u003e Cc: Anton Altaparmakov \u003caia21@cantab.net\u003e Cc: Steven French \u003csfrench@us.ibm.com\u003e Cc: \"Vladimir V. Saveliev\" \u003cvs@namesys.com\u003e Signed-off-by: Andrew Morton \u003cakpm@osdl.org\u003e Signed-off-by: Linus Torvalds \u003ctorvalds@osdl.org\u003e range_cyclic 和 range_start/end 互斥 当开启 range_cyclic 将无视 range_start/end 的值 否则底层 writepages 函数则使用 range_start/end 作为写的范围 graph TD do_writepages --\u003e writepages(\"mapping-\u003ea_ops-\u003ewritepages()\") do_writepages --\u003e generic_writepages --\u003e write_cache_pages 结合实际代码，在 mm/page-writeback.c 的 write_cache_pages 函数中有以下片段 if (wbc-\u003erange_cyclic) { writeback_index = mapping-\u003ewriteback_index; /* prev offset */ index = writeback_index; end = -1; } else { index = wbc-\u003erange_start \u003e\u003e PAGE_SHIFT; end = wbc-\u003erange_end \u003e\u003e PAGE_SHIFT; if (wbc-\u003erange_start == 0 \u0026\u0026 wbc-\u003erange_end == LLONG_MAX) range_whole = 1; } // 此处省略部分代码 /* * If we hit the last page and there is more work to be done: wrap * back the index back to the start of the file for the next * time we are called. */ if (wbc-\u003erange_cyclic \u0026\u0026 !done) done_index = 0; if (wbc-\u003erange_cyclic || (range_whole \u0026\u0026 wbc-\u003enr_to_write \u003e 0)) mapping-\u003ewriteback_index = done_index; range_cyclic 开启后会使用 mapping-\u003ewriteback_index 作为本次回写的起始地址，并会在完成本次回写流程（回写页数限制或者到达文件末尾）后更新 mapping-\u003ewriteback_index ","date":"2021-11-19","objectID":"/posts/646202b9/:4:2","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"定期回写 定期回写的任务声明在 fs/fs-writeback.c 的 wb_check_old_data_flush 函数中，而这个函数则是被 wb_workfn 调用 static long wb_check_old_data_flush(struct bdi_writeback *wb) { unsigned long expired; long nr_pages; /* * When set to zero, disable periodic writeback */ if (!dirty_writeback_interval) return 0; expired = wb-\u003elast_old_flush + msecs_to_jiffies(dirty_writeback_interval * 10); if (time_before(jiffies, expired)) return 0; wb-\u003elast_old_flush = jiffies; nr_pages = get_nr_dirty_pages(); if (nr_pages) { // 定期回写 struct wb_writeback_work work = { .nr_pages = nr_pages, .sync_mode = WB_SYNC_NONE, .for_kupdate = 1, .range_cyclic = 1, .reason = WB_REASON_PERIODIC, }; return wb_writeback(wb, \u0026work); } return 0; } graph TD wb_wakeup -.-\u003e wb_workfn --\u003e|通常情况| wb_do_writeback --\u003e wb_check_old_data_flush 首先要保证当前时间在上次定期回写的 5s （和定期唤醒的时间间隔一致）后，并且当前存在脏页，才会生成一次定期回写的任务，也就是说每 5s 内最多触发一次定期回写 生成的回写任务交给 fs/fs-writeback.c 的 wb_writeback 函数处理 并且定期回写属于一种后台回写，优先级较低，只有在 wb-\u003ework_list 为空时才会执行 wb_writeback 执行定期回写时只会选择在至脏时间在当前时间 30s 之前的 inode 的所有脏页进行回写 ","date":"2021-11-19","objectID":"/posts/646202b9/:4:3","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"阈值回写 针对脏页率内核中有两个阈值，10% 和 20% // mm/page-writeback.c /* * Start background writeback (via writeback threads) at this percentage */ int dirty_background_ratio = 10; /* * The generator of dirty data starts writeback at this percentage */ int vm_dirty_ratio = 20; bg_thresh 后台阈值 当脏页率达到 10% 时会以后台的方式进行回写 graph TD generic_perform_write --\u003e balance_dirty_pages_ratelimited --\u003e balance_dirty_pages --\u003e wb_start_background_writeback --\u003e wb_wakeup wb_wakeup -.-\u003e wb_workfn --\u003e|通常情况| wb_do_writeback --\u003e|wb_over_bg_thresh| wb_check_background_flush 当用户 write 调用使用 generic_perform_write 来写 page cache 时，会调用 balance_dirty_pages_ratelimited 来检查脏页率，当脏页率超过 10% 就会调用 balance_dirty_pages 来唤醒 wb_workfn 来进行下刷脏页，此时并不会阻塞当前的 write 过程 thresh 前台阈值 而当脏页率达到 20% 之后则会触发前台回写，此时的函数调用和逻辑和上面基本一致，不同点在于当脏页率超过 20% 后会在 balance_dirty_pages 的循环中无法跳出，因此线程会阻塞，直到脏页率降低至 20% 以下，跳出循环，启用后台回写 ","date":"2021-11-19","objectID":"/posts/646202b9/:4:4","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"手动触发回写 ","date":"2021-11-19","objectID":"/posts/646202b9/:5:0","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"sync sync 系统调用会同步所有的 page cache 在 bash 上直接输入 sync 命令就会触发 sync 系统调用 // fs/sync.c /* * Sync everything. We start by waking flusher threads so that most of * writeback runs on all devices in parallel. Then we sync all inodes reliably * which effectively also waits for all flusher threads to finish doing * writeback. At this point all data is on disk so metadata should be stable * and we tell filesystems to sync their metadata via -\u003esync_fs() calls. * Finally, we writeout all block devices because some filesystems (e.g. ext2) * just write metadata (such as inodes or bitmaps) to block device page cache * and do not sync it on their own in -\u003esync_fs(). */ void ksys_sync(void) { int nowait = 0, wait = 1; // 唤醒所有 bdi 的回写线程 wakeup_flusher_threads(WB_REASON_SYNC); // 下发所有 inode 的回写任务 iterate_supers(sync_inodes_one_sb, NULL); // 调用 sync_fs() 同步文件系统的元数据 iterate_supers(sync_fs_one_sb, \u0026nowait); iterate_supers(sync_fs_one_sb, \u0026wait); // 回写块设备的 page cache iterate_bdevs(fdatawrite_one_bdev, NULL); iterate_bdevs(fdatawait_one_bdev, NULL); if (unlikely(laptop_mode)) laptop_sync_completion(); } SYSCALL_DEFINE0(sync) { ksys_sync(); return 0; } 首先，唤醒所有设备的回写线程线程，这样大部分的回写在所有设备上并行运行 并立刻生成一个下刷设备上所有 inode 的回写任务，并等待完成 然后文件系统通过注册的 sync_fs() 调用来同步他们的元数据 最后，回写所有的块设备的 page cache 因为有些文件系统（例如 ext2）会将元数据（如 inodes 或 bitmaps）写入块设备 page cache，而不是在 sync_fs() 中自行同步 ","date":"2021-11-19","objectID":"/posts/646202b9/:5:1","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"fsync 和 fdatasync fsync 和 fdatasync 系统调用则可以更加细粒度的下刷脏页，他们的下刷对象是一个文件 // fs/sync.c /** * vfs_fsync_range - helper to sync a range of data \u0026 metadata to disk * @file: file to sync * @start: offset in bytes of the beginning of data range to sync * @end: offset in bytes of the end of data range (inclusive) * @datasync: perform only datasync * * Write back data in range @start..@end and metadata for @file to disk. If * @datasync is set only metadata needed to access modified file data is * written. */ int vfs_fsync_range(struct file *file, loff_t start, loff_t end, int datasync) { struct inode *inode = file-\u003ef_mapping-\u003ehost; if (!file-\u003ef_op-\u003efsync) return -EINVAL; if (!datasync \u0026\u0026 (inode-\u003ei_state \u0026 I_DIRTY_TIME)) mark_inode_dirty_sync(inode); return file-\u003ef_op-\u003efsync(file, start, end, datasync); } EXPORT_SYMBOL(vfs_fsync_range); /** * vfs_fsync - perform a fsync or fdatasync on a file * @file: file to sync * @datasync: only perform a fdatasync operation * * Write back data and metadata for @file to disk. If @datasync is * set only metadata needed to access modified file data is written. */ int vfs_fsync(struct file *file, int datasync) { return vfs_fsync_range(file, 0, LLONG_MAX, datasync); } EXPORT_SYMBOL(vfs_fsync); static int do_fsync(unsigned int fd, int datasync) { struct fd f = fdget(fd); int ret = -EBADF; if (f.file) { ret = vfs_fsync(f.file, datasync); fdput(f); } return ret; } SYSCALL_DEFINE1(fsync, unsigned int, fd) { return do_fsync(fd, 0); } SYSCALL_DEFINE1(fdatasync, unsigned int, fd) { return do_fsync(fd, 1); } fsync 和 fdatasync 会调用文件系统注册的 f_op-\u003efsync() 函数进行脏页的下刷。很多文件系统会使用或者参考通用的 generic_file_fsync 来实现，这里针对 __generic_file_fsync 进行分析 // fs/libfs.c /** * __generic_file_fsync - generic fsync implementation for simple filesystems * * @file: file to synchronize * @start: start offset in bytes * @end: end offset in bytes (inclusive) * @datasync: only synchronize essential metadata if true * * This is a generic implementation of the fsync method for simple * filesystems which track all non-inode metadata in the buffers list * hanging off the address_space structure. */ int __generic_file_fsync(struct file *file, loff_t start, loff_t end, int datasync) { struct inode *inode = file-\u003ef_mapping-\u003ehost; int err; int ret; err = file_write_and_wait_range(file, start, end); if (err) return err; inode_lock(inode); ret = sync_mapping_buffers(inode-\u003ei_mapping); if (!(inode-\u003ei_state \u0026 I_DIRTY_ALL)) goto out; if (datasync \u0026\u0026 !(inode-\u003ei_state \u0026 I_DIRTY_DATASYNC)) goto out; err = sync_inode_metadata(inode, 1); if (ret == 0) ret = err; out: inode_unlock(inode); /* check and advance again to catch errors after syncing out buffers */ err = file_check_and_advance_wb_err(file); if (ret == 0) ret = err; return ret; } EXPORT_SYMBOL(__generic_file_fsync); /** * generic_file_fsync - generic fsync implementation for simple filesystems * with flush * @file: file to synchronize * @start: start offset in bytes * @end: end offset in bytes (inclusive) * @datasync: only synchronize essential metadata if true * */ int generic_file_fsync(struct file *file, loff_t start, loff_t end, int datasync) { struct inode *inode = file-\u003ef_mapping-\u003ehost; int err; err = __generic_file_fsync(file, start, end, datasync); if (err) return err; return blkdev_issue_flush(inode-\u003ei_sb-\u003es_bdev, GFP_KERNEL, NULL); } EXPORT_SYMBOL(generic_file_fsync); 无论 fsync 还是 fdatasync 都会调用 file_write_and_wait_range 下刷 page cache 中的脏页。而在 indoe 本身元数据只是时间戳是脏时，fdatasync 就会跳过 sync_inode_metadata，不将元数据一起下刷到底层设备上；fsync 则不会跳过元数据的下刷。 因此 fsync 至少需要两次 IO 写操作，开销比 fdatasync 更大 ","date":"2021-11-19","objectID":"/posts/646202b9/:5:2","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"open 时带有 O_SYNC 如果在打开一个文件时带了 O_SYNC 标记，则会在写入 page cache 后，再次调用 vfs_fsync_range 将数据下刷到底层设备上 graph LR write系统调用 --\u003e ksys_write --\u003e vfs_write --\u003e __vfs_write --\u003e|ext4,f2fs等文件系统| new_sync_write 在 ext4、f2fs 等文件系统 write 系统调用会使用 new_sync_write 来调用实际文件系统注册的 read_iter 函数 而 new_sync_write 调用先调用 iocb_flags 将用户配置的 O_SYNC 进行解析，为 struct kiocb 的 ki_flags 字段生成标记 graph TD new_sync_write --\u003e init_sync_kiocb --\u003e iocb_flags new_sync_write --\u003e iov_iter_init new_sync_write --\u003e call_write_iter 和之前一样，大多数文件系统会直接使用或者参考通用的 generic_file_write_iter 来实现 read_iter 函数，这里针对 generic_file_write_iter 进行分析 // mm/filemap.c /** * generic_file_write_iter - write data to a file * @iocb: IO state structure * @from: iov_iter with data to write * * This is a wrapper around __generic_file_write_iter() to be used by most * filesystems. It takes care of syncing the file in case of O_SYNC file * and acquires i_mutex as needed. * Return: * * negative error code if no data has been written at all of * vfs_fsync_range() failed for a synchronous write * * number of bytes written, even for truncated writes */ ssize_t generic_file_write_iter(struct kiocb *iocb, struct iov_iter *from) { struct file *file = iocb-\u003eki_filp; struct inode *inode = file-\u003ef_mapping-\u003ehost; ssize_t ret; inode_lock(inode); ret = generic_write_checks(iocb, from); if (ret \u003e 0) ret = __generic_file_write_iter(iocb, from); inode_unlock(inode); if (ret \u003e 0) ret = generic_write_sync(iocb, ret); return ret; } EXPORT_SYMBOL(generic_file_write_iter); 在 __generic_file_write_iter 完成之后，实际的数据已经被写入 page cache，之后会调用 generic_write_sync 会将刚刚写入 page cache 的数据通过 vfs_fsync_range 下刷到底层设备上 // include/linux/fs.h /* * Sync the bytes written if this was a synchronous write. Expect ki_pos * to already be updated for the write, and will return either the amount * of bytes passed in, or an error if syncing the file failed. */ static inline ssize_t generic_write_sync(struct kiocb *iocb, ssize_t count) { if (iocb-\u003eki_flags \u0026 IOCB_DSYNC) { int ret = vfs_fsync_range(iocb-\u003eki_filp, iocb-\u003eki_pos - count, iocb-\u003eki_pos - 1, (iocb-\u003eki_flags \u0026 IOCB_SYNC) ? 0 : 1); if (ret) return ret; } return count; } ","date":"2021-11-19","objectID":"/posts/646202b9/:5:3","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["IO Stack"],"content":"参考资料 【CSDN】VFS 基础学习笔记 - 7. page cache 回写 【CSDN】VFS 源码分析 - Page Cache Writeback 脏页回写机制 以及在评论区的某位不愿透露姓名的 dalao 的笔记 ","date":"2021-11-19","objectID":"/posts/646202b9/:6:0","tags":["buffer IO","kernel","page cache","writeback"],"title":"page cache 回写机制","uri":"/posts/646202b9/"},{"categories":["路由器"],"content":".ipk 文件 .ipk 文件是可以通过 OpenWrt 的包管理软件 opkg 直接安装，好比 .deb 文件与 apt 的关系。虽然官方的软件仓库已经很丰富了，但是有时仍然需要从源码编译一些第三方的软件使用，例如锐捷认证等 但是由于路由器平台通常与常用的服务器或者个人 PC 的处理器架构不同，并且路由器的处理器本身性能较弱，几乎不可能直接在路由器上进行编译生成 .ipk 文件，因此需要交叉编译来实现 而官方的 OpenWrt 仓库就提供了一个方便使用的交叉编译环境 ","date":"2021-11-01","objectID":"/posts/96a1807/:1:0","tags":["交叉编译","ipk","OpenWrt"],"title":"OpenWrt 手动编译 ipk","uri":"/posts/96a1807/"},{"categories":["路由器"],"content":"编译准备 以 Debian / Ubuntu 为例，参考 官网给出的要求，可以通过下面命令来进行安装依赖包 sudo apt update sudo apt install build-essential ccache ecj fastjar file g++ gawk \\ gettext git java-propose-classpath libelf-dev libncurses5-dev \\ libncursesw5-dev libssl-dev python python2.7-dev python3 unzip wget \\ python3-distutils python3-setuptools python3-dev rsync subversion \\ swig time xsltproc zlib1g-dev 安装/更新好这些依赖之后，就可以通过 git 拉取 OpenWrt 仓库了 git clone https://git.openwrt.org/openwrt/openwrt.git 通常由于仓库较大以及网速问题，可能会需要很久，其实可以通过 --depth 来限制拉取的仓库深度，或者通过镜像站来加速拉取，当然也可以两者同时采用 git clone https://git.openwrt.org/openwrt/openwrt.git --depth=1 # cnpmjs.org 已经不能使用，请自行寻找其他镜像站 # git clone https://git.openwrt.org.cnpmjs.org/openwrt/openwrt.git # git clone https://git.openwrt.org.cnpmjs.org/openwrt/openwrt.git --depth=1 ","date":"2021-11-01","objectID":"/posts/96a1807/:2:0","tags":["交叉编译","ipk","OpenWrt"],"title":"OpenWrt 手动编译 ipk","uri":"/posts/96a1807/"},{"categories":["路由器"],"content":"编译 .ipk 文件 ","date":"2021-11-01","objectID":"/posts/96a1807/:3:0","tags":["交叉编译","ipk","OpenWrt"],"title":"OpenWrt 手动编译 ipk","uri":"/posts/96a1807/"},{"categories":["路由器"],"content":"更新 feeds 进入 openwrt 仓库后，首先需要更新软件包列表 feeds，它是在 OpenWrt 中共用位置的包的集合。运行以下命令即可更新内置软件包列表并链接到编译工具中： cd openwrt/ ./scripts/feeds update ./scripts/feeds install ","date":"2021-11-01","objectID":"/posts/96a1807/:3:1","tags":["交叉编译","ipk","OpenWrt"],"title":"OpenWrt 手动编译 ipk","uri":"/posts/96a1807/"},{"categories":["路由器"],"content":"配置平台 make menuconfig 通常使用图形化菜单界面来进行配置编译选项，依次配置处理器架构、具体的处理器型号以及设备 以小米 R3G 路由器为例，应该将他们配置成如下图所示 ","date":"2021-11-01","objectID":"/posts/96a1807/:3:2","tags":["交叉编译","ipk","OpenWrt"],"title":"OpenWrt 手动编译 ipk","uri":"/posts/96a1807/"},{"categories":["路由器"],"content":"获取交叉编译链 这一步就是获取对应设备交叉编译所需的编译链 make tools/install V=s -j$(grep processor /proc/cpuinfo | wc -l) make toolchain/install V=s -j$(grep processor /proc/cpuinfo | wc -l) V=s 可以显示 make 过程中的所有输出，方便定位当前是否卡在了某一步骤上 -j$(grep processor /proc/cpuinfo | wc -l) 则是根据机器的 CPU 数量来进行多线程编译 直接 -j 也可以 ","date":"2021-11-01","objectID":"/posts/96a1807/:3:3","tags":["交叉编译","ipk","OpenWrt"],"title":"OpenWrt 手动编译 ipk","uri":"/posts/96a1807/"},{"categories":["路由器"],"content":"添加需要编译的第三方软件包 可以先搜索有没有已经配置好的含有 Makefile 的仓库，有了适配过的 Makefile 文件就可以很方便的来编译源码生成 .ipk 文件了 以 MentoHUST 为例，github 上有已经完成的仓库，依次可以直接拉取来编译 git clone https://github.com/KyleRicardo/MentoHUST-OpenWrt-ipk.git package/minieap 在拉取完成仓库后，就可以再次配置编译选项，将需要编译成 .ipk 的功能配置成模块编译，也就是标记成 M make menuconfig 对于 MentoHUST 来说，在 Network 中的 Ruijie 找到对应选项并配置成 M 即可，如下图 配置完成后就可以进行编译了，编译命令也很简单，以 MentoHUST 为例如下所示 make package/mentohust/compile V=s -j 编译完成后，.ipk 文件会生成在 ./bin/packages/\u003cYourArchitecture\u003e/base 目录下，将其拷贝到路由器上就可以通过 opkg 进行安装使用了 ","date":"2021-11-01","objectID":"/posts/96a1807/:3:4","tags":["交叉编译","ipk","OpenWrt"],"title":"OpenWrt 手动编译 ipk","uri":"/posts/96a1807/"},{"categories":["路由器"],"content":"参考资料 【OpenWrt】编译系统准备 【Gitbook】建立编译环境 【GitHub】OpenWrt 【GitHub】MentoHUST-OpenWrt-ipk ","date":"2021-11-01","objectID":"/posts/96a1807/:4:0","tags":["交叉编译","ipk","OpenWrt"],"title":"OpenWrt 手动编译 ipk","uri":"/posts/96a1807/"},{"categories":["路由器"],"content":"介绍 Breed 是国内个人 hackpascal 开发的闭源 Bootloader，也被称为“不死鸟” 因为有些官方升级固件自带 bootloader，如果从官方固件升级，会导致现有 bootloader 被覆盖。而当 Breed 更新固件时，它会自动删除固件附带的引导加载程序，因此可以防止 Breed 被覆盖 Breed 拥有以下特性： 实时刷机进度，进度条能准确反映刷机进度 Web 页面快速响应 最大固件备份速度，依 Flash 而定，一般能达到 1MB/s 免按复位键进入 Web 刷机模式 Telnet 功能，免 TTL 进入 Breed 命令控制台 复位键定义测试功能 固件启动失败自动进入 Web 刷机模式 可自定义位置和大小的环境变量块 由于是闭源，无法进行二次开发，所有支持的设备均由 hackpascal 一人完成。在 2020-10-09 后已经停止版本更新，但 官网 目前仍然开放所有的 Breed 下载 ","date":"2021-10-31","objectID":"/posts/53d6c2d9/:1:0","tags":["Breed","BootLoader"],"title":"Breed 介绍、刷入和使用","uri":"/posts/53d6c2d9/"},{"categories":["路由器"],"content":"文件说明 下表为 Breed 的文件对应的设备介绍，发布在 恩山论坛 上，在此处做一个备份 文件名 说明 BreedEnter.exe Breed 启动中断工具，实现免按复位键进入 Web 刷机模式 md5sum.txt 当前版本所有 Breed 文件的 MD5 值，用于校验文件的完整性 breed-mt7620-reset1.bin MT7620A / MT7620N 全通用，波特率 57600，复位键 GPIO#1 breed-mt7620-reset2.bin MT7620A / MT7620N 全通用，波特率 57600，复位键 GPIO#2 breed-mt7620-reset11.bin MT7620A / MT7620N 全通用，波特率 57600，复位键 GPIO#11 breed-mt7620-reset12.bin MT7620A / MT7620N 全通用，波特率 57600，复位键 GPIO#12 breed-mt7620-reset13.bin MT7620A / MT7620N 全通用，波特率 57600，复位键 GPIO#13 breed-mt7620-reset26.bin MT7620A / MT7620N 全通用，波特率 57600，复位键 GPIO#26 breed-mt7620-reset30.bin MT7620A / MT7620N 全通用，波特率 57600，复位键 GPIO#30 breed-mt7620-rt-n14u.bin MT7620A / MT7620N 全通用，波特率 57600，复位键 GPIO#1，WPS 键 GPIO#2 breed-mt7620-whr-1166dhp.bin MT7620A / MT7620N 全通用，波特率 57600，复位键 GPIO#52，AOSS 键 GPIO#53 breed-mt7620-lenovo-y1.bin 联想 Y1 (newifi mini) 专用，波特率 115200，复位键 GPIO#11 breed-mt7620-lenovo-y1s.bin 联想 Y1S (newifi) 专用，千兆口可用，波特率 115200，复位键 GPIO#11 breed-mt7620-zte-q7.bin 中兴 ZTE Q7 专用，波特率 57600，复位键 GPIO#26 breed-mt7620-youku-yk1.bin 优酷路由宝专用，波特率 57600，复位键 GPIO#1 breed-mt7620-xiaomi-mini.bin 小米 Mini 专用，波特率 115200，复位键 GPIO#30 breed-mt7620-fir302m.bin 斐讯 FIR300M/302M 专用，波特率 57600，复位键 GPIO#2 breed-mt7620-phicomm-psg1208.bin 斐讯 PSG1208 (K1)/ PSG1218 (K2) 专用，波特率 57600，复位键 GPIO#1 breed-mt7620-hiwifi-hc5761.bin 极路由 极壹S (HC5661)/极贰 (HC5761) 专用，波特率 115200，复位键 GPIO#12 breed-mt7620-hiwifi-hc5861.bin 极路由 极叁 (HC5861) 专用，千兆LAN可用，波特率 115200，复位键 GPIO#12 breed-mt7620-oye-0001.bin 哦耶 Oye-0001 专用，波特率 115200，复位键 GPIO#1 breed-mt7620-airmobi-iplay2.bin AirMobi iPlay2 专用，波特率 57600，复位键 GPIO#26 breed-mt7621-newifi-d1.bin 联想 Newifi D1 专用，DDR3 内存适用，默认 256MB DDR AC 时序参数，波特率 115200，复位键 GPIO#15，WPS 键 GPIO#18 breed-mt7621-newifi-d2.bin 联想 Newifi D2 专用，DDR3 内存适用，默认 512MB DDR AC 时序参数，波特率 115200，复位键 GPIO#3，WPS 键 GPIO#7 breed-mt7621-xunlei-timeplug.bin 迅雷时光机 (时光云) 专用，DDR3 内存适用，默认 256MB DDR AC 时序参数，波特率 115200，复位键 GPIO#4 breed-mt7621-youku-l2.bin 优酷路由宝 YK-L2 专用，DDR3 内存适用，默认 256MB DDR AC 时序参数，波特率 115200，复位键 GPIO#18，WPS 键 GPIO#17 breed-mt7621-phicomm-k2p.bin 斐讯 K2P 专用，DDR3 内存适用，默认 512MB DDR AC 时序参数，波特率 57600，复位键 GPIO#3 breed-mt7621-pbr-m1.bin PandoraBox PBR-M1 专用，DDR3 内存适用，默认 512MB DDR AC 时序参数，波特率 115200，复位键 GPIO#18 breed-mt7621-totolink-a3004ns.bin TOTOLINK A3004NS 专用，DDR3 内存适用，默认 256MB DDR AC 时序参数，波特率 57600，复位键 GPIO#4，WPS 键 GPIO#3 breed-mt7621-xiaomi-r3g.bin 小米路由器 3G 专用，NAND 启动，DDR3 内存适用，默认 256MB DDR AC 时序参数，波特率 115200，复位键 GPIO#18 breed-mt7621-creativebox-v1.bin CreativeBox v1 专用，DDR3 内存适用，默认 512MB DDR AC 时序参数，波特率 115200，复位键 GPIO#18 breed-mt7621-hiwifi-hc5962.bin 极路由4/HC5962/B70 专用，NAND 启动，DDR3 内存适用，默认 256MB DDR AC 时序参数，波特率 115200，复位键 GPIO#18 breed-mt7621-r6220.bin Netgear R6220 专用，NAND 启动，DDR2 内存适用，固定 128MB DDR AC 时序参数，波特率 57600，复位键 GPIO#14，WPS 键 GPIO#7，RFKILL 键 GPIO#8 breed-mt7621-wndr3700v5.bin Netgear WNDR3700 v5 专用，DDR2 内存适用，固定 128MB DDR AC 时序参数，波特率 57600，复位键 GPIO#14，WPS 键 GPIO#7，RFKILL 键 GPIO#8 breed-mt7621-gehua-ghl-r-001.bin 歌华 GHL-R-001 专用，DDR3 内存适用，默认 512MB DDR AC 时序参数，波特率 57600，复位键 GPIO#18 breed-mt7621-jd-cloud-1.bin 京东云路由宝 RE-SP-01B 专用，DDR3 内存适用，默认 512MB DDR AC 时序参数，波特率 115200，复位键 GPIO#18 breed-mt7628-hiwifi-hc5661a.bin 极路由 极壹S (HC5661A) 专用，波特率 115200，复位键 GPIO#38 breed-mt7628-oye-0006.bin 哦耶 OYE-0006 专用，波特率 115200，复位键 GPIO#38 breed-mt7688-reset38.bin MT7628AN/KN 全通用，波特率 57600，复位键 GPIO#38 breed-mt7688-wrtnode2r.bin MT7628AN/KN 全通用，波特率 115200，复位键 GPIO#5 breed-rt3050-buffalo-wcr-hp-gn.bin (不再更新) Buffalo WCR-HP-GN 专用，SPI 启动，波特率 57600，复位键 GPIO#10，WPS 键 GPIO#0 breed-rt3050-di-524m-b1.bin (不再更新) D-LINK DI-624M B1 专用，SPI 启动，波特率 57600，复位键 GPIO#10 breed-rt305x-nor-reset0.bin (不再更新) RT305X 通用，NOR 启动，波特率 57600，复位键 GPIO#0 breed-rt305x-nor-reset10.bin (不再更新) RT305X 通用，NOR 启动，波特率 57600，复位键 GPIO#10 breed-rt3052-dir-605-b1.bin (不再更新) D-LINK DIR-605 B1 专用，NOR 启动，波特率 57600，复位键 GPIO#10，WPS 键 GPIO#0 breed-rt3052-hg255d.bin (不再更新) 华为 HG255D 专用，NOR 启动，波特率 115200，复位键 GPIO#4，WPS 键 GPIO#10 breed-rt5350-airmobi-iplay.bin (不再更新) AirMobi iPlay 专用，波特率 57600，复位键 GPIO#12 breed-rt5350-hame-a5.bin (不再更新) 华美","date":"2021-10-31","objectID":"/posts/53d6c2d9/:1:1","tags":["Breed","BootLoader"],"title":"Breed 介绍、刷入和使用","uri":"/posts/53d6c2d9/"},{"categories":["路由器"],"content":"刷入 Breed Breed 的刷入和固件刷入流程基本一致： 获取原厂固件的 SSH 登录权限（可能是通过原厂固件漏洞等方式） 在原厂固件上利用 cat /proc/mtd 获取 ROM 分区的布局 [可选] 备份原有的所有 ROM 分区数据，主要目的是为了恢复原厂固件 利用 mtd 等命令直接对 Bootloader 所在的 ROM 区域进行写入镜像 重启设备 刷入 Breed 后，耐心等待设备重启，通常可以通过 192.168.1.1 这个地址来进入 Breed 的 Web 管理界面 ","date":"2021-10-31","objectID":"/posts/53d6c2d9/:2:0","tags":["Breed","BootLoader"],"title":"Breed 介绍、刷入和使用","uri":"/posts/53d6c2d9/"},{"categories":["路由器"],"content":"通过 Breed 刷机 通过 Breed 刷机就很方便了，直接在 固件更新 界面，勾选固件，并上传对应的固件，并勾选正确的闪存布局后，点击上传，等待设备重启即可 ","date":"2021-10-31","objectID":"/posts/53d6c2d9/:3:0","tags":["Breed","BootLoader"],"title":"Breed 介绍、刷入和使用","uri":"/posts/53d6c2d9/"},{"categories":["路由器"],"content":"其他功能 除去 Web 界面刷机，Breed 还支持一些其他的功能，包括固件备份、超频等，更多的使用方式推荐参考网上的其他资料 ","date":"2021-10-31","objectID":"/posts/53d6c2d9/:4:0","tags":["Breed","BootLoader"],"title":"Breed 介绍、刷入和使用","uri":"/posts/53d6c2d9/"},{"categories":["路由器"],"content":"参考资料 【恩山论坛】Breed 【恩山论坛】U-Boot 刷机 【恩山论坛】小米路由器 MINI 刷 Breed 及 Pandavan 教程 【恩山论坛】小米路由器 3G 刷 Breed 及老毛子 Padavan 固件教程 ","date":"2021-10-31","objectID":"/posts/53d6c2d9/:5:0","tags":["Breed","BootLoader"],"title":"Breed 介绍、刷入和使用","uri":"/posts/53d6c2d9/"},{"categories":["IO Stack"],"content":"当前内容基于 Linux Kernel v5.4.121 ","date":"2021-10-30","objectID":"/posts/4f0d345c/:0:0","tags":["异步 IO","kernel","liburing","io_uring"],"title":"io_uring 内核源码分析","uri":"/posts/4f0d345c/"},{"categories":["IO Stack"],"content":"1. io_uring 之前 介绍过 io_uring 只增加了三个 Linux 系统调用分别是 io_uring_setup，io_uring_enter 和 io_uring_register 他们的入口都在 Linux 内核源码的 fs/io_uring.c 文件中，下面将逐个分析 ","date":"2021-10-30","objectID":"/posts/4f0d345c/:1:0","tags":["异步 IO","kernel","liburing","io_uring"],"title":"io_uring 内核源码分析","uri":"/posts/4f0d345c/"},{"categories":["IO Stack"],"content":"2. 系统调用 io_uring_setup io_uring_setup 的作用在 用户库源码分析 中有过介绍，主要是初始化初始化 io_uring 结构体 ","date":"2021-10-30","objectID":"/posts/4f0d345c/:2:0","tags":["异步 IO","kernel","liburing","io_uring"],"title":"io_uring 内核源码分析","uri":"/posts/4f0d345c/"},{"categories":["IO Stack"],"content":"2.1. io_uring_setup /* * Sets up an aio uring context, and returns the fd. Applications asks for a * ring size, we return the actual sq/cq ring sizes (among other things) in the * params structure passed in. */ static long io_uring_setup(u32 entries, struct io_uring_params __user *params) { struct io_uring_params p; long ret; int i; // 用户态拷贝到内核态 if (copy_from_user(\u0026p, params, sizeof(p))) return -EFAULT; // 确认保留区域没有被赋值 for (i = 0; i \u003c ARRAY_SIZE(p.resv); i++) { if (p.resv[i]) return -EINVAL; } // 检查 flags 参数 if (p.flags \u0026 ~(IORING_SETUP_IOPOLL | IORING_SETUP_SQPOLL | IORING_SETUP_SQ_AFF)) return -EINVAL; // 分配内存空间，创建 workqueue，创建 fd 等 ret = io_uring_create(entries, \u0026p); if (ret \u003c 0) return ret; // 内核态拷贝回用户态 if (copy_to_user(params, \u0026p, sizeof(p))) return -EFAULT; return ret; } SYSCALL_DEFINE2(io_uring_setup, u32, entries, struct io_uring_params __user *, params) { return io_uring_setup(entries, params); } 可以看到 io_uring_setup 的核心函数是 io_uring_create ","date":"2021-10-30","objectID":"/posts/4f0d345c/:2:1","tags":["异步 IO","kernel","liburing","io_uring"],"title":"io_uring 内核源码分析","uri":"/posts/4f0d345c/"},{"categories":["IO Stack"],"content":"2.2. io_uring_create static int io_uring_create(unsigned entries, struct io_uring_params *p) { struct user_struct *user = NULL; struct io_ring_ctx *ctx; bool account_mem; int ret; if (!entries || entries \u003e IORING_MAX_ENTRIES) return -EINVAL; /* * Use twice as many entries for the CQ ring. It's possible for the * application to drive a higher depth than the size of the SQ ring, * since the sqes are only used at submission time. This allows for * some flexibility in overcommitting a bit. */ p-\u003esq_entries = roundup_pow_of_two(entries); p-\u003ecq_entries = 2 * p-\u003esq_entries; user = get_uid(current_user()); // 允许对共享内存段进行锁定 account_mem = !capable(CAP_IPC_LOCK); if (account_mem) { // 不能对共享内存段进行锁定，就需要增加当前可以锁定的内存 ret = io_account_mem(user, ring_pages(p-\u003esq_entries, p-\u003ecq_entries)); if (ret) { free_uid(user); return ret; } } ctx = io_ring_ctx_alloc(p); if (!ctx) { if (account_mem) io_unaccount_mem(user, ring_pages(p-\u003esq_entries, p-\u003ecq_entries)); free_uid(user); return -ENOMEM; } ctx-\u003ecompat = in_compat_syscall(); ctx-\u003eaccount_mem = account_mem; ctx-\u003euser = user; ctx-\u003ecreds = get_current_cred(); if (!ctx-\u003ecreds) { ret = -ENOMEM; goto err; } // 申请 io_rings SQEs ret = io_allocate_scq_urings(ctx, p); if (ret) goto err; // 初始化 workqueue，[初始化内核线程用于进行 IO poll] ret = io_sq_offload_start(ctx, p); if (ret) goto err; memset(\u0026p-\u003esq_off, 0, sizeof(p-\u003esq_off)); p-\u003esq_off.head = offsetof(struct io_rings, sq.head); p-\u003esq_off.tail = offsetof(struct io_rings, sq.tail); p-\u003esq_off.ring_mask = offsetof(struct io_rings, sq_ring_mask); p-\u003esq_off.ring_entries = offsetof(struct io_rings, sq_ring_entries); p-\u003esq_off.flags = offsetof(struct io_rings, sq_flags); p-\u003esq_off.dropped = offsetof(struct io_rings, sq_dropped); p-\u003esq_off.array = (char *)ctx-\u003esq_array - (char *)ctx-\u003erings; memset(\u0026p-\u003ecq_off, 0, sizeof(p-\u003ecq_off)); p-\u003ecq_off.head = offsetof(struct io_rings, cq.head); p-\u003ecq_off.tail = offsetof(struct io_rings, cq.tail); p-\u003ecq_off.ring_mask = offsetof(struct io_rings, cq_ring_mask); p-\u003ecq_off.ring_entries = offsetof(struct io_rings, cq_ring_entries); p-\u003ecq_off.overflow = offsetof(struct io_rings, cq_overflow); p-\u003ecq_off.cqes = offsetof(struct io_rings, cqes); /* * Install ring fd as the very last thing, so we don't risk someone * having closed it before we finish setup */ // 创建 fd 便于用户态访问 ctx ret = io_uring_get_fd(ctx); if (ret \u003c 0) goto err; p-\u003efeatures = IORING_FEAT_SINGLE_MMAP; return ret; err: io_ring_ctx_wait_and_kill(ctx); return ret; } graph TD io_uring_setup --\u003e io_ring_ctx_alloc io_uring_setup --\u003e io_allocate_scq_urings io_uring_setup --\u003e io_sq_offload_start io_uring_setup --\u003e io_uring_get_fd io_ring_ctx_alloc 主要用来申请空间，初始化列表头、互斥锁、自旋锁等结构 io_allocate_scq_urings 来初始化整个 struct io_rings *rings，包括 SQ、CQ 头尾指针的初始化，以及 SQE、CQE 的初始化 不同的是 SQ、CQ 头尾指针以及 CQE 都在 struct io_rings *rings 结构体中 而 SQE 则是在 struct io_ring_ctx *ctx 结构体中 io_sq_offload_start 会根据用户通过 io_uring_setup 传递的 flags 来配置 io_uring 的运行方式，后续详细展开 io_uring_get_fd 将 struct io_ring_ctx *ctx 暴露给用户态访问 ","date":"2021-10-30","objectID":"/posts/4f0d345c/:2:2","tags":["异步 IO","kernel","liburing","io_uring"],"title":"io_uring 内核源码分析","uri":"/posts/4f0d345c/"},{"categories":["IO Stack"],"content":"2.3. io_sq_offload_start static int io_sq_offload_start(struct io_ring_ctx *ctx, struct io_uring_params *p) { int ret; mmgrab(current-\u003emm); ctx-\u003esqo_mm = current-\u003emm; if (ctx-\u003eflags \u0026 IORING_SETUP_SQPOLL) { // IORING_SETUP_SQPOLL 将会创建一个内核线程来 poll SQ ret = -EPERM; if (!capable(CAP_SYS_ADMIN)) goto err; ctx-\u003esq_thread_idle = msecs_to_jiffies(p-\u003esq_thread_idle); if (!ctx-\u003esq_thread_idle) ctx-\u003esq_thread_idle = HZ; if (p-\u003eflags \u0026 IORING_SETUP_SQ_AFF) { int cpu = p-\u003esq_thread_cpu; ret = -EINVAL; if (cpu \u003e= nr_cpu_ids) goto err; if (!cpu_online(cpu)) goto err; ctx-\u003esqo_thread = kthread_create_on_cpu(io_sq_thread, ctx, cpu, \"io_uring-sq\"); } else { ctx-\u003esqo_thread = kthread_create(io_sq_thread, ctx, \"io_uring-sq\"); } if (IS_ERR(ctx-\u003esqo_thread)) { ret = PTR_ERR(ctx-\u003esqo_thread); ctx-\u003esqo_thread = NULL; goto err; } wake_up_process(ctx-\u003esqo_thread); } else if (p-\u003eflags \u0026 IORING_SETUP_SQ_AFF) { /* Can't have SQ_AFF without SQPOLL */ ret = -EINVAL; goto err; } /* Do QD, or 2 * CPUS, whatever is smallest */ ctx-\u003esqo_wq[0] = alloc_workqueue(\"io_ring-wq\", WQ_UNBOUND | WQ_FREEZABLE, min(ctx-\u003esq_entries - 1, 2 * num_online_cpus())); if (!ctx-\u003esqo_wq[0]) { ret = -ENOMEM; goto err; } /* * This is for buffered writes, where we want to limit the parallelism * due to file locking in file systems. As \"normal\" buffered writes * should parellelize on writeout quite nicely, limit us to having 2 * pending. This avoids massive contention on the inode when doing * buffered async writes. */ // 对 buffer 写的 workqueue 深度进行限制，减少锁争用开销? ctx-\u003esqo_wq[1] = alloc_workqueue(\"io_ring-write-wq\", WQ_UNBOUND | WQ_FREEZABLE, 2); if (!ctx-\u003esqo_wq[1]) { ret = -ENOMEM; goto err; } return 0; err: io_finish_async(ctx); mmdrop(ctx-\u003esqo_mm); ctx-\u003esqo_mm = NULL; return ret; } 当 flags 中配置了 IORING_SETUP_SQPOLL 时，将启动一个单独的内核线程 io_sq_thread，而当 IORING_SETUP_SQ_AFF 字段也配置时，将根据 sq_thread_cpu 字段，在指定的 CPU 上启用内核线程 io_sq_thread 同时该函数还会创建两个工作队列 ctx-\u003esqo_wq[2] 分别名为 io_ring-wq 和 io_ring-write-wq io_ring-wq 主要处理读 IO，以及 direct 写 IO io_ring-write-wq 主要是处理 buffer 写 IO ","date":"2021-10-30","objectID":"/posts/4f0d345c/:2:3","tags":["异步 IO","kernel","liburing","io_uring"],"title":"io_uring 内核源码分析","uri":"/posts/4f0d345c/"},{"categories":["IO Stack"],"content":"3. 系统调用 io_uring_enter SYSCALL_DEFINE6(io_uring_enter, unsigned int, fd, u32, to_submit, u32, min_complete, u32, flags, const sigset_t __user *, sig, size_t, sigsz) { struct io_ring_ctx *ctx; long ret = -EBADF; int submitted = 0; struct fd f; if (flags \u0026 ~(IORING_ENTER_GETEVENTS | IORING_ENTER_SQ_WAKEUP)) return -EINVAL; f = fdget(fd); if (!f.file) return -EBADF; ret = -EOPNOTSUPP; if (f.file-\u003ef_op != \u0026io_uring_fops) goto out_fput; ret = -ENXIO; ctx = f.file-\u003eprivate_data; if (!percpu_ref_tryget(\u0026ctx-\u003erefs)) goto out_fput; /* * For SQ polling, the thread will do all submissions and completions. * Just return the requested submit count, and wake the thread if * we were asked to. */ ret = 0; if (ctx-\u003eflags \u0026 IORING_SETUP_SQPOLL) { // 唤醒内核中的 sq_thread if (flags \u0026 IORING_ENTER_SQ_WAKEUP) wake_up(\u0026ctx-\u003esqo_wait); submitted = to_submit; } else if (to_submit) { // 主动提交请求 to_submit = min(to_submit, ctx-\u003esq_entries); mutex_lock(\u0026ctx-\u003euring_lock); submitted = io_ring_submit(ctx, to_submit); mutex_unlock(\u0026ctx-\u003euring_lock); if (submitted != to_submit) goto out; } if (flags \u0026 IORING_ENTER_GETEVENTS) { // 等待指定数量的请求完成 unsigned nr_events = 0; min_complete = min(min_complete, ctx-\u003ecq_entries); if (ctx-\u003eflags \u0026 IORING_SETUP_IOPOLL) { ret = io_iopoll_check(ctx, \u0026nr_events, min_complete); } else { ret = io_cqring_wait(ctx, min_complete, sig, sigsz); } } out: percpu_ref_put(\u0026ctx-\u003erefs); out_fput: fdput(f); return submitted ? submitted : ret; } io_uring_enter 是 io_uring 的核心系统调用之一，根据 flags 的配置以及 io_uring 的模式不同，其功能也不同 开启 IORING_SETUP_SQPOLL 时，可以通过配置 flags 的 IORING_ENTER_SQ_WAKEUP 位来唤醒内核中的代理线程 io_sq_thread 未开启 IORING_SETUP_SQPOLL 时，可以通过配置 to_submit 用来主动提交指定数量的请求 未开启 IORING_SETUP_SQPOLL 时，还可以通过配置 flags 的 IORING_ENTER_SQ_WAKEUP 位以及 min_complete 用来等待指定数量的请求完成 ","date":"2021-10-30","objectID":"/posts/4f0d345c/:3:0","tags":["异步 IO","kernel","liburing","io_uring"],"title":"io_uring 内核源码分析","uri":"/posts/4f0d345c/"},{"categories":["IO Stack"],"content":"4. 系统调用 io_uring_register SYSCALL_DEFINE4(io_uring_register, unsigned int, fd, unsigned int, opcode, void __user *, arg, unsigned int, nr_args) { struct io_ring_ctx *ctx; long ret = -EBADF; struct fd f; f = fdget(fd); if (!f.file) return -EBADF; ret = -EOPNOTSUPP; if (f.file-\u003ef_op != \u0026io_uring_fops) goto out_fput; ctx = f.file-\u003eprivate_data; mutex_lock(\u0026ctx-\u003euring_lock); // 核心函数 ret = __io_uring_register(ctx, opcode, arg, nr_args); mutex_unlock(\u0026ctx-\u003euring_lock); out_fput: fdput(f); return ret; } static int __io_uring_register(struct io_ring_ctx *ctx, unsigned opcode, void __user *arg, unsigned nr_args) __releases(ctx-\u003euring_lock) __acquires(ctx-\u003euring_lock) { int ret; /* * We're inside the ring mutex, if the ref is already dying, then * someone else killed the ctx or is already going through * io_uring_register(). */ if (percpu_ref_is_dying(\u0026ctx-\u003erefs)) return -ENXIO; percpu_ref_kill(\u0026ctx-\u003erefs); /* * Drop uring mutex before waiting for references to exit. If another * thread is currently inside io_uring_enter() it might need to grab * the uring_lock to make progress. If we hold it here across the drain * wait, then we can deadlock. It's safe to drop the mutex here, since * no new references will come in after we've killed the percpu ref. */ mutex_unlock(\u0026ctx-\u003euring_lock); wait_for_completion(\u0026ctx-\u003ectx_done); mutex_lock(\u0026ctx-\u003euring_lock); // 根据 opcode 注册/释放相应的缓冲区资源 switch (opcode) { case IORING_REGISTER_BUFFERS: ret = io_sqe_buffer_register(ctx, arg, nr_args); break; case IORING_UNREGISTER_BUFFERS: ret = -EINVAL; if (arg || nr_args) break; ret = io_sqe_buffer_unregister(ctx); break; case IORING_REGISTER_FILES: ret = io_sqe_files_register(ctx, arg, nr_args); break; case IORING_UNREGISTER_FILES: ret = -EINVAL; if (arg || nr_args) break; ret = io_sqe_files_unregister(ctx); break; case IORING_REGISTER_EVENTFD: ret = -EINVAL; if (nr_args != 1) break; ret = io_eventfd_register(ctx, arg); break; case IORING_UNREGISTER_EVENTFD: ret = -EINVAL; if (arg || nr_args) break; ret = io_eventfd_unregister(ctx); break; default: ret = -EINVAL; break; } /* bring the ctx back to life */ reinit_completion(\u0026ctx-\u003ectx_done); percpu_ref_reinit(\u0026ctx-\u003erefs); return ret; } io_uring_register 主要用于注册/释放各种不同类型的缓冲区资源 通过提前注册这些缓冲区可以减轻后续每个 IO 的申请资源开销，属于一种高级功能，在这里不做过多展开 ","date":"2021-10-30","objectID":"/posts/4f0d345c/:4:0","tags":["异步 IO","kernel","liburing","io_uring"],"title":"io_uring 内核源码分析","uri":"/posts/4f0d345c/"},{"categories":["IO Stack"],"content":"5. 内核线程 io_sq_thread static int io_sq_thread(void *data) { struct io_ring_ctx *ctx = data; struct mm_struct *cur_mm = NULL; const struct cred *old_cred; mm_segment_t old_fs; DEFINE_WAIT(wait); unsigned inflight; unsigned long timeout; // 通知主线程，sqo 线程已经启动 complete(\u0026ctx-\u003esqo_thread_started); old_fs = get_fs(); set_fs(USER_DS); old_cred = override_creds(ctx-\u003ecreds); // 线程的主循环 timeout = inflight = 0; while (!kthread_should_park()) { bool mm_fault = false; unsigned int to_submit; // 如果 inflight 不为 0，说明有请求正在处理中 if (inflight) { unsigned nr_events = 0; if (ctx-\u003eflags \u0026 IORING_SETUP_IOPOLL) { /* * inflight is the count of the maximum possible * entries we submitted, but it can be smaller * if we dropped some of them. If we don't have * poll entries available, then we know that we * have nothing left to poll for. Reset the * inflight count to zero in that case. */ mutex_lock(\u0026ctx-\u003euring_lock); // iopoll 模式下，sqo 还需要负责执行 poll if (!list_empty(\u0026ctx-\u003epoll_list)) io_iopoll_getevents(ctx, \u0026nr_events, 0); else inflight = 0; mutex_unlock(\u0026ctx-\u003euring_lock); } else { /* * Normal IO, just pretend everything completed. * We don't have to poll completions for that. */ // 非 iopoll 模式下，直接将 inflight 设置为 0 nr_events = inflight; } inflight -= nr_events; if (!inflight) timeout = jiffies + ctx-\u003esq_thread_idle; } // 获取 sq ring 中的 sqe 数量 to_submit = io_sqring_entries(ctx); if (!to_submit) { /* * Drop cur_mm before scheduling, we can't hold it for * long periods (or over schedule()). Do this before * adding ourselves to the waitqueue, as the unuse/drop * may sleep. */ if (cur_mm) { unuse_mm(cur_mm); mmput(cur_mm); cur_mm = NULL; } /* * We're polling. If we're within the defined idle * period, then let us spin without work before going * to sleep. */ // 有未完成的请求，或者还在 idle 时间内，就继续循环，暂缓请求的下发 if (inflight || !time_after(jiffies, timeout)) { cond_resched(); continue; } prepare_to_wait(\u0026ctx-\u003esqo_wait, \u0026wait, TASK_INTERRUPTIBLE); /* Tell userspace we may need a wakeup call */ ctx-\u003erings-\u003esq_flags |= IORING_SQ_NEED_WAKEUP; /* make sure to read SQ tail after writing flags */ smp_mb(); to_submit = io_sqring_entries(ctx); if (!to_submit) { if (kthread_should_park()) { finish_wait(\u0026ctx-\u003esqo_wait, \u0026wait); break; } if (signal_pending(current)) flush_signals(current); schedule(); finish_wait(\u0026ctx-\u003esqo_wait, \u0026wait); ctx-\u003erings-\u003esq_flags \u0026= ~IORING_SQ_NEED_WAKEUP; continue; } finish_wait(\u0026ctx-\u003esqo_wait, \u0026wait); ctx-\u003erings-\u003esq_flags \u0026= ~IORING_SQ_NEED_WAKEUP; } /* Unless all new commands are FIXED regions, grab mm */ if (!cur_mm) { mm_fault = !mmget_not_zero(ctx-\u003esqo_mm); if (!mm_fault) { use_mm(ctx-\u003esqo_mm); cur_mm = ctx-\u003esqo_mm; } } to_submit = min(to_submit, ctx-\u003esq_entries); // 提交请求 inflight += io_submit_sqes(ctx, to_submit, cur_mm != NULL, mm_fault); /* Commit SQ ring head once we've consumed all SQEs */ // 更新 sq ring 的 head io_commit_sqring(ctx); } set_fs(old_fs); if (cur_mm) { unuse_mm(cur_mm); mmput(cur_mm); } revert_creds(old_cred); kthread_parkme(); return 0; } graph TD io_sq_thread --\u003e io_sqring_entries io_sq_thread --\u003e io_submit_sqes io_sq_thread --\u003e io_commit_sqring io_sq_thread --\u003e io_iopoll_getevents sq_thread 的功能比较简单，就是一个代理线程，主要是负责将用户写入 sq 中的请求下发到设备驱动 此外在开启了 IOPOLL 模式时，sq_thread 同时负责轮询设备驱动确认 IO 是否完成 ","date":"2021-10-30","objectID":"/posts/4f0d345c/:5:0","tags":["异步 IO","kernel","liburing","io_uring"],"title":"io_uring 内核源码分析","uri":"/posts/4f0d345c/"},{"categories":["IO Stack"],"content":"6. IOPOLL 模式 ","date":"2021-10-30","objectID":"/posts/4f0d345c/:6:0","tags":["异步 IO","kernel","liburing","io_uring"],"title":"io_uring 内核源码分析","uri":"/posts/4f0d345c/"},{"categories":["IO Stack"],"content":"6.1. 启用 当 io_uring_setup 初始化时 flags 配置了 IORING_SETUP_IOPOLL 字段后将开启 IOPOLL 模式 ","date":"2021-10-30","objectID":"/posts/4f0d345c/:6:1","tags":["异步 IO","kernel","liburing","io_uring"],"title":"io_uring 内核源码分析","uri":"/posts/4f0d345c/"},{"categories":["IO Stack"],"content":"6.2. 限制 开启此选项必须保证后续只用 O_DIRECT 打开文件并且文件系统的 file_operations 中注册了 iopoll 函数，否则 IO 将下发失败 ","date":"2021-10-30","objectID":"/posts/4f0d345c/:6:2","tags":["异步 IO","kernel","liburing","io_uring"],"title":"io_uring 内核源码分析","uri":"/posts/4f0d345c/"},{"categories":["IO Stack"],"content":"6.3. 调用栈 开启后内核将调用注册的 iopoll 函数来主动轮询设备驱动确认 IO 是否完成 对 f_op-\u003eiopoll 函数调用关系进行了分析 graph TD io_uring_create --\u003e io_ring_ctx_wait_and_kill io_uring_release --\u003e io_ring_ctx_wait_and_kill io_ring_ctx_wait_and_kill --\u003e io_iopoll_reap_events io_ring_ctx_wait_and_kill --\u003e io_ring_ctx_free io_ring_ctx_free --\u003e io_iopoll_reap_events io_iopoll_reap_events --\u003e io_iopoll_getevents syscall[\"SYSCALL_DEFINE6(io_uring_enter, ……)\"] --\u003e io_iopoll_check --\u003e io_iopoll_getevents io_sq_thread --\u003e io_iopoll_getevents io_iopoll_getevents --\u003e io_do_iopoll --\u003e iopoll[\"f_op-\u003eiopoll\"] 主要有三条调用路线（所有调用逻辑都会判断是否在初始化时配置了 IORING_SETUP_IOPOLL）： io_uring 销毁时需要调用 系统调用 io_uring_enter 将会触发，用于轮询 IO 完成情况，直到到达指定的 wait_nr 数量 IO 完成后才会退出轮询 当初始化时同时配置了 IORING_SETUP_SQPOLL 时，io_sq_thread 内核线程触发，当存在未完成的 IO 时调用，用于更新 IO 完成情况（ io_do_iopoll 的参数 min = 0，即每次调用无论是否有新完成的 IO 都会退出轮询，不会阻塞线程） ","date":"2021-10-30","objectID":"/posts/4f0d345c/:6:3","tags":["异步 IO","kernel","liburing","io_uring"],"title":"io_uring 内核源码分析","uri":"/posts/4f0d345c/"},{"categories":["IO Stack"],"content":"当前内容基于 liburing 2.1 版本 ","date":"2021-10-29","objectID":"/posts/d7259d1d/:0:0","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 用户库源码分析","uri":"/posts/d7259d1d/"},{"categories":["IO Stack"],"content":"整体流程 之前在 io_uring 简介和使用 有过总结，使用 io_uring 的一般流程如下： 使用 open、fstat 等函数来打开文件以及元数据查看等操作 因为 io_uring 替换的是读写接口，后续 io_uring 操作的对象是 fd（由 open 函数执行返回的） 使用 io_uring_queue_init 初始化 struct io_uring ring 结构体 初始化 struct iovec *iovecs 结构体用于存放用户态 buffer 指针和长度 通过 io_uring_get_sqe 获取 sqe 通过 io_uring_prep_#OP 对 sqe 填充命令，buffer 以及 offset 信息 【可选】 通过 io_uring_sqe_set_data 对 sqe 附加 user_data 信息（该信息会在 cqe 中进行返回） 通过 io_uring_submit 对整个 ring 的所有 sqe 进行下发 通过 io_uring_wait_cqe 或者 io_uring_peek_cqe 来获取 cqe io_uring_wait_cqe 会阻塞当前线程直到有一个 cqe 返回 io_uring_peek_cqe 不会阻塞，如果当前没有 cqe，就会返回错误 io_uring_cqe_get_data 可以从 cqe 中获取 user_data 通过 io_uring_cqe_seen 对当前 cqe 进行清除，避免被二次处理 所有 IO 完成后，通过 io_uring_queue_exit 将 ring 销毁 ","date":"2021-10-29","objectID":"/posts/d7259d1d/:1:0","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 用户库源码分析","uri":"/posts/d7259d1d/"},{"categories":["IO Stack"],"content":"io_uring_queue_init 函数调用逻辑 graph TD io_uring_queue_init --\u003e io_uring_queue_init_params --\u003e __sys_io_uring_setup --\u003e syscall --\u003e|陷入内核|io_uring_setup io_uring_queue_init_params --\u003e io_uring_queue_mmap --\u003e io_uring_mmap --\u003e mmap 函数功能 该函数主要将队列深度以及额外的 flags 参数传递到内核，让内核的 io_uring_setup 来初始化 io_uring 结构体，同时使用 mmap 将在内核中初始化的 SQ、CQ 以及 SQEs 映射到用户态 初始化时传递的 flags 将影响 io_uring 的运行方式： IORING_SETUP_IOPOLL：开启此选项必须保证后续只用 O_DIRECT 打开文件并且文件系统的 file_operations 中注册了 iopoll 函数，否则 IO 将下发失败。开启后内核将调用注册的 iopoll 函数来主动轮询设备驱动确认 IO 是否完成 IORING_SETUP_SQPOLL：将启动一个单独的内核线程 io_sq_thread，内核将主动轮询 SQ，然后将 IO 下发至驱动设备，能大大减少提交 IO 时的系统调用开销（内核线程工作时，提交 IO 将无需系统调用；但是该线程可能会休眠，休眠时需要系统调用来唤醒该线程） IORING_SETUP_SQ_AFF：当 IORING_SETUP_SQPOLL 已经配置后，启用 sq_thread_cpu 字段，用于配置内核线程 io_sq_thread 的跑在哪个 CPU 上 ","date":"2021-10-29","objectID":"/posts/d7259d1d/:2:0","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 用户库源码分析","uri":"/posts/d7259d1d/"},{"categories":["IO Stack"],"content":"io_uring_get_sqe 由于 SQ 已经通过 mmap 映射到用户态，该函数只需在读取 sq-\u003ekhead 时通过 io_uring_smp_load_acquire 保证一致性，而 sq-\u003esqe_tail 只用于用户态，直接读取即可，根据 sq-\u003ekhead 以及 sq-\u003esqe_tail 判断 SQ 是否已满，未满则给出 sq-\u003esqe_tail 处的 sqe 即可，然后更新 sq-\u003esqe_tail ","date":"2021-10-29","objectID":"/posts/d7259d1d/:3:0","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 用户库源码分析","uri":"/posts/d7259d1d/"},{"categories":["IO Stack"],"content":"io_uring_prep_#OP 通过调用 io_uring_prep_rw 对 sqe 填充命令 OP、fd、buffer 指针以及 offset 信息等 ","date":"2021-10-29","objectID":"/posts/d7259d1d/:4:0","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 用户库源码分析","uri":"/posts/d7259d1d/"},{"categories":["IO Stack"],"content":"io_uring_sqe_set_data 直接对 sqe-\u003euser_data 进行赋值 ","date":"2021-10-29","objectID":"/posts/d7259d1d/:5:0","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 用户库源码分析","uri":"/posts/d7259d1d/"},{"categories":["IO Stack"],"content":"io_uring_submit 函数调用逻辑 graph TD io_uring_submit --\u003e __io_uring_submit_and_wait --\u003e __io_uring_flush_sq __io_uring_submit_and_wait --\u003e __io_uring_submit --\u003e sq_ring_needs_enter __io_uring_submit --\u003e __sys_io_uring_enter --\u003e __sys_io_uring_enter2 --\u003e syscall --\u003e|陷入内核|io_uring_enter 函数功能 __io_uring_flush_sq 根据 sq-\u003esqe_tail、sq-\u003esqe_head 差值依次填充 sq-\u003earray，然后一次性更新 sq-\u003ektail，并返回内核中仍未处理 sqe 数量（sq-\u003ektail - sq-\u003ekhead） sq_ring_needs_enter 判断内核线程 io_sq_thread 是否启用以及正常工作（没有休眠）: 首先要判断用户态 ring-\u003eflags 是否配置了 IORING_SETUP_SQPOLL 标志位，判断是否启用了内核线程 io_sq_thread 然后再判断内核态 ring-\u003esq.kflags 是否配置了 IORING_SQ_NEED_WAKEUP 标志位，判断内核线程 io_sq_thread 是否需要唤醒 当内核线程 io_sq_thread 启用并且正常工作时，则整个 io_uring_submit 到此结束，无需后续的 __sys_io_uring_enter 系统调用，减少了 IO 下发的系统调用的开销 __sys_io_uring_enter 系统调用陷入内核态，将参数传递给内核的 io_uring_setup 函数，主要用于提交 IO 和获取 IO 完成情况，具体功能和初始化时配置的 ring-\u003eflags 相关 ","date":"2021-10-29","objectID":"/posts/d7259d1d/:6:0","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 用户库源码分析","uri":"/posts/d7259d1d/"},{"categories":["IO Stack"],"content":"io_uring_wait_cqe 在用户态轮询判断是否有一个新的 cqe，无需系统调用陷入内核，但是会阻塞当前线程直到有一个新的 cqe 或者出错 ","date":"2021-10-29","objectID":"/posts/d7259d1d/:7:0","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 用户库源码分析","uri":"/posts/d7259d1d/"},{"categories":["IO Stack"],"content":"io_uring_peek_cqe 仅在用户态判断一次是否有新的 cqe，无需系统调用陷入内核，如果没有新的 cqe，会返回失败信息 -errno ","date":"2021-10-29","objectID":"/posts/d7259d1d/:8:0","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 用户库源码分析","uri":"/posts/d7259d1d/"},{"categories":["IO Stack"],"content":"io_uring_cqe_get_data cqe-\u003euser_data 会在 IO 完成后，从 sqe 复制到对应的 cqe 中，该函数只用直接对 cqe-\u003euser_data 进行读取 ","date":"2021-10-29","objectID":"/posts/d7259d1d/:9:0","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 用户库源码分析","uri":"/posts/d7259d1d/"},{"categories":["IO Stack"],"content":"io_uring_cqe_seen 更新 cq-\u003ekhead，避免当前 cqe 被重复获取 ","date":"2021-10-29","objectID":"/posts/d7259d1d/:10:0","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 用户库源码分析","uri":"/posts/d7259d1d/"},{"categories":["IO Stack"],"content":"io_uring_queue_exit 首先通过 munmap 将初始化时 mmap 的 SQ、CQ 以及 SQEs 解除映射，然后通过 close 关闭 io_uring 对应的 fd，close 会调用到该 fd 注册的 io_uring_release 来释放 io_uring ","date":"2021-10-29","objectID":"/posts/d7259d1d/:11:0","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 用户库源码分析","uri":"/posts/d7259d1d/"},{"categories":["IO Stack"],"content":"参考资料 【Kernel】io_uring IOSQE_IO_LINK 【个人博客】io_uring 的接口与实现 ","date":"2021-10-29","objectID":"/posts/d7259d1d/:12:0","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 用户库源码分析","uri":"/posts/d7259d1d/"},{"categories":["IO Stack"],"content":"简介 io_uring 是 Linux 在 5.1 版本引入的一套新的异步 IO 实现。相比 Linux 在 2.6 版本引入的 AIO，io_uring 性能强很多，接近 SPDK[1]，同时支持 buffer IO io_uring 的作者 Jens Axboe 是 Linux 内核块层和其他块设备的维护者，同时也是 CFQ、Noop、Deadline 调度器、blktrace 以及 FIO 的作者，对内核块层非常熟悉 ","date":"2021-10-28","objectID":"/posts/c142853f/:1:0","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 简介和使用","uri":"/posts/c142853f/"},{"categories":["IO Stack"],"content":"使用 ","date":"2021-10-28","objectID":"/posts/c142853f/:2:0","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 简介和使用","uri":"/posts/c142853f/"},{"categories":["IO Stack"],"content":"系统调用 io_uring 只增加了三个 Linux 系统调用分别是 io_uring_setup，io_uring_enter 和 io_uring_register 他们的入口都在 Linux 内核源码的 fs/io_uring.c 文件中 用户程序可以直接使用 syscall(__NR_xxx, ……) 的方式直接调用，使用起来很麻烦 ","date":"2021-10-28","objectID":"/posts/c142853f/:2:1","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 简介和使用","uri":"/posts/c142853f/"},{"categories":["IO Stack"],"content":"liburing 由于直接使用系统调用较为复杂，Jens Axboe 还提供了封装好的用户态库 liburing，简化了 io_uring 的使用，代码位置在 github 上 样例 liburing 仓库的 examples/ 目录下提供了几个简单的样例程序： 文件 功能 其他 io_uring-test.c 读取一个文件的全部内容 - io_uring-cp.c 复制一个文件的内容到另一个文件 使用 user_data 手动处理读写 IO 之间的依赖，读 IO 返回之后才下发写 IO link-cp.c 复制一个文件的内容到另一个文件 同时下发读写，使用 IOSQE_IO_LINK 保证读写之间的依赖[2] ucontext-cp.c 复制 n 个文件的内容到另 n 个文件 使用 ucontext 进行上下文切换，模拟 协程 代码流程 仔细阅读前三个用例，可以看出使用 io_uring 的一般流程如下： 使用 open、fstat 等函数来打开文件以及元数据查看等操作 因为 io_uring 替换的是读写接口，后续 io_uring 操作的对象是 fd（由 open 函数执行返回的） 使用 io_uring_queue_init 初始化 struct io_uring ring 结构体 初始化 struct iovec *iovecs 结构体用于存放用户态 buffer 指针和长度 通过 io_uring_get_sqe 获取 sqe 通过 io_uring_prep_#OP 对 sqe 填充命令，buffer 以及 offset 信息 【可选】 通过 io_uring_sqe_set_data 对 sqe 附加 user_data 信息（该信息会在 cqe 中进行返回） 通过 io_uring_submit 对整个 ring 的所有 sqe 进行下发 通过 io_uring_wait_cqe 或者 io_uring_peek_cqe 来获取 cqe io_uring_wait_cqe 会阻塞当前线程直到有一个 cqe 返回 io_uring_peek_cqe 不会阻塞，如果当前没有 cqe，就会返回错误 io_uring_cqe_get_data 可以从 cqe 中获取 user_data 通过 io_uring_cqe_seen 对当前 cqe 进行清除，避免被二次处理 所有 IO 完成后，通过 io_uring_queue_exit 将 ring 销毁 ","date":"2021-10-28","objectID":"/posts/c142853f/:2:2","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 简介和使用","uri":"/posts/c142853f/"},{"categories":["IO Stack"],"content":"编译 根据官方 Makefile 可以看出编译时有额外的三个条件 定义 _GNU_SOURCE 宏，-D 宏定义 指定额外的头文件目录，-I 指定头文件目录位置 使用 liburing 库，-L 指定库位置，-l 指定库名 即 gcc -D_GNU_SOURCE -I../src/include/ -L../src/ -o test test.c -luring 其中头文件目录下主要有三个头文件： $ tree src/include/ src/include/ ├── liburing │ ├── barrier.h │ └── io_uring.h └── liburing.h 1 directory, 3 files 而 liburing 库也需要编译生成，推荐直接在 liburing 的顶层目录直接 make all ","date":"2021-10-28","objectID":"/posts/c142853f/:3:0","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 简介和使用","uri":"/posts/c142853f/"},{"categories":["IO Stack"],"content":"参考资料 【PDF】官方 pdf 【Kernel】io_uring 性能测试 【维基百科】Jens Axboe 【Kernel】io_uring IOSQE_IO_LINK 【阿里云技术博客】Linux 异步 IO 新时代：io_uring 【GitHub】《操作系统与存储：解析 Linux 内核全新异步 IO 引擎 —— io_uring 设计与实现》 【个人博客】[译] Linux 异步 I/O 框架 io_uring：基本原理、程序示例与性能压测（2020） ","date":"2021-10-28","objectID":"/posts/c142853f/:4:0","tags":["异步 IO","liburing","io_uring"],"title":"io_uring 简介和使用","uri":"/posts/c142853f/"},{"categories":["路由器"],"content":"Web 界面 一般 OpenWrt 安装好之后会已经默启用了 Web 管理界面（LuCI），默认地址是 192.168.1.1，默认账号是 root，无密码，直接点击登录即可进入 ","date":"2021-10-28","objectID":"/posts/51140c4a/:1:0","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"汉化 默认界面是英文的，可以在 系统-软件 中搜索中文包安装进行汉化 点击 UPDATE LIST... 耐心等待软件包的更新 然后在 Filter: 下的输入框中输入 luci-i18n-base-zh-cn，在筛选出来的结果中点击 INSTALL...，安装勾上 Overwrite files from other package(s)，然后点击 INSTALL，耐心等待安装完成之后刷新网页（Ctrl+F5）可以看见大部分界面已经汉化了 同理安装 luci-i18n-opkg-zh-cn 包用于 系统-软件 界面的汉化 同理安装 luci-i18n-firewall-zh-cn 包用于 网络-防火墙 界面的汉化 opkg update opkg install luci-i18n-base-zh-cn luci-i18n-opkg-zh-cn luci-i18n-firewall-zh-cn ","date":"2021-10-28","objectID":"/posts/51140c4a/:1:1","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"root 密码 进入管理界面后进入 系统-管理-密码 界面修改路由器密码，同时也是系统的 root 账号的密码 ","date":"2021-10-28","objectID":"/posts/51140c4a/:1:2","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"ssh 然后在 系统-管理-ssh 可以配置 ssh 登录，参考配置如下 接口：不指定 → 内网以及外网都可以 ssh 登录 端口：22 → ssh 默认端口，不做修改 密码验证：不勾选 → 推荐使用 ssh 登录 允许 root 用户凭密码登录：不勾选 → 推荐使用 ssh 登录 网关端口：根据需要勾选 按照上面配置完成后将只能通过 ssh 密钥进行登录，所以还得在 系统-管理-ssh密钥 添加设备的公钥 ","date":"2021-10-28","objectID":"/posts/51140c4a/:1:3","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"升级 LuCI ssh 登入路由器后执行以下命令： # 更新软件源 opkg update # luci-compat 包有时可以帮助解决一些兼容性问题，推荐一同安装 opkg install luci luci-base luci-compat ","date":"2021-10-28","objectID":"/posts/51140c4a/:1:4","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"美化 原始的 bootstrap 主题个人不太喜欢，在空间足够的情况下我个人额外安装了 material，主题的切换在 系统-系统-语言和界面 中 opkg update opkg install luci-theme-material ","date":"2021-10-28","objectID":"/posts/51140c4a/:1:5","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"USB 很多路由器有 USB 端口，通过插入 U 盘或者接入磁盘、SSD 等设备可以拓展存储空间，这样就可以安装更多的插件，或者搭建一个简单的 FTP、SMB 服务器用于共享数据 ","date":"2021-10-28","objectID":"/posts/51140c4a/:2:0","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"安装 USB 驱动 依次执行以下命令进行驱动基本包的安装 opkg update opkg install kmod-usb-core # insmod usbcore opkg install kmod-usb-storage 如果设备是 USB 2.0 opkg install kmod-usb2 # insmod ehci-hcd 如果设备是 USB 3.0 opkg install kmod-usb3 # insmod xhci-hcd 通常移动硬盘或者移动 SSD 还需要安装 UAS/UASP 支持 opkg install kmod-usb-storage-uas 然后热插拔存储设备，通常就能在 /dev 目录下看见 sda 设备了 ","date":"2021-10-28","objectID":"/posts/51140c4a/:2:1","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"自动挂载 安装块设备工具包 opkg install block-mount 分区 个人已经提前将存储设备划分了两个分区，一个分区较小(sda1)用于后续的 Extroot，剩余的空间(sda2)全用于存储个人数据 创建文件系统 推荐移动磁盘用 ext4 文件系统，而移动 SSD 推荐使用 f2fs 文件系统 分区和创建文件系统可以参考 官网的指导 例如： # ext4 opkg install e2fsprogs opkg install kmod-fs-ext4 mkfs.ext4 /dev/sda1 # f2fs opkg install f2fs-tools opkg install kmod-fs-f2fs mkfs.f2fs /dev/sda1 配置挂载 配置挂载可以通过直接在网页端的 系统-挂载点 进行手动配置，比较直观，如图所示： 已启用：勾选 UUID：推荐使用 UUID 来进行挂载 挂载点：也就是挂载的位置，通常在 /mnt 目录下新建一个文件夹 ","date":"2021-10-28","objectID":"/posts/51140c4a/:2:2","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"Extroot 有时候安装太多包会导致本地空间不足，此时可以通过将包安装在 USB 设备上，也可以通过 Extroot 的方式将 USB 设备的空间直接配置成 overlay 分区，后者更为推荐 修改 fstab，将原本挂载的 overlay 设备挂载到新的目录 /rwm DEVICE=\"$(sed -n -e \"/\\s\\/overlay\\s.*$/s///p\" /etc/mtab)\" uci -q delete fstab.rwm uci set fstab.rwm=\"mount\" uci set fstab.rwm.device=\"${DEVICE}\" uci set fstab.rwm.target=\"/rwm\" uci commit fstab 修改 fstab，配置 USB 设备挂载成 overlay 分区 其中部分部分操作在 上节 已经执行过，可以略去 # 查看分区信息 # block info # 确定分区并制作文件系统 DEVICE=\"/dev/sda1\" # mkfs.ext4 ${DEVICE} eval $(block info ${DEVICE} | grep -o -e \"UUID=\\S*\") uci -q delete fstab.overlay uci set fstab.overlay=\"mount\" uci set fstab.overlay.uuid=\"${UUID}\" uci set fstab.overlay.target=\"/overlay\" uci commit fstab 将原本 overlay 分区数据复制到 USB 设备上，重启设备 mkdir -p /tmp/cproot mount --bind /overlay /tmp/cproot mkdir -p /mnt/tmp mount ${DEVICE} /mnt/tmp tar -C /tmp/cproot -cvf - . | tar -C /mnt/tmp -xf - umount /tmp/cproot /mnt/tmp reboot ","date":"2021-10-28","objectID":"/posts/51140c4a/:2:3","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"锐捷认证 很多学校校园网通常采用锐捷认证，并且限制了用户账号的登陆数量，但是我们可以通过在路由器上进行锐捷认证来接入校园网，之后连接路由器的所有设备都会直接接入校园网而不需要认证了 ","date":"2021-10-28","objectID":"/posts/51140c4a/:3:0","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"MentoHUST 首选，自动重连比 Minieap 靠谱得多！！！ MentoHUST 是华中科技大学的 HustMoon 最初在校内 BBS 白云黄鹤上发布的一款可以在 Linux 系统上进行锐捷认证的软件。不过 原始项目 已经归档，不在开发，GitHub 上有加入 v4 支持的 新项目 而在 OpenWrt 可以通过 GitHub 上的两个项目手动编译 .ipk 文件，然后 opkg install xxx.ipk 进行安装即可 通过 MentoHUST-OpenWrt-ipk OpenWrt 项目可以生成 mentohust 的二进制文件 通过 OpenWrt/LEDE LuCI for MentoHUST 项目可以生成 MentoHUST 的 LuCI 控制界面（命令行已经足够） 手动编译 ipk 文件的过程可以参考 这里 ","date":"2021-10-28","objectID":"/posts/51140c4a/:3:1","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"MiniEAP MiniEAP 是一个实现了标准 EAP-MD5-Challenge 算法的 EAP 客户端，支持通过插件来修改标准数据包以通过特殊服务端的认证。同时含有支持锐捷 v3 (v4) 算法的插件，可以用来进行锐捷认证 而在 OpenWrt 可以通过 GitHub 上的两个项目手动编译 .ipk 文件，然后 opkg install xxx.ipk 进行安装即可 通过 minieap-openwrt 项目可以生成 minieap 的二进制文件 (可选) 通过 OpenWrt/LEDE LuCI for minieap 项目可以生成 MiniEAP 的 LuCI 控制界面 补充：如果想要掉线自动重新认证，在配置文件中不要配置 no-auto-reauth，参考该 minieap@issue#43 ","date":"2021-10-28","objectID":"/posts/51140c4a/:3:2","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"防火墙 防火墙规则的详细配置可以参考 官方的介绍 以及部分 例子 ","date":"2021-10-28","objectID":"/posts/51140c4a/:4:0","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"开放端口 以开放 80 端口，用于外网直接访问 Web 界面为例： 首先要在 网络-防火墙-通信规则 点击新增，进行如下配置 名称：可以随意设置 协议：根据需要进行选择即可 源区域：选择 WAN 表示是从外网进行访问 源地址以及源端口：主要用于限制来访的设备，可以根据需要进行配置 目标区域：选择 设备 代表这是一个入站的规则 目标地址：因为是访问设备，此时不需要配置 目标端口：Web 的默认端口是 80 操作：开放端口，当然是选择接受 然后在 状态-防火墙 根据需要对 IPv4、IPv6 防火墙进行重启即可 如果这时外网还是不能访问 LuCI 的 Web 界面，可以尝试路由器重启，确认路由器的 IP 是否能够 ping 通，以及确认 80 端口有没有被运营商封禁 ","date":"2021-10-28","objectID":"/posts/51140c4a/:4:1","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"端口转发 以将 Windows 的远程连接的端口 3389 为例： 首先要在 网络-防火墙-端口转发 点击新增，进行如下配置 名称：可以随意设置 协议：根据需要进行选择即可 源区域：选择 WAN 表示是从外网进行访问 外部端口：这里配置成 13389 目标区域：选择 LAN 内部 IP 地址：配置成内网需要远程连接的主机 内部端口：远程连接的默认端口是 3389 然后在 状态-防火墙 根据需要对 IPv4、IPv6 防火墙进行重启即可 后续就可以通过访问路由器 WAN_IP:13389 来远程连接内网的 Windows 主机了 ","date":"2021-10-28","objectID":"/posts/51140c4a/:4:2","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"IPv6 在校园网环境下发现 WAN 口默认能自动获取到 IPv6 地址（但是 /128 的地址），并且在路由器上测试也能正常访问 IPv6 网站，但是局域网内的设备不能正常访问 IPv6 网站，于是选择 NAT6 的方式来解决 参考 官网的 NAT6 文档，需要在路由器内依次进行如下配置： 注：基于 OpenWrt 22.03.2 版本配置，版本不同配置可能有所不同！ 安装 kmod-ipt-nat6 包 # Install packages opkg update opkg install kmod-ipt-nat6 配置 IPv6 ULA 前缀，使得内网设备默认使用 IPv6 # Using IPv6 by default NET_ULA=\"$(uci get network.globals.ula_prefix)\" uci set network.globals.ula_prefix=\"d${NET_ULA:1}\" # 默认 network.lan.ip6assign 配置可能有误，需要根据 ula_prefix 重新配置 IP6_ASSIGN=\"$(echo ${NET_ULA} | grep -E '(\\d+)$' -o)\" uci set network.lan.ip6assign=\"${IP6_ASSIGN}\" uci commit network /etc/init.d/network restart 配置 WAN6 以及 LAN 端口 uci set dhcp.wan6.ra='relay' uci set dhcp.wan6.dhcpv6='relay' uci delete dhcp.wan6.ndp uci set dhcp.wan6.master='1' uci set dhcp.lan.ra_default='1' uci set dhcp.lan.ra='server' uci set dhcp.lan.dhcpv6='server' uci delete dhcp.lan.ndp uci set dhcp.lan.ra_management='1' uci commit dhcp /etc/init.d/odhcpd restart 配置防火墙 # Configure firewall uci set firewall.@zone[1].masq6=\"1\" uci commit firewall /etc/init.d/firewall restart 添加 ipv6 默认网关 cd /etc/hotplug.d/iface touch 90-nat66 echo \"#!/bin/sh\" \u003e\u003e 90-nat66 echo \"[ \\\"\\$ACTION\\\" = ifup ] || exit 0\" \u003e\u003e 90-nat66 echo \"route -A inet6 add default gw \\`(ip -6 route | grep default | awk '{print \\$5,\\$6,\\$7}')\\`\" \u003e\u003e 90-nat66 也可以直接 vim /etc/hotplug.d/iface/90-nat66 填入： #!/bin/sh [ \"$ACTION\" = ifup ] || exit 0 route -A inet6 add default gw `(ip -6 route | grep default | awk '{print $5,$6,$7}')` 该步骤主要是让 OpenWRT 每次重启后自动添加 ipv6 默认网关，如果要立即生效可以手动执行 重启路由器 ","date":"2021-10-28","objectID":"/posts/51140c4a/:5:0","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"ZeroTier 为了异地内网互访，ZeroTier 可以算是一个“神器”了，虽然不如 frp 稳定，但是胜在免费，无需公网 VPS 首先安装 zerotier 包 opkg update opkg install zerotier 直接修改配置文件 vim /etc/config/zerotier 默认文件类似下面这样 config zerotier sample_config option enabled 0 # persistent configuration folder (for ZT controller mode) #option config_path '/etc/zerotier' #option port '9993' # Generate secret on first start option secret '' # Join a public network called Earth list join '8056c2e21c000001' #list join '\u003cother_network\u003e' 修改其中的 enabled 为 1，开启服务，并且 list join 后的网络 ID 改为自己申请的网络 ID 即可 也可以新建一个配置，填上自己的网络 ID，如下 uci set zerotier.openwrt_network=zerotier uci add_list zerotier.openwrt_network.join='xxxxxxxxxxxxxxxx' uci set zerotier.openwrt_network.enabled='1' uci commit zerotier 重启路由器 reboot 配置防火墙 开启外网 udp 到 9993 端口的访问权限 uci add firewall rule uci set firewall.@rule[-1].name='Allow-ZeroTier-Inbound' uci set firewall.@rule[-1].src='*' uci set firewall.@rule[-1].target='ACCEPT' uci set firewall.@rule[-1].proto='udp' uci set firewall.@rule[-1].dest_port='9993' uci commit firewall /etc/init.d/firewall restart 配置 ZeroTier 的路由 在 网络-接口 界面新建一个接口，ztXXXXXXXX 根据实际情况替换，后续类似不再重复 名称：ZeroTier 协议：不配置协议 设备：ztXXXXXXXX 命令行也可以 uci set network.ZeroTier=interface uci set network.ZeroTier.proto='none' uci set network.ZeroTier.device='ztXXXXXXXX' uci commit network /etc/init.d/network restart 然后在 网络-防火墙 界面新建一个防火墙区域 名称: zerotier 入站数据：接受 出站数据：接受 转发：拒绝 IP 动态伪装: [√] MSS 钳制: [ ] 涵盖的网络: [√] ZeroTier 允许转发到目标区域：[√] lan [√] wan wan6 允许来自源区域的转发：[√] lan 命令行也可以，仅供参考 uci add firewall zone uci set firewall.@zone[-1].name='zerotier' uci set firewall.@zone[-1].input='ACCEPT' uci set firewall.@zone[-1].output='ACCEPT' uci set firewall.@zone[-1].forward='ACCEPT' uci set firewall.@zone[-1].masq='1' uci add_list firewall.@zone[-1].network='ZeroTier' uci add firewall forwarding uci set firewall.@forwarding[-1].src='zerotier' uci set firewall.@forwarding[-1].dest='lan' uci add firewall forwarding uci set firewall.@forwarding[-1].src='zerotier' uci set firewall.@forwarding[-1].dest='wan' uci add firewall forwarding uci set firewall.@forwarding[-1].src='lan' uci set firewall.@forwarding[-1].dest='zerotier' uci commit firewall /etc/init.d/firewall restart 至此路由器本身的配置就完了，然后需要去 zerotier 官网 配置一下路由 例如我的局域网段选的 192.168.192.*，两个路由器实际的内网的 LAN 口配置依次为 192.168.22.0/24 和 192.168.33.0/24 对应左边的红框，路由器自身的 ZeroTier 的虚拟 IP 为 192.168.192.22 和 192.168.192.33 则对应着右边红框，这里不详细展开，可以参考 这篇博文 ","date":"2021-10-28","objectID":"/posts/51140c4a/:6:0","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"FTP 配置好 USB 后，就可以配置 FTP 来共享 USB 设备 首先安装 vsftpd 包 opkg install vsftpd 修改配置文件 /etc/vsftpd.conf，这里给出个人的配置，可以参考 background=YES listen=YES anonymous_enable=NO local_enable=YES write_enable=YES local_umask=022 check_shell=NO #dirmessage_enable=YES #ftpd_banner=Welcome to MINI FTP service. session_support=NO #syslog_enable=YES #userlist_enable=YES #userlist_deny=NO #userlist_file=/etc/vsftpd/vsftpd.users #xferlog_enable=YES #xferlog_file=/var/log/vsftpd.log #xferlog_std_format=YES ### ### TLS/SSL options ### example key generation: openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/vsftpd/vsftpd_privkey.pem -out /etc #ssl_enable=YES #allow_anon_ssl=NO #force_local_data_ssl=NO #force_local_logins_ssl=NO #ssl_tlsv1=YES #ssl_sslv2=NO #ssl_sslv3=NO #rsa_cert_file=/etc/vsftpd/vsftpd_cert.pem #rsa_private_key_file=/etc/vsftpd/vsftpd_privkey.pem # 共享的目录位置 local_root=/mnt/ext4 pasv_enable=YES pasv_min_port=10090 pasv_max_port=10100 然后参考之前的 开放端口，打开 20、21、10090-10100 端口就可以在外网访问 FTP 服务器了 之后重启 vsftpd 服务即可使用 /etc/init.d/vsftpd restart P.S. 连接 ftp 服务器的账号密码就是路由器的 root 账号密码 ","date":"2021-10-28","objectID":"/posts/51140c4a/:7:0","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"SMB 使用 Samba 来共享的设备可以在 Windows 的文件资源管理器中挂载，使用起来和本地磁盘一样（在局域网内） 安装 samba4-server 以及 LuCI 管理界面 opkg install samba4-server opkg install luci-app-samba4 luci-i18n-samba4-zh-cn 在网页端的 服务-网络共享 中进行配置，个人配置如下，可以参考 之后重启 samba4 服务即可使用 /etc/init.d/samba4 restart P.S. 连接 Samba 服务器的账号密码也是路由器的 root 账号密码 ","date":"2021-10-28","objectID":"/posts/51140c4a/:8:0","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"BT 下载 transmission 是一个轻量级跨平台的 BT 下载客户端 安装 transmission opkg install transmission-daemon opkg install transmission-cli opkg install transmission-web # web 界面，可选 opkg install transmission-remote opkg install luci-app-transmission luci-i18n-transmission-zh-cn 直接修改 /etc/config/transmission，或者在网页端的 服务-Transmission 进行配置，下面给出个人配置，可以参考 config transmission option config_overwrite '1' option mem_percentage '50' option nice '10' option alt_speed_enabled 'false' option alt_speed_time_enabled 'false' option bind_address_ipv4 '0.0.0.0' option bind_address_ipv6 '::' option blocklist_enabled 'false' option cache_size_mb '2' option dht_enabled 'true' option download_queue_enabled 'true' option download_queue_size '4' option encryption '1' option idle_seeding_limit_enabled 'false' option lazy_bitfield_enabled 'true' option lpd_enabled 'false' option message_level '1' option peer_limit_global '240' option peer_limit_per_torrent '60' option peer_port '51413' option peer_port_random_on_start 'false' option peer_socket_tos 'default' option pex_enabled 'true' option port_forwarding_enabled 'true' option preallocation '1' option queue_stalled_enabled 'true' option queue_stalled_minutes '30' option ratio_limit '2.0000' option rename_partial_files 'true' option rpc_bind_address '0.0.0.0' option rpc_enabled 'true' option rpc_host_whitelist_enabled 'false' option rpc_port '9091' option rpc_url '/transmission/' option rpc_whitelist_enabled 'false' option scrape_paused_torrents_enabled 'true' option script_torrent_done_enabled 'false' option seed_queue_enabled 'false' option speed_limit_down_enabled 'false' option speed_limit_up_enabled 'false' option start_added_torrents 'true' option umask '18' option utp_enabled 'true' option scrape_paused_torrents 'true' option watch_dir_enabled 'false' option enabled '1' option user 'root' option group 'root' option upload_slots_per_torrent '10' option download_dir '/mnt/ext4/transmission' option incomplete_dir_enabled 'true' option incomplete_dir '/mnt/ext4/transmission/incomplete' option trash_original_torrent_files 'true' option rpc_authentication_required 'true' option rpc_username 'rpc_username' option rpc_password 'rpc_password' option ratio_limit_enabled 'true' option config_dir '/etc/transmission' 之后重启 transmission 服务即可使用 /etc/init.d/transmission restart 连接的账号密码为自行配置的 RPC 连接的账号密码 默认的 Web 界面 比较简陋，并且不能配置 tracker，个人推荐使用 transgui 来 RPC 连接使用 如果需要远程访问，则需要将 rpc_port 配置的端口开放，具体流程参考 上文 ","date":"2021-10-28","objectID":"/posts/51140c4a/:9:0","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"参考资料 【OpenWrt】LuCI 【CSDN】luci.cbi 报错 【GitHub】应用设置界面错误 【OpenWrt】安装 USB 驱动 【OpenWrt】使用 USB 设备 【OpenWrt】Extroot 配置 【GitHub】MentoHUST 加入 v4 支持 【GitHub】MentoHUST-OpenWrt-ipk 【GitHub】OpenWrt/LEDE LuCI for MentoHUST 【GitHub】MiniEAP 【GitHub】minieap-openwrt 【GitHub】OpenWrt/LEDE LuCI for minieap 【GitHub】no-auto-reauth 配置项的逻辑判断有问题 【OpenWrt】firewall rules 【OpenWrt】防火墙配置举例 【OpenWrt】IPv6 NAT6 配置 【OpenWrt】默认使用 IPv6 【OpenWrt】默认 IPv6 路由 【Bilibili】【老湿基】IPv6 竟然也可以开 NAT｜OpenWRT IPv6 NAT 手把手教学 【Zhihu】如何开启 NAT6 【GitHub】ZeroTier setup on OpenWRT 【个人博客】ZeroTier 中阶教程 【OpenWrt】FTP 【OpenWrt】Samba 【OpenWrt】transmission ","date":"2021-10-28","objectID":"/posts/51140c4a/:10:0","tags":["锐捷","IPv6","NAS","OpenWrt"],"title":"OpenWrt 配置使用","uri":"/posts/51140c4a/"},{"categories":["路由器"],"content":"简介 ","date":"2021-10-28","objectID":"/posts/8507aaa1/:1:0","tags":["OpenWrt"],"title":"OpenWrt 简介和安装","uri":"/posts/8507aaa1/"},{"categories":["路由器"],"content":"来源 2002 年底 Linksys 公司推出 WRT-54G，采用了 Linux 取代了原来的 vXworks 系统。迫于 Linux 的开源协议要求，Linksys 开源了路由器的固件代码，后续逐渐发展成了 OpenWrt 这样一个项目 ","date":"2021-10-28","objectID":"/posts/8507aaa1/:1:1","tags":["OpenWrt"],"title":"OpenWrt 简介和安装","uri":"/posts/8507aaa1/"},{"categories":["路由器"],"content":"介绍 OpenWrt 是一个针对嵌入式设备（通常是路由器或者软路由）的 Linux 操作系统项目，提供了具有软件包管理功能的完全可写的文件系统，因此拥有了完全定制的能力，可以榨干设备的全部性能 ","date":"2021-10-28","objectID":"/posts/8507aaa1/:1:2","tags":["OpenWrt"],"title":"OpenWrt 简介和安装","uri":"/posts/8507aaa1/"},{"categories":["路由器"],"content":"安装 初次安装推荐在 支持设备列表 中找到对应设备所在的 设备专属页面，然后根据页面介绍进行安装 ","date":"2021-10-28","objectID":"/posts/8507aaa1/:2:0","tags":["OpenWrt"],"title":"OpenWrt 简介和安装","uri":"/posts/8507aaa1/"},{"categories":["路由器"],"content":"一般安装流程 通常的安装步骤主要通过以下流程： 获取原厂固件的 SSH 登录权限（可能是通过原厂固件漏洞等方式） 在原厂固件上利用 cat /proc/mtd 获取 ROM 分区的布局 [可选] 备份原有的所有 ROM 分区数据 利用 mtd 等命令直接对相应的 ROM 区域进行写入镜像 [可选] bootloader 镜像（设备运行的情况下，个人更倾向于刷入 Breed） kernel 镜像 rootfs 镜像 重启设备 ","date":"2021-10-28","objectID":"/posts/8507aaa1/:2:1","tags":["OpenWrt"],"title":"OpenWrt 简介和安装","uri":"/posts/8507aaa1/"},{"categories":["路由器"],"content":"固件搜索下载 官网也对老手提供了快捷的 固件搜索 页面，能够更加快捷的找到 ROM 镜像的下载界面 ","date":"2021-10-28","objectID":"/posts/8507aaa1/:2:2","tags":["OpenWrt"],"title":"OpenWrt 简介和安装","uri":"/posts/8507aaa1/"},{"categories":["路由器"],"content":"参考资料 【维基百科】OpenWrt 【OpenWrt】官网 【OpenWrt】支持设备列表 【OpenWrt】固件搜索 ","date":"2021-10-28","objectID":"/posts/8507aaa1/:3:0","tags":["OpenWrt"],"title":"OpenWrt 简介和安装","uri":"/posts/8507aaa1/"},{"categories":["LaTeX"],"content":"中文支持参考环境配置中的 内容，在这里不做重复 ","date":"2021-10-19","objectID":"/posts/2033aa70/:0:0","tags":["LaTeX","todo"],"title":"LaTeX 语法","uri":"/posts/2033aa70/"},{"categories":["LaTeX"],"content":"长度 常用的长度单位 单位 含义 换算成 pt 换成算成 mm pt 基本单位 1 pt 0.35146 mm mm 毫米 2.84 pt 1 mm cm 厘米 28.4 pt 10 mm in 英寸 72.27 pt 0.35146 mm ex 当前字体的 x 字母高度 - - em 当前字体的 m 字母宽度 - - ","date":"2021-10-19","objectID":"/posts/2033aa70/:1:0","tags":["LaTeX","todo"],"title":"LaTeX 语法","uri":"/posts/2033aa70/"},{"categories":["LaTeX"],"content":"空行 \\vspace{length} ","date":"2021-10-19","objectID":"/posts/2033aa70/:2:0","tags":["LaTeX","todo"],"title":"LaTeX 语法","uri":"/posts/2033aa70/"},{"categories":["LaTeX"],"content":"空格 \\hspace{length} ","date":"2021-10-19","objectID":"/posts/2033aa70/:3:0","tags":["LaTeX","todo"],"title":"LaTeX 语法","uri":"/posts/2033aa70/"},{"categories":["LaTeX"],"content":"超链接 % 开启链接颜色配置，并配置为蓝色 \\usepackage[colorlinks=true, allcolors=blue]{hyperref} \\url{https://ywang-wnlo.github.io/posts/2033aa70.html} \\href{https://ywang-wnlo.github.io/posts/2033aa70.html}{LaTeX 语法} ","date":"2021-10-19","objectID":"/posts/2033aa70/:4:0","tags":["LaTeX","todo"],"title":"LaTeX 语法","uri":"/posts/2033aa70/"},{"categories":["LaTeX"],"content":"数学公式 ","date":"2021-10-19","objectID":"/posts/2033aa70/:5:0","tags":["LaTeX","todo"],"title":"LaTeX 语法","uri":"/posts/2033aa70/"},{"categories":["LaTeX"],"content":"段落中（隐式） 三种均可，任意选择，以 E=mc2 为例 \\(E=mc^2\\) $E=mc^2$ \\begin{math}E=mc^2\\end{math} ","date":"2021-10-19","objectID":"/posts/2033aa70/:5:1","tags":["LaTeX","todo"],"title":"LaTeX 语法","uri":"/posts/2033aa70/"},{"categories":["LaTeX"],"content":"单独成段（显式） 三种均可，任意选择 \\[E=mc^2\\] \\begin{displaymath}E=mc^2\\end{displaymath} \\begin{equation}E=mc^2\\end{equation} ","date":"2021-10-19","objectID":"/posts/2033aa70/:5:2","tags":["LaTeX","todo"],"title":"LaTeX 语法","uri":"/posts/2033aa70/"},{"categories":["LaTeX"],"content":"居中，左对齐，右对齐 ","date":"2021-10-19","objectID":"/posts/2033aa70/:6:0","tags":["LaTeX","todo"],"title":"LaTeX 语法","uri":"/posts/2033aa70/"},{"categories":["LaTeX"],"content":"居中 \\begin{center} balabala \\end{center} ","date":"2021-10-19","objectID":"/posts/2033aa70/:6:1","tags":["LaTeX","todo"],"title":"LaTeX 语法","uri":"/posts/2033aa70/"},{"categories":["LaTeX"],"content":"左对齐 \\begin{flushleft} balabala \\end{flushleft} ","date":"2021-10-19","objectID":"/posts/2033aa70/:6:2","tags":["LaTeX","todo"],"title":"LaTeX 语法","uri":"/posts/2033aa70/"},{"categories":["LaTeX"],"content":"右对齐 \\begin{flushright} balabala \\end{flushright} ","date":"2021-10-19","objectID":"/posts/2033aa70/:6:3","tags":["LaTeX","todo"],"title":"LaTeX 语法","uri":"/posts/2033aa70/"},{"categories":["LaTeX"],"content":"参考文献配置 \\bibliographystyle{stylename} \\bibliography{bibfile} 其中 bibfile 为 .bib 文件的名，而 stylename 是风格名称，以 overleaf 为例，有如下选项 stylename output abbrc acm alpha apalike ieeetr plain siam unsrt ","date":"2021-10-19","objectID":"/posts/2033aa70/:7:0","tags":["LaTeX","todo"],"title":"LaTeX 语法","uri":"/posts/2033aa70/"},{"categories":["LaTeX"],"content":"TODO ","date":"2021-10-19","objectID":"/posts/2033aa70/:8:0","tags":["LaTeX","todo"],"title":"LaTeX 语法","uri":"/posts/2033aa70/"},{"categories":["LaTeX"],"content":"参考资料 【维基百科】LaTeX Lengths 【维基百科】LaTeX Hyperlinks 【overleaf】Mathematical expressions 【overleaf】Bibtex bibliography styles ","date":"2021-10-19","objectID":"/posts/2033aa70/:9:0","tags":["LaTeX","todo"],"title":"LaTeX 语法","uri":"/posts/2033aa70/"},{"categories":["LaTeX"],"content":"Beamer 模板 PPT 推荐用 Beamer 模板来做，Beamer 是一个用于制作幻灯片的 LaTeX 文档类，可以用来制作演讲稿、学术报告、课件等 以下仅记录个人常用的一些功能，具体可以参考 Overleaf 上相关介绍 来使用 ","date":"2021-10-19","objectID":"/posts/499c5a19/:1:0","tags":["Beamer","LaTeX"],"title":"LaTeX PPT","uri":"/posts/499c5a19/"},{"categories":["LaTeX"],"content":"特性 ","date":"2021-10-19","objectID":"/posts/499c5a19/:2:0","tags":["Beamer","LaTeX"],"title":"LaTeX PPT","uri":"/posts/499c5a19/"},{"categories":["LaTeX"],"content":"frame 与 slide Beamer 中通常会用一对 \\begin{frame}、\\end{frame} 来制作一页幻灯片（slide），例如 \\begin{frame} \\frametitle{标题名称} 主体内容 \\end{frame} 然而其实 frame 并不等同于 slide，其实 frame 对应的是一组 slides \\pause 添加 \\pause 会将 \\pause 语句前面内容单独在新的一页 slide 上显示，实现了类似 PPT 动画中的点击页面出现下一段文字的效果，下面给出代码和生成的 PDF 帮助理解 \\begin{frame} \\frametitle{\\textbackslash pause 使用} 在这组幻灯片中 \\pause 这段文件将部分可见 \\pause 现在所有文字都可以看见了 \\end{frame} itemize 中的尖括号 \u003cstrat-end\u003e \\begin{frame} \\frametitle{item 中的尖括号} \\begin{itemize} \\item\u003c1-\u003e 该文字在 1+ 页均可见 \\item\u003c2-3\u003e 该文字在 2-3 页均可见 \\item\u003c3\u003e 该文字仅在第 3 页均可见 \\item\u003c4-\u003e 该文字在 4+ 页均可见 \\end{itemize} \\end{frame} ","date":"2021-10-19","objectID":"/posts/499c5a19/:2:1","tags":["Beamer","LaTeX"],"title":"LaTeX PPT","uri":"/posts/499c5a19/"},{"categories":["LaTeX"],"content":"参考资料 【Overleaf】Beamer ","date":"2021-10-19","objectID":"/posts/499c5a19/:3:0","tags":["Beamer","LaTeX"],"title":"LaTeX PPT","uri":"/posts/499c5a19/"},{"categories":["LaTeX"],"content":"网页环境 ","date":"2021-10-19","objectID":"/posts/4f94956/:1:0","tags":["LaTeX","VSCode"],"title":"LaTeX 环境配置","uri":"/posts/4f94956/"},{"categories":["LaTeX"],"content":"Overleaf Overleaf 是一个在线的 LaTeX 编辑环境，可以避免在本地安装和配置的过程，同时还能和他人共享编辑 官网的 教程文档 给了丰富的图文教程，这里不再赘述 推荐优先查看 创建文档 和 共享项目 ","date":"2021-10-19","objectID":"/posts/4f94956/:1:1","tags":["LaTeX","VSCode"],"title":"LaTeX 环境配置","uri":"/posts/4f94956/"},{"categories":["LaTeX"],"content":"本地环境 ","date":"2021-10-19","objectID":"/posts/4f94956/:2:0","tags":["LaTeX","VSCode"],"title":"LaTeX 环境配置","uri":"/posts/4f94956/"},{"categories":["LaTeX"],"content":"TeX Live TeX Live 可以利用镜像安装节省下载时间 从 清华镜像站 直接下载 或者利用 种子文件 BT 下载镜像 可以在安装 TeX Live 时同时勾选上安装 TeXworks 前端，然后就可以使用 TeXworks 作为 IDE 来使用了 ","date":"2021-10-19","objectID":"/posts/4f94956/:2:1","tags":["LaTeX","VSCode"],"title":"LaTeX 环境配置","uri":"/posts/4f94956/"},{"categories":["LaTeX"],"content":"TeXstudio TeXstudio 也是一个很好的 LaTeX 编辑软件，可以直接去 官网 下载安装，并且有中文界面 ","date":"2021-10-19","objectID":"/posts/4f94956/:2:2","tags":["LaTeX","VSCode"],"title":"LaTeX 环境配置","uri":"/posts/4f94956/"},{"categories":["LaTeX"],"content":"VSCode 个人更喜欢 VSCode，通过安装扩展并进行相应的配置即可较好的支持 LaTeX，同时还有格式化和自动补全等功能，非常方便 安装 LaTeX Workshop 扩展 直接在 VSCode 的扩展商店 中搜索 LaTeX Workshop 安装即可 编译链配置 默认配置 TeX Live 安装时会同时安装 latexmk, LaTeX Workshop 会默认使用 latexmk 来编译 .tex，无需手动再配置 手动配置(可选) 手动配置 LaTeX Workshop，在 VSCode 的配置文件 settings.json 中直接手动添加如下代码: 主要参考插件的 官方 recipes 配置 修改 // 配置编译链，可以根据需要做修改 \"latex-workshop.latex.recipes\": [ { \"name\": \"xelatex 🔃\", \"tools\": [ \"xelatex\" ] }, { \"name\": \"pdflatex 🔃\", \"tools\": [ \"pdflatex\" ] }, { \"name\": \"latexmk 🔃\", \"tools\": [ \"latexmk\" ] }, { \"name\": \"xelatex ➞ bibtex ➞ xelatex`×2\", \"tools\": [ \"xelatex\", \"bibtex\", \"xelatex\", \"xelatex\" ] }, { \"name\": \"pdflatex ➞ bibtex ➞ pdflatex`×2\", \"tools\": [ \"pdflatex\", \"bibtex\", \"pdflatex\", \"pdflatex\" ] } ], // 具体的编译命令配置 \"latex-workshop.latex.tools\": [ { \"name\": \"latexmk\", \"command\": \"latexmk\", \"args\": [ \"-synctex=1\", \"-interaction=nonstopmode\", \"-file-line-error\", \"-pdf\", \"-outdir=%OUTDIR%\", \"%DOC%\" ] }, { \"name\": \"xelatex\", \"command\": \"xelatex\", \"args\": [ \"-synctex=1\", \"-interaction=nonstopmode\", \"-file-line-error\", \"%DOC%\" ] }, { \"name\": \"pdflatex\", \"command\": \"pdflatex\", \"args\": [ \"-synctex=1\", \"-interaction=nonstopmode\", \"-file-line-error\", \"%DOC%\" ] }, { \"name\": \"bibtex\", \"command\": \"bibtex\", \"args\": [ \"%DOCFILE%\" ] } ], 正向同步 正向同步指的是编译完成后，在 .tex 文件内通过快捷键，快速定位到光标位置在 .tex 的对应位置，方便查看 PDF 文件 推荐打开文件修改后，编译完成后自动正向同步。该功能通过 latex-workshop.synctex.afterBuild.enabled 来控制 \"latex-workshop.synctex.afterBuild.enabled\": true, 反向同步 反向同步指的是编译完成后，在 PDF 文件内通过快捷键，快速定位点击部分在 .tex 的位置，方便修改 .tex 源码 主要参考插件的 官方 synctex 配置 修改 VSCode 内部 PDF 浏览器 如果直接使用 VSCode 来浏览 PDF，不需要额外设置，可以根据需要修改 latex-workshop.view.pdf.internal.synctex.keybinding 来修改反向同步的快捷键即可，默认 Ctrl 加鼠标左键 // 默认 Ctrl 加鼠标左键 \"latex-workshop.view.pdf.internal.synctex.keybinding\": \"ctrl-click\", 外部 PDF 浏览器 SumatraPDF 是一款流行的小巧方便的免费 PDF 浏览软件。VSCode 支持使用外部的 PDF 浏览器来查看编译后的 PDF 文件，以及反向搜索功能。主要需要如下配置： // 配置为使用外部 PDF 浏览软件来浏览 PDF \"latex-workshop.view.pdf.viewer\": \"external\", // 配置外部 PDF 浏览软件的命令行以及参数 \"latex-workshop.view.pdf.external.viewer.command\": \"D:/Program/SumatraPDF/SumatraPDF-3.2-64.exe\", // 自行修改路径 \"latex-workshop.view.pdf.external.viewer.args\": [ \"%PDF%\" ], 在 SumatraPDF 的设置-选项中设置反向搜索命令行 C:\\Users\\\u003cuser\u003e\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe -g \"%f:%l\"，Code 的路径应该为完整的绝对路径 其他可选配置 // 关闭自动编译 \"latex-workshop.latex.autoBuild.run\": \"never\", // 默认选择上次编译链 \"latex-workshop.latex.recipe.default\": \"lastUsed\" // 右键菜单 \"latex-workshop.showContextMenu\": true, // 关闭编译出错的弹窗 \"latex-workshop.message.error.show\": false, \"latex-workshop.message.warning.show\": false, ","date":"2021-10-19","objectID":"/posts/4f94956/:2:3","tags":["LaTeX","VSCode"],"title":"LaTeX 环境配置","uri":"/posts/4f94956/"},{"categories":["LaTeX"],"content":"中文支持 该节主要参考 Overleaf Chinese 文档 推荐使用 XeLaTeX 和 LuaLaTeX 来编译含有中文字符的 .tex 文件 ","date":"2021-10-19","objectID":"/posts/4f94956/:3:0","tags":["LaTeX","VSCode"],"title":"LaTeX 环境配置","uri":"/posts/4f94956/"},{"categories":["LaTeX"],"content":"XeLaTeX 和 LuaLaTeX 直接使用 ctexart 文档类即可支持中文 或者使用 ctex 包来支持中文 参考代码如下： \\documentclass{ctexart} \\begin{document} \\tableofcontents \\begin{abstract} 这是简介及摘要。 \\end{abstract} \\section{前言} \\section{关于数学部分} 数学、中英文皆可以混排。You can intersperse math, Chinese and English (Latin script) without adding extra environments. 這是繁體中文。 \\end{document} 或者 \\documentclass{xxx} \\usepackage{ctex} ","date":"2021-10-19","objectID":"/posts/4f94956/:3:1","tags":["LaTeX","VSCode"],"title":"LaTeX 环境配置","uri":"/posts/4f94956/"},{"categories":["LaTeX"],"content":"XeLaTeX XeLaTeX 还可以使用 xeCJK 包来支持中文 参考代码如下： \\documentclass{article} \\usepackage{xeCJK} \\begin{document} \\section{前言} \\section{关于数学部分} 数学、中英文皆可以混排。You can intersperse math, Chinese and English (Latin script) without adding extra environments. 這是繁體中文。 \\end{document} ","date":"2021-10-19","objectID":"/posts/4f94956/:3:2","tags":["LaTeX","VSCode"],"title":"LaTeX 环境配置","uri":"/posts/4f94956/"},{"categories":["LaTeX"],"content":"pdfLaTeX pdfLaTeX 对中文支持不是很好，只用 pdaLaTeX 的话需要引入 CJKutf8 包，并且用 \\begin{CJK*}{UTF8}{gbsn} 和 \\end{CJK*} 包住所有的中文。 gbsn 和 gkai 是简体的字体 bsmi 和 bkai 是繁体的字体 参考代码如下： \\documentclass{article} \\usepackage{CJKutf8} \\begin{document} \\begin{CJK*}{UTF8}{gbsn} \\section{前言} \\section{关于数学部分} 数学、中英文皆可以混排。You can intersperse math, Chinese and English (Latin script) without adding extra environments. \\end{CJK*} \\bigskip %% Just some white space You can also insert Latin text in your document \\bigskip %% Just some white space \\begin{CJK*}{UTF8}{bsmi} 這是繁體中文。 \\end{CJK*} \\end{document} ","date":"2021-10-19","objectID":"/posts/4f94956/:3:3","tags":["LaTeX","VSCode"],"title":"LaTeX 环境配置","uri":"/posts/4f94956/"},{"categories":["LaTeX"],"content":"编译 首先 .tex 文件名以及路径尽量不要含有空格以及中文字符 在使用 latexmk 和 VSCode 的 LaTeX Workshop 时，推荐使用第三个编译链 Recipe: latexmk (lualatex) ","date":"2021-10-19","objectID":"/posts/4f94956/:3:4","tags":["LaTeX","VSCode"],"title":"LaTeX 环境配置","uri":"/posts/4f94956/"},{"categories":["LaTeX"],"content":"参考资料 【Overleaf】教程文档 【Overleaf】创建文档 【Overleaf】共享项目 【LaTeX Workshop】依赖 【LaTeX Workshop】recipes 配置 【LaTeX Workshop】synctex 配置 【知乎】使用 VSCode 编写 LaTeX 【知乎】Visual Studio Code 配置 LaTeX 【Overleaf】Chinese ","date":"2021-10-19","objectID":"/posts/4f94956/:4:0","tags":["LaTeX","VSCode"],"title":"LaTeX 环境配置","uri":"/posts/4f94956/"},{"categories":["LaTeX"],"content":"TeX 和 LaTeX Tex 是一个排版软件，而 LaTeX 是基于 TeX 开发的排版系统，可以理解成 LaTeX 通过对 TeX 进行封装，使用 TeX 作为它的格式化引擎，使得排版文字变得更加方便。 LaTeX 利用 TeX 对 .tex 后缀的文件进行编译，生成 .dvi 文件 ","date":"2021-10-19","objectID":"/posts/a4752f87/:1:0","tags":["LaTeX"],"title":"LaTeX 基础介绍","uri":"/posts/a4752f87/"},{"categories":["LaTeX"],"content":"pdfTeX、XeTeX 和 LuaTeX ","date":"2021-10-19","objectID":"/posts/a4752f87/:2:0","tags":["LaTeX"],"title":"LaTeX 基础介绍","uri":"/posts/a4752f87/"},{"categories":["LaTeX"],"content":"三者的介绍 pdfTeX、XeTeX 和 LuaTeX 都是在原有的 TeX 停止更新后进行修改增强的 TeX 引擎，提供一些额外的附加功能，例如可以直接输出成 pdf 文件等。 pdfLaTeX 表示将 LaTeX 宏包与 pdfTeX 引擎一起使用 XeLaTeX 表示将 LaTeX 宏包与 XeTeX 引擎一起使用 LuaLaTeX 表示将 LaTeX 宏包与 LuaTeX 引擎一起使用 ","date":"2021-10-19","objectID":"/posts/a4752f87/:2:1","tags":["LaTeX"],"title":"LaTeX 基础介绍","uri":"/posts/a4752f87/"},{"categories":["LaTeX"],"content":"各自的特性 pdfTeX 的主要特性是能直接生成 pdf XeLaTeX 的主要特性是支持 UTF-8 编码，因此理论上原生支持中文字符 LuaLaTeX 的主要特性除了支持 UTF-8 编外之外，主要是增加了 Lua 脚本 ","date":"2021-10-19","objectID":"/posts/a4752f87/:2:2","tags":["LaTeX"],"title":"LaTeX 基础介绍","uri":"/posts/a4752f87/"},{"categories":["LaTeX"],"content":"参考资料 【Overleaf】pdfTeX, XeTeX and LuaTeX ","date":"2021-10-19","objectID":"/posts/a4752f87/:3:0","tags":["LaTeX"],"title":"LaTeX 基础介绍","uri":"/posts/a4752f87/"}]